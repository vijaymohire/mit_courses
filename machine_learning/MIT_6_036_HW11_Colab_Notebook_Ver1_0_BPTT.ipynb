{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "q58cS9antfCw"
      },
      "cell_type": "markdown",
      "source": [
        "#MIT 6.036 Spring 2019: Homework 11#\n",
        "\n",
        "This colab notebook provides code and a framework for question 6 from [homework 11](https://lms.mitx.mit.edu/courses/course-v1:MITx+6.036+2019_Spring/courseware/Week11/week11_homework/).  You can work out your solutions here, then submit your results back on the homework page when ready.\n",
        "\n",
        "## <section>**Setup**</section>\n",
        "\n",
        "First, download the code distribution for this homework that contains test cases and helper functions.\n",
        "\n",
        "Run the next code block to download and import the code for this lab."
      ]
    },
    {
      "metadata": {
        "id": "OUEtSZRdtmI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38493fa1-8b7b-48be-c364-eecd5a1da978"
      },
      "cell_type": "code",
      "source": [
        "!rm -rf code_for_hw11* __MACOSX data .DS_Store\n",
        "#!wget --quiet https://introml.odl.mit.edu/cat-soop/_static/6.036/homework/hw11/code_for_hw11.zip\n",
        "!wget --quiet https://introml_oll.odl.mit.edu/cat-soop/_static/6.036/homework/hw11/code_for_hw11.zip\n",
        "!unzip code_for_hw11.zip\n",
        "!mv code_for_hw11/* ."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  code_for_hw11.zip\n",
            "   creating: code_for_hw11/\n",
            "  inflating: code_for_hw11/rnn_hw11.py  \n",
            "  inflating: code_for_hw11/util.py   \n",
            "  inflating: code_for_hw11/sm.py     \n",
            "  inflating: code_for_hw11/.rnn_hw11.py.swp  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#session = tf.compat.v1.keras.backend.get_session()\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "K6umsDsjA9Nk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import code_for_hw11 as code_for_hw11\n",
        "from rnn_hw11 import *\n",
        "from util import *\n",
        "\n",
        "import numpy as np\n",
        "import math as m\n",
        "import random\n",
        "\n",
        "import pdb\n",
        "from util import argmax_with_val, argmax\n",
        "import importlib"
      ],
      "metadata": {
        "id": "fI3ePJGO7iWp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8jnw4bt5QKLJ"
      },
      "cell_type": "markdown",
      "source": [
        "P6) **BPTT in code**:\n",
        "\n",
        "Complete the following implementation of BPTT. This is a method in an RNN class.\n",
        "\n",
        "The instance (self) has attributes that define the RNN, in particular:\n",
        "\n",
        "The weight matrices and offsets: self.Wss, self.Wsx, self.Wo, self.Wss0 and self.Wo0.\n",
        "The activation functions and their derivatives: self.f1, self.df1, self.f2, self.df2\n",
        "The loss function and the derivative of the combined loss and final activation (as we did for feedforward networks): self.loss_fn and self.dloss_f2.\n",
        "The dimensions of states (hidden), inputs and outputs: self.hidden_dim, self.input_dim, self.output_dim.\n",
        "The initial state and, the current state: self.init_state and self.hidden_state\n",
        "The step size for gradient descent: self.step_size\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Back propagation through time\n",
        "# xs is matrix of inputs: l by k\n",
        "# dLdz2 is matrix of output errors: 1 by k\n",
        "# states is matrix of state values: m by k\n",
        "def bptt(self, xs, dLtdz2, states):\n",
        "    dWsx = np.zeros_like(self.Wsx)\n",
        "    dWss = np.zeros_like(self.Wss)\n",
        "    dWo = np.zeros_like(self.Wo)\n",
        "    dWss0 = np.zeros_like(self.Wss0)\n",
        "    dWo0 = np.zeros_like(self.Wo0)\n",
        "\n",
        "    # Derivative of future loss (from t+1 forward) wrt state at time t\n",
        "    dFtdst = np.zeros((self.hidden_dim, 1))\n",
        "    k = xs.shape[1]\n",
        "\n",
        "    for t in range(k-1, -1, -1):\n",
        "        # Get relevant quantities\n",
        "        xt = xs[:, t:t+1]\n",
        "        st = states[:, t:t+1]\n",
        "        stm1 = states[:, t-1:t] if t-1 >= 0 else self.init_state\n",
        "        dLtdz2t = dLtdz2[:, t:t+1]\n",
        "\n",
        "        # Compute gradients step by step using Final answers only\n",
        "        dLtdst = np.transpose(self.Wo) @ dLtdz2t  # Your final answer\n",
        "        dFtm1dst = dLtdst + dFtdst              # Your final answer\n",
        "        dFtm1dz1t = dFtm1dst * self.df1(st)    # Your final answer\n",
        "        dFtm1dstm1 = np.transpose(self.Wss) @ dFtm1dz1t  # Your final answer\n",
        "\n",
        "        # Gradients w.r.t weights\n",
        "        dLtdWo = dLtdz2t @ np.transpose(st)     # Your final answer\n",
        "        dLtdWo0 = dLtdz2t                        # Your final answer\n",
        "        dFtm1dWss = dFtm1dz1t @ np.transpose(stm1)  # Your final answer\n",
        "        dFtm1dWss0 = dFtm1dz1t                   # Your final answer\n",
        "        dFtm1dWsx = dFtm1dz1t @ np.transpose(xt)  # Your final answer\n",
        "\n",
        "        # Accumulate updates to weights\n",
        "        dWsx += dFtm1dWsx\n",
        "        dWss += dFtm1dWss\n",
        "        dWss0 += dFtm1dWss0\n",
        "        dWo += dLtdWo\n",
        "        dWo0 += dLtdWo0\n",
        "\n",
        "        # Pass delta \"back\" to next iteration\n",
        "        dFtdst = dFtm1dstm1\n",
        "\n",
        "    return dWsx, dWss, dWo, dWss0, dWo0\n"
      ],
      "metadata": {
        "id": "BObcy8JjF8Fc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DDiVytnhTssj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a372df6-40bf-4485-c9ce-c955f20735cd"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def delay_num_test(bptt, delay = 1, num_epochs = 10000, num_seqs = 10000, seq_length = 10, step_size = .005):\n",
        "  '''\n",
        "  This is a test function provided to help you debug your implementation\n",
        "\n",
        "  In case we want to initialize.  Now just for delay = 1\n",
        "  # Wsx = np.array([[1.], [0.]])\n",
        "  # Wss = np.array([[0., 0.],\n",
        "  #              [1., 0.]])\n",
        "  # Wo = np.array([[0., 1.]])\n",
        "  # Wss0 = np.array([[0.], [0.0]])\n",
        "  # Wo0 = np.array([[0.]])\n",
        "  '''\n",
        "  np.random.seed(0)\n",
        "  data = []\n",
        "  for _ in range(num_seqs):\n",
        "    vals = np.random.random((1, seq_length))\n",
        "    x = np.hstack([vals, np.zeros([1, delay])])\n",
        "    y = np.hstack([np.zeros((1, delay)), vals])\n",
        "    data.append((x, y))\n",
        "  m = (delay + 1) * 2\n",
        "  RNN.bptt = bptt\n",
        "  rnn = RNN(1, m, 1, quadratic_loss, lambda z: z, quadratic_linear_gradient, step_size, lambda z: z, lambda z: 1)\n",
        "  # Wsx = Wsx, Wo = Wo, Wss = Wss, Wo0 = Wo0, Wss0 = Wss0)\n",
        "  rnn.train_seq_to_seq(data, num_epochs)\n",
        "  assert np.all(np.isclose(rnn.Wsx, np.array([[0.00856855],\n",
        "        [0.01936238],\n",
        "        [0.01382334],\n",
        "        [0.00771265]])))\n",
        "  assert np.all(np.isclose(rnn.Wss, np.array([[0.01505222, 0.02059889, 0.01594291, 0.00558242],\n",
        "        [0.00824307, 0.01741733, 0.01864768, 0.01079751],\n",
        "        [0.01577334, 0.0124164 , 0.0171516 , 0.0071486 ],\n",
        "        [0.00722321, 0.00497032, 0.00514737, 0.00979516]])))\n",
        "  assert np.all(np.isclose(rnn.Wo, np.array([[0.02522786, 0.01744193, 0.01995478, 0.0084726 ]])))\n",
        "  assert np.all(np.isclose(rnn.Wss0, np.array([[0.01502946],\n",
        "        [0.01181406],\n",
        "        [0.02051297],\n",
        "        [0.00716202]])))\n",
        "  assert np.all(np.isclose(rnn.Wo0, np.array([[0.42198824]])))\n",
        "  print(\"Test passed!\")\n",
        "  return (rnn.Wsx, rnn.Wss, rnn.Wo, rnn.Wss0, rnn.Wo0)\n",
        "\n",
        "delay_num_test(bptt)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training error 0.04945571303681596\n",
            "training error 0.048114092792055106\n",
            "training error 0.04850511140924504\n",
            "training error 0.04834714371014377\n",
            "training error 0.04845429552158349\n",
            "training error 0.048195163749529306\n",
            "training error 0.0490306116336328\n",
            "training error 0.048476636551466105\n",
            "training error 0.048258029080159005\n",
            "Test passed!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.00856855],\n",
              "        [0.01936238],\n",
              "        [0.01382334],\n",
              "        [0.00771265]]),\n",
              " array([[0.01505222, 0.02059889, 0.01594291, 0.00558242],\n",
              "        [0.00824307, 0.01741733, 0.01864768, 0.01079751],\n",
              "        [0.01577334, 0.0124164 , 0.0171516 , 0.0071486 ],\n",
              "        [0.00722321, 0.00497032, 0.00514737, 0.00979516]]),\n",
              " array([[0.02522786, 0.01744193, 0.01995478, 0.0084726 ]]),\n",
              " array([[0.01502946],\n",
              "        [0.01181406],\n",
              "        [0.02051297],\n",
              "        [0.00716202]]),\n",
              " array([[0.42198824]]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}