{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xIaEwCD406A"
      },
      "source": [
        "#MIT 6.036 Spring 2019: Homework 8#\n",
        "\n",
        "This colab notebook provides code and a framework for [homework 8](https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week8/week8_homework/).  You can work out your solutions here, then submit your results back on the homework page when ready. By New MIT course 2024\n",
        "\n",
        "## <section>**Setup**</section>\n",
        "\n",
        "First, download the code distribution for this homework that contains test cases and helper functions.\n",
        "\n",
        "Run the next code block to download and import the code for this lab.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow==1.9\n",
        "!pip install tensorflow==2.8.0\n",
        "!pip install np_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awwxMVzrVar9",
        "outputId": "47fe0608-077e-4f07-ffff-83cba7925dc6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.8.0\n",
            "  Using cached tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (24.3.25)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.11.0)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.8.0)\n",
            "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.16.0)\n",
            "Collecting tensorboard<2.9,>=2.8 (from tensorflow==2.8.0)\n",
            "  Using cached tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8.0)\n",
            "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.0)\n",
            "  Using cached keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.64.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.32.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\n",
            "Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "Installing collected packages: tf-estimator-nightly, tensorboard-plugin-wit, keras, tensorboard-data-server, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.23.1 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Requirement already satisfied: np_utils in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from np_utils) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#session = tf.compat.v1.keras.backend.set_session()\n",
        "#K.get_session()\n",
        "session = tf.compat.v1.keras.backend.get_session()\n",
        "\n",
        "from tensorflow.compat.v1.keras.models import Sequential"
      ],
      "metadata": {
        "id": "3Ms9vAuGXHDw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "batG7aEHaNM7",
        "outputId": "9eb83bb7-3b56-423f-d758-7620f142568f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-07 13:16:45--  https://introml_oll.odl.mit.edu/cat-soop/_static/6.036/homework/hw08/code_for_hw8.zip\n",
            "Resolving introml_oll.odl.mit.edu (introml_oll.odl.mit.edu)... 3.226.240.108\n",
            "Connecting to introml_oll.odl.mit.edu (introml_oll.odl.mit.edu)|3.226.240.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 95906 (94K) [application/zip]\n",
            "Saving to: ‘code_for_hw8.zip’\n",
            "\n",
            "code_for_hw8.zip    100%[===================>]  93.66K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-09-07 13:16:46 (749 KB/s) - ‘code_for_hw8.zip’ saved [95906/95906]\n",
            "\n",
            "Archive:  code_for_hw8.zip\n",
            "   creating: code_for_hw8/\n",
            "  inflating: code_for_hw8/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/code_for_hw8/\n",
            "  inflating: __MACOSX/code_for_hw8/._.DS_Store  \n",
            "  inflating: code_for_hw8/code_for_hw8_oop.py  \n",
            "  inflating: __MACOSX/code_for_hw8/._code_for_hw8_oop.py  \n",
            "   creating: code_for_hw8/data/\n",
            "  inflating: code_for_hw8/data/data3_train.csv  \n",
            "   creating: __MACOSX/code_for_hw8/data/\n",
            "  inflating: __MACOSX/code_for_hw8/data/._data3_train.csv  \n",
            "  inflating: code_for_hw8/data/data4_train.csv  \n",
            "  inflating: code_for_hw8/data/data4_validate.csv  \n",
            "  inflating: code_for_hw8/data/data3_validate.csv  \n",
            "  inflating: code_for_hw8/data/dataXor_train.csv  \n",
            "  inflating: code_for_hw8/data/data2_train.csv  \n",
            "  inflating: code_for_hw8/data/data2_validate.csv  \n",
            "  inflating: code_for_hw8/data/data3class_train.csv  \n",
            "  inflating: code_for_hw8/data/data1_validate.csv  \n",
            "  inflating: code_for_hw8/data/data1_train.csv  \n",
            "  inflating: code_for_hw8/code_for_hw8_keras.py  \n",
            "  inflating: __MACOSX/code_for_hw8/._code_for_hw8_keras.py  \n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!rm -rf code_for_hw8*\n",
        "!rm -rf data\n",
        "!rm -rf mnist_data\n",
        "!rm -rf *.zip\n",
        "!rm -rf test*/\n",
        "!rm -rf *.py\n",
        "!rm -rf *.pt\n",
        "!rm -rf __*\n",
        "!wget https://introml_oll.odl.mit.edu/cat-soop/_static/6.036/homework/hw08/code_for_hw8.zip --no-check-certificate\n",
        "#!wget --quiet https://introml.odl.mit.edu/6.036/static/homework/hw08/code_for_hw8.zip --no-check-certificate\n",
        "!unzip code_for_hw8.zip\n",
        "#!unzip code_for_hw8/q4.zip\n",
        "#!unzip -q test1.zip\n",
        "#!unzip -q test2.zip\n",
        "#!unzip -q test3.zip\n",
        "!mv code_for_hw8/* .\n",
        "\n",
        "from code_for_hw8 import *\n",
        "\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "import math as m\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision\n",
        "\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "\n",
        "import os\n",
        "!pwd\n",
        "\n",
        "os.environ['KERAS_BACKEND']='tensorflow'\n",
        "#import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "#from code_for_hw8_oop import Module, Linear, Tanh, ReLU, SoftMax, NLL\n",
        "#from code_for_hw8_pytorch import get_image_data_1d\n",
        "\n",
        "#from utils_hw8 import (model_fit, model_evaluate, run_pytorch, call_model,\n",
        "#                       plot_decision, plot_heat, plot_separator, make_iter,\n",
        "#                       set_weights, set_bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-sSs7N4mMiX"
      },
      "source": [
        "# 2) Implementing Mini-batch Gradient Descent and Batch Normalization (OPTIONAL)\n",
        "\n",
        "** Note: You can click the arrow on the left of this text block to collapse/expand this optional section and all its code blocks **\n",
        "\n",
        "Last week we implemented a framework for building neural networks from scratch. We trained our models using *stochastic* gradient descent. In this problem, we explore how we can implement batch normalization as a module `BatchNorm` in our framework. It is the same module which you analyzed in problem 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgxmIfXVmVwd"
      },
      "source": [
        "Key to the concept of batch normalization is the doing gradient descent on batches of data. So we instead of using last week's stochastic gradient descent, we will first implement the *mini-batch* gradient descent method `mini_gd`, which is a hybrid between *stochastic* gradient descent and *batch* gradient descent. The lecture notes on <a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week7/neural_networks_2/1?activate_block_id=block-v1%3AMITx%2B6.036%2B2019_Spring%2Btype%40vertical%2Bblock%40neural_networks_2_optimizing_neural_network_parameters_vert\"> optimizing neural network parameters</a> are helpful for this part.\n",
        "\n",
        "In *mini-batch* gradient descent, for a mini-batch of size $K$, we select $K$ distinct data points uniformly at random from the data set and update the network weights based only on their contributions to the gradient:\n",
        "$$W := W - \\eta\\sum_{i=1}^K \\nabla_W \\mathcal{L}(h(x^{(i)}; W), y^{(i)})\\;\\;.$$\n",
        "\n",
        "Our *mini-batch* method `mini_gd` will be implemented within the `Sequential` python class (see homework 7 problem 2) and will take the following as inputs:\n",
        "\n",
        "* `X`: a standard data array (d by n)\n",
        "* `y`: a standard labels row vector (1 by n)\n",
        "* `iters`: the number of updates to perform on weights $W$\n",
        "* `lrate`: the learning rate used\n",
        "* `K`: the mini-batch size to be used\n",
        "\n",
        "One call of `mini_gd` should call `Sequential.backward` for back-propagation and `Sequential.step` for updating the weights, for a total of `iters` times, using `lrate` as the learning rate. As in our implementation of `sgd` from homework 7, we compute the predicted output for a mini-batch of data with the `Sequential.forward` method. We compute the loss between our predictions and the true labels using the assigned `Sequential.loss` method. (Note that in homework 7, `Sequential.step` was called `Sequential.sgd_step`. While the functionality of the step function is the same, it has been renamed for convenience. The same is true for the `module.step` function of each module we implemented, where applicable.)\n",
        "\n",
        "For picking $K$ unique data points at random from our large data-set for each mini-batch, we will implement the following strategy: we will first shuffle our data points `X` (and associated labels `y`). Then, we get <math>\\frac{n}{k}</math> (rounded down to the nearest integer) different mini-batches by grouping each $K$ consecutive points from this shuffled array. If we end up iterating over all the points but need more mini-batches, we will repeat the shuffling and the batching process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr1kWI08mdo4"
      },
      "source": [
        "<b>2A)</b>You need to fill in the missing code below. We have implemented the shuffling of indices and have provided you with the outer and inner loops."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_lvmO9Z22bH"
      },
      "source": [
        "** This OPTIONAL problem has you extend your homework 7 implementation for building neural networks. **\n",
        "### PLEASE COPY IN YOUR CODE FROM HOMEWORK 7 TO COMPLEMENT THE CLASSES GIVEN HERE\n",
        "\n",
        "Recall that your implementation from homework 7 included the following classes:\n",
        "    \n",
        "  * Module\n",
        "  * Linear\n",
        "  * Tanh\n",
        "  * ReLU\n",
        "  * SoftMax\n",
        "  * NLL\n",
        "  * Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1f46u0j2yVL6"
      },
      "outputs": [],
      "source": [
        "class Module:\n",
        "    def sgd_step(self, lrate): pass  # For modules w/o weights\n",
        "\n",
        "\n",
        "class Linear(Module):\n",
        "    def __init__(self, m, n):\n",
        "        self.m, self.n = (m, n)  # (in size, out size)\n",
        "        self.W0 = np.zeros([self.n, 1])  # (n x 1)\n",
        "        self.W = np.random.normal(0, 1.0 * m ** (-.5), [m, n])  # (m x n)\n",
        "\n",
        "class Tanh(Module):            # Layer activation\n",
        "    def forward(self, Z):\n",
        "        self.A = np.tanh(Z)\n",
        "        return self.A\n",
        "\n",
        "    def backward(self, dLdA):    # Uses stored self.A\n",
        "        return dLdA * (1.0 - (self.A ** 2))        # Your code: return dLdZ (?, b)\n",
        "\n",
        "class ReLU(Module):              # Layer activation\n",
        "    def forward(self, Z):\n",
        "        self.A = np.maximum(0, Z)\n",
        "        return self.A\n",
        "\n",
        "    def backward(self, dLdA):    # uses stored self.A\n",
        "        return dLdA * (self.A != 0)\n",
        "\n",
        "class SoftMax(Module):           # Output activation\n",
        "    def forward(self, Z):\n",
        "        return np.exp(Z) / np.sum(np.exp(Z), axis=0)\n",
        "\n",
        "    def backward(self, dLdZ):    # Assume that dLdZ is passed in\n",
        "        return dLdZ\n",
        "\n",
        "    def class_fun(self, Ypred):  # Return class indices\n",
        "        return np.argmax(Ypred, axis=0)   # Your code: (1, b)\n",
        "\n",
        "class NLL(Module):       # Loss\n",
        "    def forward(self, Ypred, Y):\n",
        "        self.Ypred = Ypred\n",
        "        self.Y = Y\n",
        "        return float(np.sum(-Y * np.log(Ypred)))\n",
        "\n",
        "    def backward(self):  # Use stored self.Ypred, self.Y\n",
        "        return self.Ypred - self.Y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jrvcXA1mzYtO"
      },
      "outputs": [],
      "source": [
        " import math as m\n",
        "\n",
        " class Sequential:\n",
        "    def __init__(self, modules, loss):            # List of modules, loss module\n",
        "        self.modules = modules\n",
        "        self.loss = loss\n",
        "\n",
        "    def sgd(self, X, Y, iters=100, lrate=0.005):  # Train\n",
        "        D, N = X.shape\n",
        "        sum_loss = 0\n",
        "        for it in range(iters):\n",
        "            i = np.random.randint(N)\n",
        "            Xt = X[:, i:i+1]\n",
        "            Yt = Y[:, i:i+1]\n",
        "            Ypred = self.forward(Xt)\n",
        "            sum_loss += self.loss.forward(Ypred, Yt)\n",
        "            err = self.loss.backward()\n",
        "            self.backward(err)\n",
        "            self.sgd_step(lrate)\n",
        "\n",
        "    def forward(self, Xt):                        # Compute Ypred\n",
        "        for m in self.modules: Xt = m.forward(Xt)\n",
        "        return Xt\n",
        "\n",
        "    def backward(self, delta):                    # Update dLdW and dLdW0\n",
        "        # Note reversed list of modules\n",
        "        for m in self.modules[::-1]: delta = m.backward(delta)\n",
        "\n",
        "    def sgd_step(self, lrate):                    # Gradient descent step\n",
        "        for m in self.modules: m.sgd_step(lrate)\n",
        "\n",
        "    def print_accuracy(self, it, X, Y, cur_loss, every=250):\n",
        "        # Utility method to print accuracy on full dataset, should\n",
        "        # improve over time when doing SGD. Also prints current loss,\n",
        "        # which should decrease over time. Call this on each iteration\n",
        "        # of SGD!\n",
        "        if it % every == 1:\n",
        "            cf = self.modules[-1].class_fun\n",
        "            acc = np.mean(cf(self.forward(X)) == cf(Y))\n",
        "            print('Iteration =', it, '\tAcc =', acc, '\tLoss =', cur_loss)\n",
        "\n",
        "    def mini_gd(self, X, Y, iters, lrate, notif_each=None, K=10):\n",
        "        D, N = X.shape\n",
        "\n",
        "        np.random.seed(0)\n",
        "        num_updates = 0\n",
        "        indices = np.arange(N)\n",
        "        while num_updates < iters:\n",
        "\n",
        "            np.random.shuffle(indices)\n",
        "            X = None  # Your code\n",
        "            Y = None  # Your code\n",
        "\n",
        "            for j in range(m.floor(N/K)):\n",
        "                if num_updates >= iters: break\n",
        "\n",
        "                # Implement the main part of mini_gd here\n",
        "                # Your code\n",
        "\n",
        "                num_updates += 1\n",
        "\n",
        "    def step(self, lrate):\n",
        "        for m in self.modules: m.step(lrate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JZeeKXkm6YI"
      },
      "source": [
        "<b>2B)</b> We are now ready to implement batch normalization into our neural network framework! Our module `BatchNorm` will sit between consecutive layers of neurons, such as the $l^{th}$ and $(l+1)^{th}$ layers, acting as a \"corrector\" which allows $W^l$ to change freely, producing outputs $z^l$, but then the module corrects the covariate shift induced in the signals before they reach the $(l+1)^{th}$ layer, converting $z^l$ to $\\widehat{Z}^l$.\n",
        "\n",
        "The following is a summmary what is described in the <a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week7/neural_networks_2/2\">lecture notes</a>, and it should guide your implementation of the module.\n",
        "\n",
        "Any normalization between the $l^{th}$ and $(l+1)^{th}$ layers is done *separately* for each of the $n^l$ input connections leading to the $(l+1)^{th}$ layer. We handle a mini-batch of data of size $K$, and $Z^l$ is $n^l \\times K$, and the output $\\widehat{Z}^l$is of the same shape.\n",
        "\n",
        "We first compute $n^l$ *batchwise* means and\n",
        "standard deviations.  Let $\\mu^l$ be the $n^l \\times 1$ vector (`self.mus`) where\n",
        "$$\\mu^l_i = \\frac{1}{K} \\sum_{j = 1}^K Z^l_{ij}\\;\\;,$$\n",
        "and let $\\sigma^l$ be the $n^l \\times 1$ vector (`self.vars`) where\n",
        "$$\\sigma^l_i = \\sqrt{\\frac{1}{K} \\sum_{j = 1}^K (Z^l_{ij} - \\mu_i)^2}\\;\\;.$$\n",
        "\n",
        "The normalized data `self.norm` is the matrix $\\overline{Z}$, where\n",
        "$$\\overline{Z}^l_{ij} = \\frac{Z^l_{ij} - \\mu^l_i}{\\sigma^l_i + \\epsilon}\\;\\;,$$\n",
        "and where $\\epsilon$ is a very small constant to guard against division by\n",
        "zero.\n",
        "\n",
        "We define weights $G^l$ (`self.G`) and $B^l$ (`self.B`), each being an $n^l \\times 1$ vector, which we use to to shift and scale the outputs:\n",
        "$$\\widehat{Z}^l_{ij} = G^l_i \\overline{Z}^l_{ij} + B^l_i\\;\\;.$$\n",
        "\n",
        "The outputs are finally ready to be passed to the $(l+1)^{th}$ layer.\n",
        "\n",
        "A slight warning (that we will not worry about here) about `BatchNorm` is that during the *test* phase, if the test mini-batch size is too small (imagine we are deploying a neural network that deals with live video frames), then the lack of samples would cause the freshly-calculated $\\mu^l$ and $\\sigma^l$ to be far off from their true values that the module's parameters $G^l$ and $B^l$ were trained to be compatible with. To fix that, people usually compute a running average of $\\mu^l$ and $\\sigma^l$ during training, to be used at test time. We will assume our test mini-batches are large enough.\n",
        "\n",
        "In this problem we only implement the `BatchNorm.forward` and `BatchNorm.step` methods. We provide you with the implementation for `BatchNorm.backward` and the lecture notes contain the details of the derivations. You will need to fill in the missing code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UlXP26plm8R7"
      },
      "outputs": [],
      "source": [
        "class BatchNorm(Module):\n",
        "    def __init__(self, m):\n",
        "        np.random.seed(0)\n",
        "        self.eps = 1e-20\n",
        "        self.m = m  # number of input channels\n",
        "\n",
        "        # Init learned shifts and scaling factors\n",
        "        self.B = np.zeros([self.m, 1])\n",
        "        self.G = np.random.normal(0, 1.0 * self.m ** (-.5), [self.m, 1])\n",
        "\n",
        "    # Works on m x b matrices of m input channels and b different inputs\n",
        "    def forward(self, A):# A is m x K: m input channels and mini-batch size K\n",
        "        # Store last inputs and K for next backward() call\n",
        "        self.A = A\n",
        "        self.K = A.shape[1]\n",
        "\n",
        "        self.mus = np.mean(Z, axis=1, keepdims=True)  # Your Code\n",
        "        self.vars = np.var(Z, axis=1, keepdims=True)  # Your Code\n",
        "\n",
        "        # Normalize inputs using their mean and standard deviation\n",
        "        self.norm = (Z - self.mus)/(np.sqrt(self.vars) + self.eps)  # Your Code\n",
        "\n",
        "        # Return scaled and shifted versions of self.norm\n",
        "        return self.G * self.norm + self.B  # Your Code\n",
        "\n",
        "    def backward(self, dLdZ):\n",
        "        # Re-usable constants\n",
        "        std_inv = 1/np.sqrt(self.vars+self.eps)\n",
        "        A_min_mu = self.A-self.mus\n",
        "\n",
        "        dLdnorm = dLdZ * self.G\n",
        "        dLdVar = np.sum(dLdnorm * A_min_mu * -0.5 * std_inv**3, axis=1, keepdims=True)\n",
        "        dLdMu = np.sum(dLdnorm*(-std_inv), axis=1, keepdims=True) + dLdVar * (-2/self.K) * np.sum(A_min_mu, axis=1, keepdims=True)\n",
        "        dLdX = (dLdnorm * std_inv) + (dLdVar * (2/self.K) * A_min_mu) + (dLdMu/self.K)\n",
        "\n",
        "        self.dLdB = np.sum(dLdZ, axis=1, keepdims=True)\n",
        "        self.dLdG = np.sum(dLdZ * self.norm, axis=1, keepdims=True)\n",
        "        return dLdX\n",
        "\n",
        "    def step(self, lrate):\n",
        "        self.B = self.B - lrate*self.dLdB  # Your Code\n",
        "        self.G = self.G - lrate*self.dLdG  # Your Code\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65LKUAHD_77Y"
      },
      "source": [
        "# 3) 2D Datasets\n",
        "\n",
        "For the 2D datasets, we have provided the following function:\n",
        "\n",
        "\n",
        "```\n",
        "run_keras_2d(data_name, layers, epochs, split=0.25, display=True, trials=5)\n",
        "```\n",
        "\n",
        "\n",
        "where:\n",
        "\n",
        "data_name is a string, such as '1', '2', etc.\n",
        "layers is a list of Keras layer definitions for a Sequential model, e.g.\n",
        "```\n",
        "[Dense(input_dim=2, units=10, activation='relu'), Dense(units=2, activation='softmax')]\n",
        "```\n",
        "\n",
        "epochs is an integer indicating how many times to go through the data in training\n",
        "split is a fraction of the training data to use for validation if a validation set is not defined\n",
        "display whether to display result plots\n",
        "verbose whether to print loss and accuracy (percent correctly labeled) each epoch\n",
        "trials is an integer indicating how many times to perform the training and testing\n",
        "2D Data\n",
        "The two-class datasets have data_names: '1','2','3','4'. Target accuracies (percent correct) on the validation set are (99%, 90.5%, 96%, 94%).\n",
        "\n",
        "In this problem, try the following 5 architectures, specified by the number of units in the hidden layers:\n",
        "\n",
        "1: (0), 2: (10), 3: (100), 4: (10, 10), 5: (100, 100))\n",
        "You may find the archs function in the code file to be helpful here.\n",
        "Some of these questions ask for the \"simplest\" architecture; the list above is ordered starting with the simplest."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import np_utils"
      ],
      "metadata": {
        "id": "5R4IZ2XoGU0h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdb\n",
        "#import numpy as np\n",
        "import itertools\n",
        "\n",
        "#import math as m"
      ],
      "metadata": {
        "id": "kl9li3rJLJsr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Vp-RWPD7FUeo"
      },
      "outputs": [],
      "source": [
        "\n",
        "import keras\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.compat.v1.keras.models import Sequential\n",
        "#from keras.models import Sequential\n",
        "#from keras.optimizers import SGD, Adam\n",
        "from tensorflow.compat.v1.keras.optimizers import SGD, Adam\n",
        "\n",
        "#from keras.layers import Conv1D, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
        "from tensorflow.compat.v1.keras.layers import Conv1D, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
        "\n",
        "#from keras.utils import np_utils\n",
        "#from keras import utils\n",
        "from tensorflow.compat.v1.keras import utils\n",
        "\n",
        "#from keras.callbacks import Callback\n",
        "from tensorflow.compat.v1.keras.callbacks import Callback\n",
        "\n",
        "#from keras.datasets import mnist\n",
        "from tensorflow.compat.v1.keras.datasets import mnist\n",
        "\n",
        "#from keras.initializers import VarianceScaling\n",
        "from tensorflow.compat.v1.keras.initializers import VarianceScaling\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "#from keras import backend as K\n",
        "import tensorflow.keras.backend as K"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def run_keras_2d(data_name, layers, epochs, display=True, split=0.25, verbose=True, trials=1):\n",
        "    print('Keras FC: dataset=', data_name)\n",
        "    (train_dataset, val_dataset, test_dataset) = dataset_paths(data_name)\n",
        "\n",
        "    # Load the datasets\n",
        "    X_train, y, num_classes = get_data_set(train_dataset)\n",
        "    X_val, y2, _ = get_data_set(val_dataset)\n",
        "    X_test, y3, _ = get_data_set(test_dataset)\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    y_train = utils.to_categorical(y, num_classes)\n",
        "    y_val = utils.to_categorical(y2, num_classes) if X_val is not None else None\n",
        "    y_test = utils.to_categorical(y3, num_classes) if X_test is not None else None\n",
        "\n",
        "    val_acc, test_acc = 0, 0\n",
        "    for trial in range(trials):\n",
        "        # Reset the weights for TensorFlow 1.x compatibility\n",
        "        sess = tf.compat.v1.keras.backend.get_session()\n",
        "        for layer in layers:\n",
        "            for v in layer.__dict__:\n",
        "                v_arg = getattr(layer, v)\n",
        "                if hasattr(v_arg, 'initializer'):\n",
        "                    initializer_func = getattr(v_arg, 'initializer')\n",
        "                    initializer_func.run(session=sess)\n",
        "\n",
        "        # Run the model\n",
        "        model, history, vacc, tacc = run_keras(X_train, y_train, X_val, y_val, X_test, y_test, layers, epochs, split=split, verbose=verbose)\n",
        "        val_acc += vacc if vacc else 0\n",
        "        test_acc += tacc if tacc else 0\n",
        "\n",
        "        if display:\n",
        "            # Plot classifier landscape on training data\n",
        "            plot_heat(X_train, y, model)\n",
        "            plt.title('Training data')\n",
        "            plt.show()\n",
        "\n",
        "            if X_test is not None:\n",
        "                # Plot classifier landscape on testing data\n",
        "                plot_heat(X_test, y3, model)\n",
        "                plt.title('Testing data')\n",
        "                plt.show()\n",
        "\n",
        "            # Plot epoch loss\n",
        "            if 'epoch_loss' in history.values and 'epoch_val_loss' in history.values:\n",
        "                plt.plot(history.values['epoch_loss'], label='loss')\n",
        "                plt.plot(history.values['epoch_val_loss'], label='val_loss')\n",
        "                plt.xlabel('epoch')\n",
        "                plt.ylabel('loss')\n",
        "                plt.title('Epoch val_loss and loss')\n",
        "                plt.legend()\n",
        "                plt.show()\n",
        "\n",
        "            # Plot epoch accuracy\n",
        "            if 'epoch_acc' in history.values and 'epoch_val_acc' in history.values:\n",
        "                plt.plot(history.values['epoch_acc'], label='accuracy')\n",
        "                plt.plot(history.values['epoch_val_acc'], label='val_accuracy')\n",
        "                plt.xlabel('epoch')\n",
        "                plt.ylabel('accuracy')\n",
        "                plt.title('Epoch val_acc and acc')\n",
        "                plt.legend()\n",
        "                plt.show()\n",
        "\n",
        "    if val_acc:\n",
        "        print(\"\\nAvg. validation accuracy:\" + str(val_acc / trials))\n",
        "    if test_acc:\n",
        "        print(\"\\nAvg. test accuracy:\" + str(test_acc / trials))\n",
        "\n",
        "    return X_train, y, model\n"
      ],
      "metadata": {
        "id": "Ano7Xnigy7e2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# Problem 3 - 2D data\n",
        "######################################################################\n",
        "import tensorflow as tf\n",
        "\n",
        "'''def archs(classes):\n",
        "    return [[Dense(input_dim=2, units=classes, activation=\"softmax\")],\n",
        "            [Dense(input_dim=2, units=10, activation='relu'),\n",
        "             Dense(units=classes, activation=\"softmax\")],\n",
        "            [Dense(input_dim=2, units=100, activation='relu'),\n",
        "             Dense(units=classes, activation=\"softmax\")],\n",
        "            [Dense(input_dim=2, units=10, activation='relu'),\n",
        "             Dense(units=10, activation='relu'),\n",
        "             Dense(units=classes, activation=\"softmax\")],\n",
        "            [Dense(input_dim=2, units=100, activation='relu'),\n",
        "             Dense(units=100, activation='relu'),\n",
        "             Dense(units=classes, activation=\"softmax\")]]'''\n",
        "def archs(classes):\n",
        "    return [\n",
        "        [tf.compat.v1.keras.layers.Dense(input_dim=2, units=classes, activation=\"softmax\")],\n",
        "        [tf.compat.v1.keras.layers.Dense(input_dim=2, units=10, activation='relu'),\n",
        "         tf.compat.v1.keras.layers.Dense(units=classes, activation=\"softmax\")],\n",
        "        [tf.compat.v1.keras.layers.Dense(input_dim=2, units=100, activation='relu'),\n",
        "         tf.compat.v1.keras.layers.Dense(units=classes, activation=\"softmax\")],\n",
        "        [tf.compat.v1.keras.layers.Dense(input_dim=2, units=10, activation='relu'),\n",
        "         tf.compat.v1.keras.layers.Dense(units=10, activation='relu'),\n",
        "         tf.compat.v1.keras.layers.Dense(units=classes, activation=\"softmax\")],\n",
        "        [tf.compat.v1.keras.layers.Dense(input_dim=2, units=100, activation='relu'),\n",
        "         tf.compat.v1.keras.layers.Dense(units=100, activation='relu'),\n",
        "         tf.compat.v1.keras.layers.Dense(units=classes, activation=\"softmax\")]\n",
        "    ]\n",
        "\n",
        "# Read the simple 2D dataset files\n",
        "def get_data_set(name):\n",
        "    try:\n",
        "        data = np.loadtxt(name, skiprows=0, delimiter = ' ')\n",
        "    except:\n",
        "        return None, None, None\n",
        "    np.random.shuffle(data)             # shuffle the data\n",
        "    # The data uses ROW vectors for a data point, that's what Keras assumes.\n",
        "    _, d = data.shape\n",
        "    X = data[:,0:d-1]\n",
        "    Y = data[:,d-1:d]\n",
        "    y = Y.T[0]\n",
        "    classes = set(y)\n",
        "    if classes == set([-1.0, 1.0]):\n",
        "        print('Convert from -1,1 to 0,1')\n",
        "        y = 0.5*(y+1)\n",
        "    print('Loading X', X.shape, 'y', y.shape, 'classes', set(y))\n",
        "    return X, y, len(classes)\n",
        "\n",
        "######################################################################\n",
        "# General helpers for Problems 3-5\n",
        "######################################################################\n",
        "\n",
        "class LossHistory(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.keys = ['loss', 'acc', 'val_loss', 'val_acc']\n",
        "        self.values = {}\n",
        "        for k in self.keys:\n",
        "            self.values['batch_'+k] = []\n",
        "            self.values['epoch_'+k] = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        for k in self.keys:\n",
        "            bk = 'batch_'+k\n",
        "            if k in logs:\n",
        "                self.values[bk].append(logs[k])\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        for k in self.keys:\n",
        "            ek = 'epoch_'+k\n",
        "            if k in logs:\n",
        "                self.values[ek].append(logs[k])\n",
        "\n",
        "    def plot(self, keys):\n",
        "        for key in keys:\n",
        "            plt.plot(np.arange(len(self.values[key])), np.array(self.values[key]), label=key)\n",
        "        plt.legend()\n",
        "\n",
        "'''def run_keras(X_train, y_train, X_val, y_val, X_test, y_test, layers, epochs, split=0, verbose=True):\n",
        "    # Model specification\n",
        "    model = Sequential()\n",
        "    for layer in layers:\n",
        "        model.add(layer)\n",
        "    # Define the optimization\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
        "    N = X_train.shape[0]\n",
        "    # Pick batch size\n",
        "    batch = 32 if N > 1000 else 1     # batch size\n",
        "    history = LossHistory()\n",
        "    # Fit the model\n",
        "    if X_val is None:\n",
        "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch, validation_split=split,\n",
        "                  callbacks=[history], verbose=verbose)\n",
        "    else:\n",
        "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch, validation_data=(X_val, y_val),\n",
        "                  callbacks=[history], verbose=verbose)\n",
        "    # Evaluate the model on validation data, if any\n",
        "    if X_val is not None or split > 0:\n",
        "        val_acc, val_loss = history.values['epoch_val_acc'][-1], history.values['epoch_val_loss'][-1]\n",
        "        print (\"\\nLoss on validation set:\"  + str(val_loss) + \" Accuracy on validation set: \" + str(val_acc))\n",
        "    else:\n",
        "        val_acc = None\n",
        "    # Evaluate the model on test data, if any\n",
        "    if X_test is not None:\n",
        "        test_loss, test_acc = model.evaluate(X_test, y_test, batch_size=batch)\n",
        "        print (\"\\nLoss on test set:\"  + str(test_loss) + \" Accuracy on test set: \" + str(test_acc))\n",
        "    else:\n",
        "        test_acc = None\n",
        "    return model, history, val_acc, test_acc'''\n",
        "\n",
        "\n",
        "    # Added function VMohire Sept 2024\n",
        "def run_keras(X_train, y_train, X_val, y_val, X_test, y_test, layers, epochs, split=0.25, verbose=True):\n",
        "    # Build the model\n",
        "    model = Sequential()\n",
        "    for layer in layers:\n",
        "        model.add(layer)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=32,\n",
        "                        validation_data=(X_val, y_val) if X_val is not None else None,\n",
        "                        verbose=verbose)\n",
        "\n",
        "    # Evaluate the model\n",
        "    if X_val is not None:\n",
        "        val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "    else:\n",
        "        val_loss, val_acc = None, None\n",
        "\n",
        "    if X_test is not None:\n",
        "        test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    else:\n",
        "        test_loss, test_acc = None, None\n",
        "\n",
        "    # Return the model, history, and accuracy/loss values\n",
        "    return model, history, val_acc, test_acc\n",
        "\n",
        "def dataset_paths(data_name):\n",
        "    return [\"data/data\"+data_name+\"_\"+suffix+\".csv\" for suffix in (\"train\", \"validate\", \"test\")]\n",
        "\n",
        "# The name is a string such as \"1\" or \"Xor\"\n",
        "def run_keras_2d(data_name, layers, epochs, display=True, split=0.25, verbose=True, trials=1):\n",
        "    print('Keras FC: dataset=', data_name)\n",
        "    (train_dataset, val_dataset, test_dataset) = dataset_paths(data_name)\n",
        "    # Load the datasets\n",
        "    X_train, y, num_classes = get_data_set(train_dataset)\n",
        "    X_val, y2, _ = get_data_set(val_dataset)\n",
        "    X_test, y3, _ = get_data_set(test_dataset)\n",
        "    # Categorize the labels\n",
        "    #y_train = np_utils.to_categorical(y, num_classes) # one-hot\n",
        "    y_train = utils.to_categorical(y, num_classes)   #VMohire Sept 2024\n",
        "    y_val = y_test = None\n",
        "    if X_val is not None:\n",
        "        #y_val = np_utils.to_categorical(y2, num_classes) # one-hot\n",
        "        y_val = utils.to_categorical(y2, num_classes)   #VMohire Sept 2024\n",
        "    if X_test is not None:\n",
        "        #y_test = np_utils.to_categorical(y3, num_classes) # one-hot\n",
        "        utils.to_categorical(y, num_classes)   #VMohire Sept 2024\n",
        "    val_acc, test_acc = 0, 0\n",
        "    for trial in range(trials):\n",
        "        # Reset the weights\n",
        "        # See https://github.com/keras-team/keras/issues/341\n",
        "        #session = K.get_session()\n",
        "        session = tf.compat.v1.keras.backend.get_session()\n",
        "        for layer in layers:\n",
        "            for v in layer.__dict__:\n",
        "                v_arg = getattr(layer, v)\n",
        "                if hasattr(v_arg, 'initializer'):\n",
        "                    initializer_func = getattr(v_arg, 'initializer')\n",
        "                    initializer_func.run(session=session)\n",
        "        # Run the model\n",
        "        model, history, vacc, tacc, = \\\n",
        "               run_keras(X_train, y_train, X_val, y_val, X_test, y_test, layers, epochs,\n",
        "                         split=split, verbose=verbose)\n",
        "        val_acc += vacc if vacc else 0\n",
        "        test_acc += tacc if tacc else 0\n",
        "        if display:\n",
        "            # plot classifier landscape on training data\n",
        "            plot_heat(X_train, y, model)\n",
        "            plt.title('Training data')\n",
        "            plt.show()\n",
        "            if X_test is not None:\n",
        "                # plot classifier landscape on testing data\n",
        "                plot_heat(X_test, y3, model)\n",
        "                plt.title('Testing data')\n",
        "                plt.show()\n",
        "            # Plot epoch loss\n",
        "            history.plot(['epoch_loss', 'epoch_val_loss'])\n",
        "            plt.xlabel('epoch')\n",
        "            plt.ylabel('loss')\n",
        "            plt.title('Epoch val_loss and loss')\n",
        "            plt.show()\n",
        "            # Plot epoch accuracy\n",
        "            history.plot(['epoch_acc', 'epoch_val_acc'])\n",
        "            plt.xlabel('epoch')\n",
        "            plt.ylabel('accuracy')\n",
        "            plt.title('Epoch val_acc and acc')\n",
        "            plt.show()\n",
        "    if val_acc:\n",
        "        print (\"\\nAvg. validation accuracy:\"  + str(val_acc/trials))\n",
        "    if test_acc:\n",
        "        print (\"\\nAvg. test accuracy:\"  + str(test_acc/trials))\n",
        "    return X_train, y, model\n",
        "\n",
        "######################################################################\n",
        "# Helper functions for\n",
        "# OPTIONAL: Problem 4 - Weight Sharing\n",
        "######################################################################\n",
        "\n",
        "def generate_1d_images(nsamples,image_size,prob):\n",
        "    Xs=[]\n",
        "    Ys=[]\n",
        "    for i in range(0,nsamples):\n",
        "        X=np.random.binomial(1, prob, size=image_size)\n",
        "        Y=count_objects_1d(X)\n",
        "        Xs.append(X)\n",
        "        Ys.append(Y)\n",
        "    Xs=np.array(Xs)\n",
        "    Ys=np.array(Ys)\n",
        "    return Xs,Ys\n",
        "\n",
        "\n",
        "#count the number of objects in a 1d array\n",
        "def count_objects_1d(array):\n",
        "    count=0\n",
        "    for i in range(len(array)):\n",
        "        num=array[i]\n",
        "        if num==0:\n",
        "            if i==0 or array[i-1]==1:\n",
        "                count+=1\n",
        "    return count\n",
        "\n",
        "def l1_reg(weight_matrix):\n",
        "    return 0.01 * K.sum(K.abs(weight_matrix))\n",
        "\n",
        "\n",
        "def filter_reg(weights):\n",
        "    lam=0\n",
        "    return lam* val\n",
        "\n",
        "def get_image_data_1d(tsize,image_size,prob):\n",
        "    #prob controls the density of white pixels\n",
        "    #tsize is the size of the training and test sets\n",
        "    vsize=int(0.2*tsize)\n",
        "    X_train,Y_train=generate_1d_images(tsize,image_size,prob)\n",
        "    X_val,Y_val=generate_1d_images(vsize,image_size,prob)\n",
        "    X_test,Y_test=generate_1d_images(tsize,image_size,prob)\n",
        "    #reshape the input data for the convolutional layer\n",
        "    X_train=np.expand_dims(X_train,axis=2)\n",
        "    X_val=np.expand_dims(X_val,axis=2)\n",
        "    X_test=np.expand_dims(X_test,axis=2)\n",
        "    data=(X_train,Y_train,X_val,Y_val,X_test,Y_test)\n",
        "    return data\n",
        "\n",
        "def train_neural_counter(layers,data,loss_func='mse',display=False):\n",
        "    (X_train,Y_train,X_val,Y_val,X_test,Y_test)=data\n",
        "    epochs=10\n",
        "    batch=1\n",
        "\n",
        "    model=Sequential()\n",
        "    for layer in layers:\n",
        "        model.add(layer)\n",
        "    model.summary()\n",
        "    model.compile(loss=loss_func, optimizer=Adam())\n",
        "    history = LossHistory()\n",
        "    model.fit(X_train, Y_train, epochs=epochs, batch_size=batch, validation_data=(X_val, Y_val),callbacks=[history], verbose=True)\n",
        "    err=model.evaluate(X_test,Y_test)\n",
        "    ws=model.layers[-1].get_weights()[0]\n",
        "    if display:\n",
        "        plt.plot(ws)\n",
        "        plt.show()\n",
        "    return model,err\n",
        "\n",
        "######################################################################\n",
        "# Problem 5\n",
        "######################################################################\n",
        "\n",
        "def shifted(X, shift):\n",
        "    n = X.shape[0]\n",
        "    m = X.shape[1]\n",
        "    size = m + shift\n",
        "    X_sh = np.zeros((n, size, size))\n",
        "    plt.ion()\n",
        "    for i in range(n):\n",
        "        sh1 = np.random.randint(shift)\n",
        "        sh2 = np.random.randint(shift)\n",
        "        X_sh[i, sh1:sh1+m, sh2:sh2+m] = X[i, :, :]\n",
        "        # If you want to see the shifts, uncomment\n",
        "        #plt.figure(1); plt.imshow(X[i])\n",
        "        #plt.figure(2); plt.imshow(X_sh[i])\n",
        "        #plt.show()\n",
        "        #input('Go?')\n",
        "    return X_sh\n",
        "\n",
        "def get_MNIST_data(shift=0):\n",
        "    (X_train, y1), (X_val, y2) = mnist.load_data()\n",
        "    if shift:\n",
        "        size = 28+shift\n",
        "        X_train = shifted(X_train, shift)\n",
        "        X_val = shifted(X_val, shift)\n",
        "    return (X_train, y1), (X_val, y2)\n",
        "\n",
        "# Example Usage:\n",
        "# train, validation = get_MNIST_data()\n",
        "\n",
        "def run_keras_fc_mnist(train, test, layers, epochs, split=0.1, verbose=True, trials=1):\n",
        "    (X_train, y1), (X_val, y2) = train, test\n",
        "    # Flatten the images\n",
        "    m = X_train.shape[1]\n",
        "    X_train = X_train.reshape((X_train.shape[0], m*m))\n",
        "    X_val = X_val.reshape((X_val.shape[0], m*m))\n",
        "    # Categorize the labels\n",
        "    num_classes = 10\n",
        "    y_train = np_utils.to_categorical(y1, num_classes)\n",
        "    y_val = np_utils.to_categorical(y2, num_classes)\n",
        "    # Train, use split for validation\n",
        "    val_acc, test_acc = 0, 0\n",
        "    for trial in range(trials):\n",
        "        # Reset the weights\n",
        "        # See https://github.com/keras-team/keras/issues/341\n",
        "        #session = K.get_session()\n",
        "        session = tf.compat.v1.keras.backend.get_session()\n",
        "        for layer in layers:\n",
        "            for v in layer.__dict__:\n",
        "                v_arg = getattr(layer, v)\n",
        "                if hasattr(v_arg, 'initializer'):\n",
        "                    initializer_func = getattr(v_arg, 'initializer')\n",
        "                    initializer_func.run(session=session)\n",
        "        # Run the model\n",
        "        model, history, vacc, tacc = \\\n",
        "                run_keras(X_train, y_train, X_val, y_val, None, None, layers, epochs, split=split, verbose=verbose)\n",
        "        val_acc += vacc if vacc else 0\n",
        "        test_acc += tacc if tacc else 0\n",
        "    if val_acc:\n",
        "        print (\"\\nAvg. validation accuracy:\"  + str(val_acc/trials))\n",
        "    if test_acc:\n",
        "        print (\"\\nAvg. test accuracy:\"  + str(test_acc/trials))\n",
        "\n",
        "def run_keras_cnn_mnist(train, test, layers, epochs, split=0.1, verbose=True, trials=1):\n",
        "    # Load the dataset\n",
        "    (X_train, y1), (X_val, y2) = train, test\n",
        "    # Add a final dimension indicating the number of channels (only 1 here)\n",
        "    m = X_train.shape[1]\n",
        "    X_train = X_train.reshape((X_train.shape[0], m, m, 1))\n",
        "    X_val = X_val.reshape((X_val.shape[0], m, m, 1))\n",
        "    # Categorize the labels\n",
        "    num_classes = 10\n",
        "    y_train = np_utils.to_categorical(y1, num_classes)\n",
        "    y_val = np_utils.to_categorical(y2, num_classes)\n",
        "    # Train, use split for validation\n",
        "    val_acc, test_acc = 0, 0\n",
        "    for trial in range(trials):\n",
        "        # Reset the weights\n",
        "        # See https://github.com/keras-team/keras/issues/341\n",
        "        #session = K.get_session()\n",
        "        session = tf.compat.v1.keras.backend.get_session()\n",
        "        for layer in layers:\n",
        "            for v in layer.__dict__:\n",
        "                v_arg = getattr(layer, v)\n",
        "                if hasattr(v_arg, 'initializer'):\n",
        "                    initializer_func = getattr(v_arg, 'initializer')\n",
        "                    initializer_func.run(session=session)\n",
        "        # Run the model\n",
        "        model, history, vacc, tacc = \\\n",
        "                run_keras(X_train, y_train, X_val, y_val, None, None, layers, epochs, split=split, verbose=verbose)\n",
        "        val_acc += vacc if vacc else 0\n",
        "        test_acc += tacc if tacc else 0\n",
        "    if val_acc:\n",
        "        print (\"\\nAvg. validation accuracy:\"  + str(val_acc/trials))\n",
        "    if test_acc:\n",
        "        print (\"\\nAvg. test accuracy:\"  + str(test_acc/trials))\n",
        "\n",
        "# Example usage:\n",
        "# train, validation = get_MNIST_data()\n",
        "# layers = [Dense(input_dim=???, units=???, activation='softmax')]\n",
        "# run_keras_fc_mnist(train, validation, layers, 1, split=0.1, verbose=True, trials=5)\n",
        "# Same pattern applies to the function: run_keras_cnn_mnist\n",
        "\n",
        "######################################################################\n",
        "# Plotting Functions\n",
        "######################################################################\n",
        "\n",
        "def plot_heat(X, y, model, res = 200):\n",
        "    eps = .1\n",
        "    xmin = np.min(X[:,0]) - eps; xmax = np.max(X[:,0]) + eps\n",
        "    ymin = np.min(X[:,1]) - eps; ymax = np.max(X[:,1]) + eps\n",
        "    ax = tidyPlot(xmin, xmax, ymin, ymax, xlabel = 'x', ylabel = 'y')\n",
        "    xl = np.linspace(xmin, xmax, res)\n",
        "    yl = np.linspace(ymin, ymax, res)\n",
        "    xx, yy = np.meshgrid(xl, yl, sparse=False)\n",
        "    zz = np.argmax(model.predict(np.c_[xx.ravel(), yy.ravel()]), axis=1)\n",
        "    im = ax.imshow(np.flipud(zz.reshape((res,res))), interpolation = 'none',\n",
        "                   extent = [xmin, xmax, ymin, ymax],\n",
        "                   cmap = 'viridis')\n",
        "    plt.colorbar(im)\n",
        "    for yi in set([int(_y) for _y in set(y)]):\n",
        "        color = ['r', 'g', 'b'][yi]\n",
        "        marker = ['X', 'o', 'v'][yi]\n",
        "        cl = np.where(y==yi)\n",
        "        ax.scatter(X[cl,0], X[cl,1], c = color, marker = marker, s=80,\n",
        "                   edgecolors = 'none')\n",
        "    return ax\n",
        "\n",
        "def tidyPlot(xmin, xmax, ymin, ymax, center = False, title = None,\n",
        "                 xlabel = None, ylabel = None):\n",
        "    plt.figure(facecolor=\"white\")\n",
        "    ax = plt.subplot()\n",
        "    if center:\n",
        "        ax.spines['left'].set_position('zero')\n",
        "        ax.spines['right'].set_color('none')\n",
        "        ax.spines['bottom'].set_position('zero')\n",
        "        ax.spines['top'].set_color('none')\n",
        "        ax.spines['left'].set_smart_bounds(True)\n",
        "        ax.spines['bottom'].set_smart_bounds(True)\n",
        "        ax.xaxis.set_ticks_position('bottom')\n",
        "        ax.yaxis.set_ticks_position('left')\n",
        "    else:\n",
        "        ax.spines[\"top\"].set_visible(False)\n",
        "        ax.spines[\"right\"].set_visible(False)\n",
        "        ax.get_xaxis().tick_bottom()\n",
        "        ax.get_yaxis().tick_left()\n",
        "    eps = .05\n",
        "    plt.xlim(xmin-eps, xmax+eps)\n",
        "    plt.ylim(ymin-eps, ymax+eps)\n",
        "    if title: ax.set_title(title)\n",
        "    if xlabel: ax.set_xlabel(xlabel)\n",
        "    if ylabel: ax.set_ylabel(ylabel)\n",
        "    return ax\n",
        "\n",
        "def plot_separator(ax, th, th_0):\n",
        "    xmin, xmax = ax.get_xlim()\n",
        "    ymin,ymax = ax.get_ylim()\n",
        "    pts = []\n",
        "    eps = 1.0e-6\n",
        "    # xmin boundary crossing is when xmin th[0] + y th[1] + th_0 = 0\n",
        "    # that is, y = (-th_0 - xmin th[0]) / th[1]\n",
        "    if abs(th[1,0]) > eps:\n",
        "        pts += [np.array([x, (-th_0 - x * th[0,0]) / th[1,0]]) \\\n",
        "                                                        for x in (xmin, xmax)]\n",
        "    if abs(th[0,0]) > 1.0e-6:\n",
        "        pts += [np.array([(-th_0 - y * th[1,0]) / th[0,0], y]) \\\n",
        "                                                         for y in (ymin, ymax)]\n",
        "    in_pts = []\n",
        "    for p in pts:\n",
        "        if (xmin-eps) <= p[0] <= (xmax+eps) and \\\n",
        "           (ymin-eps) <= p[1] <= (ymax+eps):\n",
        "            duplicate = False\n",
        "            for p1 in in_pts:\n",
        "                if np.max(np.abs(p - p1)) < 1.0e-6:\n",
        "                    duplicate = True\n",
        "            if not duplicate:\n",
        "                in_pts.append(p)\n",
        "    if in_pts and len(in_pts) >= 2:\n",
        "        # Plot separator\n",
        "        vpts = np.vstack(in_pts)\n",
        "        ax.plot(vpts[:,0], vpts[:,1], 'k-', lw=2)\n",
        "        # Plot normal\n",
        "        vmid = 0.5*(in_pts[0] + in_pts[1])\n",
        "        scale = np.sum(th*th)**0.5\n",
        "        diff = in_pts[0] - in_pts[1]\n",
        "        dist = max(xmax-xmin, ymax-ymin)\n",
        "        vnrm = vmid + (dist/10)*(th.T[0]/scale)\n",
        "        vpts = np.vstack([vmid, vnrm])\n",
        "        ax.plot(vpts[:,0], vpts[:,1], 'k-', lw=2)\n",
        "        # Try to keep limits from moving around\n",
        "        ax.set_xlim((xmin, xmax))\n",
        "        ax.set_ylim((ymin, ymax))\n",
        "    else:\n",
        "        print('Separator not in plot range')\n",
        "\n",
        "def plot_decision(data, cl, diff=False):\n",
        "    layers = archs(cl)[0]\n",
        "    X, y, model = run_keras_2d(data, layers, 10, trials=1, verbose=False, display=False)\n",
        "    ax = plot_heat(X,y,model)\n",
        "    W = layers[0].get_weights()[0]\n",
        "    W0 = layers[0].get_weights()[1].reshape((cl,1))\n",
        "    if diff:\n",
        "        for i,j in list(itertools.combinations(range(cl),2)):\n",
        "            plot_separator(ax, W[:,i:i+1] - W[:,j:j+1], W0[i:i+1,:] - W0[j:j+1,:])\n",
        "    else:\n",
        "        for i in range(cl):\n",
        "            plot_separator(ax, W[:,i:i+1], W0[i:i+1,:])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "79NIEopsLzr2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_YWbWX47_9Tr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1ca8d46-9c35-4200-d2cf-37ceb87eae37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras FC: dataset= 3\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy:0.925000011920929\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 1.63713564e+00, -2.17432334e+00],\n",
              "        [-1.24643954e+00,  1.49863868e-01],\n",
              "        [ 1.63904127e-01,  8.16453466e-01],\n",
              "        [ 1.43637773e+00,  8.88204900e-01],\n",
              "        [-1.03777338e+00,  8.71249143e-01],\n",
              "        [-1.07724068e+00, -9.62656450e-01],\n",
              "        [ 1.32115979e+00,  1.08700327e+00],\n",
              "        [ 1.15960716e+00, -1.52652878e+00],\n",
              "        [-2.81881752e-01, -8.84938507e-01],\n",
              "        [-8.66231054e-01,  1.14435380e+00],\n",
              "        [ 2.50246022e-01,  1.16369383e+00],\n",
              "        [-9.00916800e-01,  1.09612133e+00],\n",
              "        [-2.91308358e-01, -1.32297240e+00],\n",
              "        [-2.43518124e+00, -1.33467556e+00],\n",
              "        [ 1.34999576e+00,  5.94932219e-01],\n",
              "        [-6.36989768e-01,  8.95222556e-01],\n",
              "        [ 1.10961771e+00, -1.71291812e+00],\n",
              "        [ 1.30783537e+00,  8.72599493e-01],\n",
              "        [-1.60869714e+00,  1.04500028e+00],\n",
              "        [-2.48121610e+00, -1.36699313e+00],\n",
              "        [-2.69267911e-01, -2.13216450e-02],\n",
              "        [ 2.69701928e-01, -3.44847643e-01],\n",
              "        [ 5.56595729e-01, -9.68298445e-01],\n",
              "        [-1.33650871e-01, -9.32036395e-01],\n",
              "        [ 3.01511975e-01,  6.02119507e-01],\n",
              "        [ 4.69102326e-01,  1.00753548e+00],\n",
              "        [ 8.09768501e-01,  1.25234471e+00],\n",
              "        [-1.74711514e-01, -2.36960028e+00],\n",
              "        [-5.97566850e-01, -2.36224337e-01],\n",
              "        [ 9.64624265e-01, -1.72598657e+00],\n",
              "        [-1.80086374e-01, -1.62109929e+00],\n",
              "        [-3.13859609e-01,  1.08169038e+00],\n",
              "        [ 1.25803015e+00, -1.32034853e+00],\n",
              "        [ 6.12599632e-01, -6.08357600e-01],\n",
              "        [-2.21627523e+00, -1.43020809e+00],\n",
              "        [ 8.73755570e-01,  7.88411817e-01],\n",
              "        [-9.17862713e-01, -1.28247051e+00],\n",
              "        [-1.09673065e-01, -9.38314921e-01],\n",
              "        [-6.50672262e-01,  1.22474875e+00],\n",
              "        [-8.72351116e-01,  6.33199395e-01],\n",
              "        [-1.74344996e+00,  9.97776869e-01],\n",
              "        [ 5.10668351e-01,  1.43624362e+00],\n",
              "        [ 3.19006021e-01,  7.05395797e-01],\n",
              "        [-1.45586427e+00,  1.06759553e+00],\n",
              "        [ 4.45047706e-01, -8.43962960e-01],\n",
              "        [-1.00235028e+00, -7.98731516e-01],\n",
              "        [ 3.07141783e-01, -5.24623805e-01],\n",
              "        [ 7.34556744e-01,  1.12729093e+00],\n",
              "        [-3.44366268e-01, -1.36434668e+00],\n",
              "        [ 1.62752185e-01,  9.21716731e-01],\n",
              "        [ 1.27208381e-01,  1.33817514e+00],\n",
              "        [ 5.31870945e-01,  6.12922734e-03],\n",
              "        [ 2.88990304e-01, -3.04575699e-01],\n",
              "        [-1.92028794e-01,  6.18618137e-01],\n",
              "        [ 1.53031689e+00, -1.42527722e+00],\n",
              "        [-1.34882284e+00, -2.41377262e+00],\n",
              "        [-1.93393136e+00,  1.03763746e+00],\n",
              "        [-4.54727548e-01,  8.28009080e-01],\n",
              "        [-6.78200836e-02, -7.11586415e-01],\n",
              "        [ 2.82678103e-01, -1.52199667e+00],\n",
              "        [ 5.25962696e-01, -2.00777506e+00],\n",
              "        [ 2.70581984e-01,  8.32604236e-01],\n",
              "        [ 8.29727566e-01, -1.71167084e+00],\n",
              "        [ 1.16818754e+00, -4.06042985e-01],\n",
              "        [ 6.06949123e-01, -1.92695095e+00],\n",
              "        [ 3.39483309e-01, -1.53777198e+00],\n",
              "        [-5.76529670e-01, -9.03522018e-01],\n",
              "        [-5.14657260e-01,  1.25692322e+00],\n",
              "        [-1.12435698e+00, -4.30035232e-01],\n",
              "        [-6.11094774e-01, -1.75893850e+00],\n",
              "        [ 2.68572445e-01,  9.19915554e-01],\n",
              "        [-1.05234752e+00, -1.19191135e+00],\n",
              "        [-1.55859064e-01, -9.93383540e-01],\n",
              "        [ 1.45250817e+00, -1.98062295e+00],\n",
              "        [ 4.51483402e-01,  6.79791225e-01],\n",
              "        [ 1.83689989e-01, -2.78607469e-01],\n",
              "        [ 3.59507195e-01,  7.53390980e-01],\n",
              "        [ 7.76414305e-01, -7.84042128e-01],\n",
              "        [-1.10963737e+00, -7.21441528e-01],\n",
              "        [-1.10192400e-01, -1.62969750e+00],\n",
              "        [ 1.03397734e+00,  9.94625504e-01],\n",
              "        [-1.67530495e+00,  1.03949695e+00],\n",
              "        [ 3.53483649e-01, -1.04684497e+00],\n",
              "        [-1.17264210e+00, -2.10489761e+00],\n",
              "        [ 4.86250026e-01, -1.56351910e+00],\n",
              "        [-8.19510632e-01,  9.16036256e-01],\n",
              "        [ 8.71930256e-01,  9.44092465e-01],\n",
              "        [ 1.20849816e+00, -5.16103953e-01],\n",
              "        [ 9.33095520e-02, -1.34614077e+00],\n",
              "        [-3.90186213e-01,  8.66811674e-01],\n",
              "        [-2.84390861e-01,  1.28516740e-01],\n",
              "        [-2.50691573e+00, -5.61748430e-01],\n",
              "        [-6.74971949e-01,  1.23686691e+00],\n",
              "        [ 2.04669999e+00, -1.01775787e+00],\n",
              "        [-1.55601351e-01, -4.15193470e-01],\n",
              "        [ 5.75533547e-01, -1.77035812e+00],\n",
              "        [-5.89184200e-01, -7.13968242e-01],\n",
              "        [-1.28541366e+00,  8.89537258e-01],\n",
              "        [-1.94083970e-01,  1.25165885e+00],\n",
              "        [-1.11206353e+00, -1.69493671e+00],\n",
              "        [ 1.24289721e+00,  3.87016394e-01],\n",
              "        [-8.88840612e-01,  9.57599953e-01],\n",
              "        [ 1.84385841e+00, -1.19911559e+00],\n",
              "        [-1.79255442e-01,  9.04111402e-01],\n",
              "        [-5.30929289e-01,  1.37027026e+00],\n",
              "        [-1.18822392e+00,  6.05652299e-01],\n",
              "        [ 4.70360399e-01,  1.05361224e+00],\n",
              "        [ 3.11442245e-01,  1.10354795e+00],\n",
              "        [-1.91133900e-01, -1.35711833e+00],\n",
              "        [ 3.31873096e-01,  1.16156475e+00],\n",
              "        [ 8.49637322e-01, -1.29314599e-01],\n",
              "        [-6.21091558e-03, -1.53802337e+00],\n",
              "        [-7.93915442e-02,  5.93908225e-01],\n",
              "        [ 9.04075035e-01, -4.19988897e-01],\n",
              "        [ 2.02584111e+00,  4.63471587e-03],\n",
              "        [-1.22825580e+00,  6.62205401e-01],\n",
              "        [ 1.17325348e-01, -1.47735832e+00],\n",
              "        [ 1.15606866e-01,  6.01664637e-01],\n",
              "        [ 1.51880196e-01, -1.13827324e+00],\n",
              "        [ 3.59454556e-02, -4.94537729e-01],\n",
              "        [ 1.00844652e+00,  1.30543156e+00],\n",
              "        [ 1.26251243e+00, -1.33798222e+00],\n",
              "        [-1.56985091e+00,  1.81721816e-01],\n",
              "        [ 1.09315404e+00,  1.25350731e+00],\n",
              "        [ 5.05644320e-01, -1.31135357e+00],\n",
              "        [-4.93084898e-01,  7.83595885e-01],\n",
              "        [-9.49084956e-01,  1.13001262e+00],\n",
              "        [ 7.15681337e-01, -7.61277410e-02],\n",
              "        [ 6.44314599e-01,  9.56992667e-01],\n",
              "        [-9.66556680e-02,  1.17882331e+00],\n",
              "        [ 5.01637382e-02, -1.86205461e-01],\n",
              "        [ 1.03949361e+00, -9.53568987e-01],\n",
              "        [ 1.02885868e+00,  1.03520193e+00],\n",
              "        [ 4.82659146e-01, -1.18185819e+00],\n",
              "        [ 1.34258818e+00,  9.03842338e-01],\n",
              "        [ 2.89462527e-01,  8.06161465e-01],\n",
              "        [-1.61810048e-01,  1.17513901e+00],\n",
              "        [ 2.18459391e+00,  9.08547003e-01],\n",
              "        [-3.90784151e-01,  9.14456623e-01],\n",
              "        [ 4.04713428e-01,  1.39722625e+00],\n",
              "        [-1.30422169e-01, -8.92018698e-01],\n",
              "        [ 2.56817317e+00,  1.00347317e+00],\n",
              "        [-1.47834412e+00, -4.58217735e-01],\n",
              "        [-3.55639647e-02,  1.26847710e+00],\n",
              "        [-6.40393302e-02, -2.09756863e-01],\n",
              "        [ 4.42338898e-01, -7.90399307e-01],\n",
              "        [ 1.13615505e+00,  9.34159707e-01],\n",
              "        [ 1.49791013e+00, -9.05810242e-01],\n",
              "        [ 1.52537231e+00, -7.05544863e-01],\n",
              "        [-1.77364406e-01, -9.63714670e-01],\n",
              "        [-1.48038581e+00,  1.05573465e+00],\n",
              "        [-9.89379259e-01,  1.43420494e+00],\n",
              "        [-6.11864335e-01, -3.04394204e-01],\n",
              "        [ 3.70332689e-01, -2.35719846e+00],\n",
              "        [-1.91870264e+00, -9.72408379e-01],\n",
              "        [ 1.22280969e+00, -6.34011641e-01],\n",
              "        [ 7.50266447e-01,  4.23964853e-01],\n",
              "        [ 6.37641117e-01,  9.24521718e-01],\n",
              "        [-4.61139539e-01, -7.41682510e-01],\n",
              "        [ 6.13678993e-01, -1.17730862e+00],\n",
              "        [-1.60947813e+00,  1.00125605e+00],\n",
              "        [-4.22725606e-01, -2.40543697e+00],\n",
              "        [-2.58962352e-01,  9.36627693e-01],\n",
              "        [-8.71517413e-02, -1.67901807e+00],\n",
              "        [ 1.65294623e+00, -1.25610734e+00],\n",
              "        [-1.00263655e+00,  6.72766167e-01],\n",
              "        [ 1.25901523e+00,  1.11166169e+00],\n",
              "        [-6.46615721e-02,  7.29392228e-01],\n",
              "        [ 6.21830757e-01,  1.03110956e+00],\n",
              "        [-1.23416151e+00,  1.19439315e+00],\n",
              "        [ 2.97793904e-01,  9.73662817e-01],\n",
              "        [ 6.10165824e-01, -7.02758659e-01],\n",
              "        [-1.59015462e+00,  7.44042740e-02],\n",
              "        [ 9.33550381e-01, -2.31296466e-01],\n",
              "        [ 8.70593920e-02,  1.16291413e+00],\n",
              "        [ 2.84183705e-01,  9.97209950e-01],\n",
              "        [-2.66744646e-01,  1.24707267e+00],\n",
              "        [-2.62825570e+00, -1.17227297e+00],\n",
              "        [-7.36954920e-01, -1.99090996e+00],\n",
              "        [-5.01996284e-02,  9.92626678e-01],\n",
              "        [ 5.14712326e-01,  1.11414252e+00],\n",
              "        [ 2.22795714e+00,  1.13783995e+00],\n",
              "        [ 4.81312605e-01,  9.71724691e-01],\n",
              "        [ 2.27937491e+00, -5.31454264e-01],\n",
              "        [-7.59563291e-01, -9.90655407e-01],\n",
              "        [-1.48656535e+00,  7.84957559e-01],\n",
              "        [-1.40386913e+00, -1.02071773e+00],\n",
              "        [-1.21620968e+00,  6.83049065e-01],\n",
              "        [ 3.60688993e-01, -1.41913281e+00],\n",
              "        [-1.24458639e+00,  7.30610549e-01],\n",
              "        [-1.42672828e+00, -1.68955108e+00],\n",
              "        [ 2.83963318e-01,  1.12920018e+00],\n",
              "        [-9.22451178e-01,  1.55938011e+00],\n",
              "        [-5.62743687e-01,  1.05045366e+00],\n",
              "        [ 7.26888772e-01,  1.01551074e+00],\n",
              "        [ 2.97567420e-02, -1.70729600e+00],\n",
              "        [-1.69731484e-02, -1.73171939e+00],\n",
              "        [-2.79335783e-01, -8.87909018e-01],\n",
              "        [-4.83400521e-01,  5.84297393e-01],\n",
              "        [-6.24272716e-01,  1.25215523e+00],\n",
              "        [-4.21253088e-01, -8.18917818e-01],\n",
              "        [ 1.61815412e+00, -1.41098154e+00],\n",
              "        [ 3.56311070e-01, -1.83422288e+00],\n",
              "        [-1.29386870e+00,  8.96543019e-01],\n",
              "        [-1.80173222e-01,  8.91152061e-01],\n",
              "        [ 6.65228620e-01,  1.05274437e+00],\n",
              "        [ 4.74916742e-01, -1.14933559e+00],\n",
              "        [-5.98009083e-02,  8.22694316e-01],\n",
              "        [ 1.50096157e+00, -1.67580194e+00],\n",
              "        [ 8.25923398e-01,  1.33663561e+00],\n",
              "        [-7.19309633e-01, -9.10266737e-01],\n",
              "        [-6.44300389e-01,  1.14495920e+00],\n",
              "        [ 4.51101916e-01,  1.05104320e+00],\n",
              "        [ 4.20037118e-01,  1.03254396e+00],\n",
              "        [-1.40281568e+00, -9.50144300e-01],\n",
              "        [ 1.55592533e+00,  9.77496170e-01],\n",
              "        [ 1.80089979e-01,  8.68041199e-01],\n",
              "        [ 1.07484879e+00,  8.23433889e-01],\n",
              "        [-7.97818459e-01,  1.73665182e-01],\n",
              "        [-1.66460869e+00, -9.50342075e-01],\n",
              "        [ 7.24363038e-01, -3.74497572e-01],\n",
              "        [-1.55593397e+00,  1.54091974e+00],\n",
              "        [ 7.17487011e-01,  1.40977888e+00],\n",
              "        [-5.12638604e-01, -1.66997181e+00],\n",
              "        [-1.45236904e+00,  4.70368522e-01],\n",
              "        [ 1.07186791e+00, -6.00332252e-01],\n",
              "        [-7.03010715e-01, -8.36794524e-01],\n",
              "        [-1.44035415e+00,  1.00674819e+00],\n",
              "        [-6.74156049e-01,  8.03037965e-01],\n",
              "        [ 5.35367865e-01,  1.19632359e+00],\n",
              "        [-5.66103130e-02, -1.74011165e+00],\n",
              "        [-1.78366045e-01,  1.05159727e+00],\n",
              "        [ 2.97069152e-01, -1.18341697e+00],\n",
              "        [ 1.53758454e+00,  4.26999405e-01],\n",
              "        [ 1.92377126e-01, -1.50177035e-01],\n",
              "        [ 1.25180445e+00, -1.31323403e+00],\n",
              "        [-6.09169793e-01,  1.21864793e+00],\n",
              "        [ 9.82494282e-01, -1.33938777e+00],\n",
              "        [-5.15713362e-01, -2.05668156e+00],\n",
              "        [-3.73398803e-02, -1.92251617e+00],\n",
              "        [-7.32381388e-01, -3.16439954e-01],\n",
              "        [-2.19315340e-01,  1.31915105e+00],\n",
              "        [ 3.80551397e+00,  1.49137866e-01],\n",
              "        [-1.29854547e+00, -1.78213954e+00],\n",
              "        [-8.83476976e-01,  1.09421850e+00],\n",
              "        [-1.37496427e+00, -2.14360387e+00],\n",
              "        [-9.28369699e-01,  1.09835499e+00],\n",
              "        [-6.04300483e-01, -1.27031016e+00],\n",
              "        [ 6.27158849e-02,  1.13288371e+00],\n",
              "        [ 1.34281872e+00, -1.98908865e+00],\n",
              "        [-3.92251702e-01, -5.99675561e-01],\n",
              "        [-8.76150821e-01,  9.38246134e-01],\n",
              "        [ 3.27494621e+00, -3.78799528e-01],\n",
              "        [-6.07685719e-01, -9.00295674e-01],\n",
              "        [ 4.96845017e-01,  8.59549327e-01],\n",
              "        [ 5.41193475e-01, -1.16136205e+00],\n",
              "        [ 3.71876077e-01,  1.20938305e+00],\n",
              "        [ 1.61892082e-02,  7.50985464e-01],\n",
              "        [-5.33350199e-01, -7.01342176e-01],\n",
              "        [-2.77688414e-01, -7.44748537e-01],\n",
              "        [-1.26693058e-01, -7.50666180e-01],\n",
              "        [-6.25363136e-01, -2.16919689e+00],\n",
              "        [-9.67562269e-02, -1.04634812e+00],\n",
              "        [-5.62944237e-01, -1.81517397e+00],\n",
              "        [-2.80759883e-01, -6.54796310e-01],\n",
              "        [-3.38696894e-01,  2.09506699e-01],\n",
              "        [ 6.42911514e-01,  9.43444347e-01],\n",
              "        [ 7.10252376e-01,  1.10546805e+00],\n",
              "        [-1.72375519e+00, -7.07488608e-01],\n",
              "        [-2.78095935e+00,  1.33528844e+00],\n",
              "        [-4.98048222e-01, -2.05324570e+00],\n",
              "        [ 4.17050342e-01,  1.06947274e+00],\n",
              "        [ 1.03489991e+00,  1.19767297e+00],\n",
              "        [-8.98607781e-01,  1.32135061e+00],\n",
              "        [-9.10797208e-01, -1.51408134e+00],\n",
              "        [ 1.44416641e+00,  3.36156387e-01],\n",
              "        [-1.47211524e-01, -6.12836186e-01],\n",
              "        [ 4.82131302e-01, -7.66786885e-01],\n",
              "        [ 3.76946605e-03, -2.19287900e+00],\n",
              "        [ 6.91740501e-01,  9.32466520e-01],\n",
              "        [-9.26586783e-01,  2.04149817e+00],\n",
              "        [-2.60818351e-02,  1.01596097e+00],\n",
              "        [-6.53755185e-01,  1.22121044e+00],\n",
              "        [ 1.99083423e+00,  7.39232662e-01],\n",
              "        [ 2.33610938e-02, -1.84518665e+00],\n",
              "        [ 7.74771870e-01, -1.12994088e+00],\n",
              "        [ 1.24379850e+00, -1.24186239e+00],\n",
              "        [ 1.51944832e+00,  6.69433159e-01],\n",
              "        [-3.27830527e-01,  1.18556267e+00],\n",
              "        [-2.87826838e-01,  8.75110161e-01],\n",
              "        [ 1.12891929e-01,  9.84968701e-01],\n",
              "        [-3.98901569e-01, -1.37282347e+00],\n",
              "        [-1.25241081e-01,  7.65571558e-01],\n",
              "        [ 2.40553070e-01,  7.52439524e-01],\n",
              "        [ 1.56110391e+00, -4.70849410e-01],\n",
              "        [ 7.87116585e-01, -5.48711063e-01],\n",
              "        [-3.12358157e-01, -1.47095439e+00],\n",
              "        [-1.02646091e+00,  7.30186986e-01],\n",
              "        [ 1.10922347e+00, -1.68327194e+00],\n",
              "        [-7.36329438e-01,  8.31344915e-01],\n",
              "        [ 2.01124258e+00, -6.50151870e-01],\n",
              "        [ 3.38379307e-01,  1.31134144e+00],\n",
              "        [-5.09257270e-01,  1.47036827e+00],\n",
              "        [ 7.44323809e-01, -1.11690801e+00],\n",
              "        [ 2.15120831e-01, -1.07328215e+00],\n",
              "        [ 1.99009149e+00,  9.04658862e-01],\n",
              "        [-1.14914412e-01, -1.66416399e-01],\n",
              "        [ 1.47028284e+00, -1.02889795e+00],\n",
              "        [ 6.65546340e-01, -4.87610678e-01],\n",
              "        [ 9.05983584e-01,  8.39840174e-01],\n",
              "        [-2.09114448e-01,  4.01341583e-01],\n",
              "        [-8.60042024e-01,  6.82399393e-01],\n",
              "        [-1.64588447e+00, -1.79336505e+00],\n",
              "        [ 7.82625350e-02,  7.77665351e-01],\n",
              "        [ 3.05757245e+00,  8.02533863e-02],\n",
              "        [-3.44555998e-01,  4.75899767e-03],\n",
              "        [-1.95634261e-02,  1.08597651e+00],\n",
              "        [-9.78487004e-01,  1.33753667e+00],\n",
              "        [-2.06423656e+00, -1.49811482e+00],\n",
              "        [ 1.02194219e+00, -5.46483705e-01],\n",
              "        [-8.55522699e-01, -4.78157321e-01],\n",
              "        [-6.57027257e-01,  1.04703625e+00],\n",
              "        [-1.10907769e+00,  6.14530338e-01],\n",
              "        [-1.10877497e+00,  1.14858995e+00],\n",
              "        [ 4.28358501e-01, -1.10757364e+00],\n",
              "        [-1.15840553e+00,  1.15352059e+00],\n",
              "        [ 4.10510520e-01, -5.62003310e-01],\n",
              "        [ 1.49376800e-01,  6.48015791e-01],\n",
              "        [-1.14506636e+00, -6.01617601e-01],\n",
              "        [ 8.37403896e-01,  7.07465258e-01],\n",
              "        [ 6.44335216e-01, -9.07492218e-01],\n",
              "        [ 1.98167116e-01,  1.19834281e+00],\n",
              "        [ 1.24118132e-01, -1.30177445e+00],\n",
              "        [-1.54098934e+00, -1.19598653e+00],\n",
              "        [-2.48854241e+00,  6.00533278e-01],\n",
              "        [ 9.22557925e-01,  7.22022394e-01],\n",
              "        [-4.73362117e-01,  5.83668048e-01],\n",
              "        [-9.51855250e-01, -2.25623806e+00],\n",
              "        [ 1.62749494e+00, -1.17694401e+00],\n",
              "        [-1.29008702e-01, -6.50680800e-01],\n",
              "        [ 3.17664339e-01,  1.14073734e+00],\n",
              "        [-1.27959872e-01,  1.42780257e+00],\n",
              "        [-6.38776473e-01, -1.49137041e+00],\n",
              "        [ 6.82230917e-01,  1.43235646e+00],\n",
              "        [-7.02131498e-01, -6.29810247e-01],\n",
              "        [ 2.74061755e-02, -1.06785991e+00],\n",
              "        [ 4.61412128e-01,  1.62721884e+00],\n",
              "        [ 7.58980601e-01,  1.17926749e+00],\n",
              "        [-1.05960887e+00,  1.27313945e+00],\n",
              "        [ 5.93103644e-01,  1.20379038e+00],\n",
              "        [-6.37157920e-01, -4.27618581e-01],\n",
              "        [-5.10468330e-01,  7.41753970e-01],\n",
              "        [ 1.17643799e+00, -7.50069105e-02],\n",
              "        [ 1.40697557e+00,  8.38761777e-01],\n",
              "        [-1.47108290e+00,  9.47191900e-01],\n",
              "        [-1.54337318e+00, -5.27867198e-01],\n",
              "        [-9.70534473e-01,  1.13151763e+00],\n",
              "        [-1.07412296e-01,  1.18497910e+00],\n",
              "        [-8.19227913e-01,  1.13638010e+00],\n",
              "        [ 1.55798065e-01,  9.80926148e-01],\n",
              "        [-2.07979093e+00,  3.40368771e-01],\n",
              "        [-1.89499918e-01,  8.55965739e-01],\n",
              "        [ 8.65776779e-01, -1.21762329e+00],\n",
              "        [-9.03762539e-01, -1.97830405e+00],\n",
              "        [ 6.97383772e-01, -2.26678389e+00],\n",
              "        [-1.18857664e+00,  1.33689522e+00],\n",
              "        [-1.02974722e+00,  8.08029008e-01],\n",
              "        [ 2.52094708e+00,  1.11913471e+00],\n",
              "        [-8.20603757e-01,  7.74998455e-01],\n",
              "        [ 7.70115634e-01,  7.80058089e-01],\n",
              "        [ 7.74967979e-01, -5.45248881e-02],\n",
              "        [-9.15863874e-01,  1.16368824e+00],\n",
              "        [ 1.05421974e+00, -1.32045158e+00],\n",
              "        [-7.65561520e-01,  1.13055983e+00],\n",
              "        [ 2.98144973e-01,  5.57058930e-01],\n",
              "        [-4.72235332e-02,  1.12898458e+00],\n",
              "        [-1.14015107e+00,  6.75329607e-01],\n",
              "        [-8.59917131e-01, -7.74332383e-01],\n",
              "        [ 1.10434286e+00, -1.11628861e+00],\n",
              "        [-9.45670383e-01,  2.91358459e-01],\n",
              "        [ 1.64094544e+00, -7.78994384e-01],\n",
              "        [-4.14832677e-01, -7.61685543e-01],\n",
              "        [ 1.65836601e-01,  1.04371696e+00],\n",
              "        [-5.02895716e-01,  1.03914579e+00],\n",
              "        [-2.69641336e-01, -1.31882248e+00],\n",
              "        [-1.00421449e+00,  9.21219259e-01],\n",
              "        [-9.19477385e-01, -8.83574263e-01],\n",
              "        [ 1.08570167e+00, -9.29783088e-01],\n",
              "        [ 1.43609074e+00,  5.39197880e-01],\n",
              "        [-1.56887718e+00,  1.58366785e+00],\n",
              "        [ 3.43319427e-01, -1.58022728e+00],\n",
              "        [ 9.89600289e-01,  1.26694159e+00],\n",
              "        [ 1.29299584e+00,  1.13473841e+00],\n",
              "        [ 1.66128608e+00,  1.59085862e+00],\n",
              "        [ 7.14038234e-01,  1.02249603e+00],\n",
              "        [-5.68201865e-01,  9.97233331e-01],\n",
              "        [-1.06101136e+00,  9.01626186e-01],\n",
              "        [-9.97925058e-01,  7.41648174e-01],\n",
              "        [-3.23073838e-01, -1.53094630e+00],\n",
              "        [-2.94792699e-01, -6.86119747e-01]]),\n",
              " array([0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
              "        1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
              "        0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
              "        1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
              "        0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "        0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
              "        1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
              "        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
              "        1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
              "        1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
              "        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
              "        1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
              "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
              "        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
              "        1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
              "        0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
              "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "        1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
              "        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 0., 0.]),\n",
              " <keras.engine.sequential.Sequential at 0x79b4a4209960>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#example of run_kfrom tensorflow.compat.v1.keras.layers\n",
        "import tensorflow as tf\n",
        "\n",
        "layer1 = tf.compat.v1.keras.layers.Dense(units=3, activation='relu', use_bias=False)\n",
        "#layer1 = keras.layers.Dense(units=3, activation='relu', use_bias=False)\n",
        "run_keras_2d(\"3\", archs(2)[0], 10, split=0.5, display=False, verbose=False, trials=1)\n",
        "#run_keras_2d_vm(\"3\", archs(2)[0], 10, split=0.5, display=False, verbose=False, trials=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh4u39OCjLza"
      },
      "source": [
        "# Weight sharing (OPTIONAL)\n",
        "\n",
        "** Note: You can click the arrow on the left of this text block to collapse/expand this optional section and all its code blocks **\n",
        "\n",
        "In the lab we designed a CNN that can count the number of objects in 1 dimensional images, where each black pixel is represented by a value of 0 and each white pixel is represented by a value of 1. Recall that an object is a consecutive sequence of black pixels ($0$'s). For example, the sequence $0100110$ contains three objects.\n",
        "\n",
        "Here we want to see how hard/easy it is to train such a network from data.  Our network architecture will be as follows:\n",
        "\n",
        "* The first layer is convolutional and you will implement it using the Keras `Conv1D` function, with a kernel of size 2 and stride of 1 with ReLu activation.\n",
        "\n",
        "* The second layer is a fully connected `Dense` layer which has a scalar output.\n",
        "\n",
        "Here is sample usage of the `Conv1D` and`Dense` layers.\n",
        "\n",
        "`layer1=keras.layers.Conv1D(filters=?, kernel_size=?, strides=?,use_bias=False, activation=?, batch_size=1, input_shape=?, padding='same')`\n",
        "\n",
        "`Dense(units=?, activation=?, use_bias=False)`\n",
        "\n",
        "You need to fill in the parameters marked with `?` based on the problem specifications. Note also that in Keras, depending on your implementation, you may be forced to use *three* layers to implement such a network, where one intermediary `Flatten` layer is used to flatten the output of the convolutional layer, before being passed to the dense layer.\n",
        "\n",
        "Refer to the <a href=\"https://keras.io/layers/convolutional/\">Conv 1D</a>, <a href=\"https://keras.io/layers/core/\">Dense</a> and <a href=\"https://keras.io/layers/core/#flatten\">Flatten</a> descriptions in the Keras documentation to see the available parameter options.\n",
        "\n",
        "In this exercise, we fix the structure and want to learn the best combination of weights from data. In the homework code, we have provided functions `train_neural_counter` and `get_image_data_1d`. You can use them to generate data and train the above neural network in Keras to answer the following questions. We assume that the images in our data set are randomly generated. The probability of a pixel being white is $0.1$. We work with mean squared error as the loss function for this problem. We have provided template code which you can fill in, to perform the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKa8iMv_j3ek"
      },
      "source": [
        "<b>4B)</b> What is (approximately) the expected loss of the network on $1024\\times 1$ images if the convolutional layer is an averaging filter and second layer is the sum function (without a bias term)? (Note that you can answer the question theoretically or through coding, depending on your preference.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKxedp-qFXJe"
      },
      "outputs": [],
      "source": [
        "#from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oKPcB588ok8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e068c872-6997-48c3-b872-1a37cbe59db3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 5ms/step - loss: 100.7885\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100.78849792480469"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Code template if you would like to check 4B) through code\n",
        "\n",
        "imsize = 1024\n",
        "prob_white = 0.1\n",
        "\n",
        "num_filters = 1  # Your code\n",
        "kernel_size = 2  # Your code\n",
        "strides = 1  # Your code\n",
        "activation_conv = 'relu'  # Your code\n",
        "\n",
        "(X_train,Y_train,X_val,Y_val,X_test,Y_test) = get_image_data_1d(1000,imsize,prob_white)\n",
        "\n",
        "layer1=keras.layers.Conv1D(filters=num_filters, kernel_size=kernel_size, \\\n",
        "       strides=strides, use_bias=False, activation=activation_conv, batch_size=1, input_shape=(imsize,1), padding='same')\n",
        "\n",
        "activation_dense = 'linear'  # Your code\n",
        "num_units = 1  # Your code\n",
        "layer3=Dense(units=num_units, activation=activation_dense, use_bias=False)\n",
        "\n",
        "layers=[layer1,Flatten(),layer3]\n",
        "\n",
        "# This is how we create the model using our layers\n",
        "model=Sequential()\n",
        "for layer in layers:\n",
        "    model.add(layer)\n",
        "\n",
        "model.compile(loss='mse', optimizer=Adam())\n",
        "\n",
        "# Set the weights of the layers to desired values\n",
        "# We give you the lines to use for this part\n",
        "model.layers[0].set_weights([np.array([1/2,1/2]).reshape(2,1,1)])\n",
        "model.layers[-1].set_weights([np.ones(imsize).reshape(imsize,1)])\n",
        "\n",
        "model.evaluate(X_test,Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js3OYsbwj7Ms"
      },
      "source": [
        "<b>4C)</b> Now suppose we add a bias term of $-10$ to the last layer. What is (approximately) the expected quadratic loss? (Note that you can answer the question theoretically or through coding, depending on your preference.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AKynxhF1klga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a6d6289-7b93-4ab2-f727-718bb29dde91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 5ms/step - loss: 13.7128\n",
            "Test Loss: 13.712750434875488\n"
          ]
        }
      ],
      "source": [
        "# Edit code from 4B) with the bias\n",
        "\n",
        "# Parameters\n",
        "imsize = 1024\n",
        "prob_white = 0.1\n",
        "\n",
        "num_filters = 1\n",
        "kernel_size = 2\n",
        "strides = 1\n",
        "activation_conv = 'relu'\n",
        "\n",
        "(X_train, Y_train, X_val, Y_val, X_test, Y_test) = get_image_data_1d(1000, imsize, prob_white)\n",
        "\n",
        "# Define the layers\n",
        "layer1 = keras.layers.Conv1D(filters=num_filters, kernel_size=kernel_size, strides=strides,\n",
        "                       use_bias=False, activation=activation_conv, padding='same',\n",
        "                       input_shape=(imsize, 1))\n",
        "\n",
        "activation_dense = 'linear'\n",
        "num_units = 1\n",
        "\n",
        "# Create the Dense layer with bias\n",
        "layer3 = Dense(units=num_units, activation=activation_dense, use_bias=True)  # Use bias term\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(layer1)\n",
        "model.add(Flatten())\n",
        "model.add(layer3)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mse', optimizer=Adam())\n",
        "\n",
        "# Set weights for Conv1D layer\n",
        "conv_weights = np.array([[1/2, 1/2]]).reshape(kernel_size, 1, num_filters)\n",
        "model.layers[0].set_weights([conv_weights])\n",
        "\n",
        "# Set weights and bias for Dense layer\n",
        "dense_weights = np.ones((imsize, num_units))  # Correct weights shape: (imsize, num_units)\n",
        "dense_bias = np.array([-10])  # Bias term\n",
        "\n",
        "# Set weights for the Dense layer\n",
        "model.layers[-1].set_weights([dense_weights, dense_bias])\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test, Y_test)\n",
        "print(f\"Test Loss: {loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GCLr8qmj-Hk"
      },
      "source": [
        "<b>4D)</b> Averaging type filters are abundant and form a nearly flat valley of local minima for this problem. It is difficult for the network to find alternative solutions on its own. We need to force our way out of these bad minima and towards a better solution, i.e., an edge detector. To force the first layer to behave as an edge detector, we need to choose a proper **kernel regularizer**. Consider the following functions\n",
        "\n",
        "$f_1=\\sum_i |w_i|$, $f_2=\\sum_i |w_i^2|$, $f_3=|\\sum_{i} w_i|$. Which one of the choices is likely to guide the network to find an edge detector at the convolution layer?\n",
        "\n",
        "\n",
        "<a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week8/week8_homework/\">Refer to Catsoop.</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aubU6Q6kwOI"
      },
      "source": [
        "Implement your choice of regularizers from above in the code (complete the function `filter_reg`). Do not allow any bias in the layers for the rest of the problem. The code generates some random test and training data sets and trains the model on these data. Run a few learning trials (5 or more) for each data set and answer the following questions based on the performance of your model.\n",
        "\n",
        "**IMPORTANT**: When implementing `filter_reg`, you should use the keras backend operations, imported as \"K\" in the code. So for example, `K.sum` and `K.abs`, rather than `np.sum` and `np.abs`. This is because the `weights` argument is NOT a numpy object, but rather an internal Keras object!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yOLZf_JsuTLn"
      },
      "outputs": [],
      "source": [
        "# Implement filter_reg\n",
        "\n",
        "def filter_reg(weights):\n",
        "    # We scale the output of the filter by lam\n",
        "    lam=1000\n",
        "    filter_result = torch.abs(torch.sum(weights))  # Your code\n",
        "    return lam * filter_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYRwd0eJkAdh"
      },
      "source": [
        "<b>4E)</b> For $1024\\times 1$ images and training set of size $1000$, is the network **without any regularization** likely to find models that have a mean square error lower than 8 on the test data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1KiCbZmksXO6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecaa0962-7360-4915-df50-eaa1d248f2ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_3 (Conv1D)           (1, 1024, 1)              2         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (1, 1024)                 0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (1, 1)                    1024      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,026\n",
            "Trainable params: 1,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 8708.3867\n",
            "8708.38671875\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_4 (Conv1D)           (1, 1024, 1)              2         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (1, 1024)                 0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (1, 1)                    1024      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,026\n",
            "Trainable params: 1,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 2196.4055 - val_loss: 10.5514\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 10.3750 - val_loss: 10.2978\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 9.6917 - val_loss: 10.5902\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 8.7337 - val_loss: 10.4653\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 7.8215 - val_loss: 10.6742\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 7.1109 - val_loss: 10.8243\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 6.2645 - val_loss: 12.2976\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 5.7744 - val_loss: 12.3684\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 5.3622 - val_loss: 12.9316\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 5.0117 - val_loss: 13.2376\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 16.2764\n",
            "16.276378631591797\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_5 (Conv1D)           (1, 1024, 1)              2         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (1, 1024)                 0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (1, 1)                    1024      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,026\n",
            "Trainable params: 1,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 3258.2283 - val_loss: 15.3556\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 10.3641 - val_loss: 10.4967\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.6702 - val_loss: 10.5173\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 8.9274 - val_loss: 10.3913\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 8.1449 - val_loss: 10.5143\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 7.2363 - val_loss: 11.4550\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 6.6743 - val_loss: 11.1376\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 6.0913 - val_loss: 11.6070\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 5.5793 - val_loss: 12.0210\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 5.1840 - val_loss: 12.8226\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 15.0060\n",
            "15.00601863861084\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_6 (Conv1D)           (1, 1024, 1)              2         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (1, 1024)                 0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (1, 1)                    1024      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,026\n",
            "Trainable params: 1,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8652.8896 - val_loss: 8559.9902\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 8708.3867\n",
            "8708.38671875\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_7 (Conv1D)           (1, 1024, 1)              2         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (1, 1024)                 0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (1, 1)                    1024      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,026\n",
            "Trainable params: 1,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2985.8352 - val_loss: 13.8716\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 10.5426 - val_loss: 10.2222\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.8296 - val_loss: 10.1667\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.0038 - val_loss: 10.2109\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8.2035 - val_loss: 10.5536\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 7.2568 - val_loss: 12.0281\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 6.5078 - val_loss: 11.7020\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 5.8985 - val_loss: 11.6067\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 5.4179 - val_loss: 11.9990\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 5.1248 - val_loss: 12.7375\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 15.0415\n",
            "15.041535377502441\n"
          ]
        }
      ],
      "source": [
        "# Code template if you would like to check 4B) through code\n",
        "\n",
        "imsize = 1024\n",
        "prob_white = 0.1\n",
        "\n",
        "data=get_image_data_1d(1000, imsize, prob_white)\n",
        "trials=5\n",
        "for trial in range(trials):\n",
        "\n",
        "    num_filters = 1  # Your code\n",
        "    kernel_size = 2  # Your code\n",
        "    strides = 1  # Your code\n",
        "    activation_conv = 'relu'  # Your code\n",
        "\n",
        "    layer1=keras.layers.Conv1D(filters=num_filters, kernel_size=kernel_size, \\\n",
        "    strides=strides, use_bias=False, activation=activation_conv, batch_size=1, \\\n",
        "    input_shape=(imsize,1),padding='same')\n",
        "\n",
        "    activation_dense = 'relu'  # Your code\n",
        "    num_units = 1  # Your code\n",
        "\n",
        "    layer3=Dense(units=num_units, activation=activation_dense, use_bias=False)\n",
        "\n",
        "    layers=[layer1,Flatten(),layer3]\n",
        "    model,err = train_neural_counter(layers, data, 'mse')\n",
        "\n",
        "    model.layers[0].get_weights()[0]\n",
        "    np.mean(model.layers[-1].get_weights()[0])\n",
        "    print(err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1vcUEL-vW9D"
      },
      "source": [
        "#### For parts F) to J), simply edit your code from E) with the necessary changes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_25ygQJkD5F"
      },
      "source": [
        "<b>4F)</b> Repeat the same experiment, but now with the regularizer you implemented. Try different regularization parameters. Which choice of regularization parameter gives the best prediction results?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "# Example function placeholder for get_image_data_1d\n",
        "def get_image_data_1d(num_samples, imsize, prob_white):\n",
        "    # Generate synthetic data; replace with actual function\n",
        "    X = torch.rand(num_samples, 1, imsize)  # (num_samples, channels, imsize)\n",
        "    Y = torch.rand(num_samples, 1)  # (num_samples, output_dim)\n",
        "    return X, Y\n",
        "\n",
        "# Custom regularizer function\n",
        "def filter_reg(weights, lam):\n",
        "    # Compute the L1 norm of the weights (or another custom regularization)\n",
        "    filter_result = torch.abs(torch.sum(weights))\n",
        "    return lam * filter_result\n",
        "\n",
        "def train_neural_counter(layers, data, lambda_reg=0):\n",
        "    # Create dataset and dataloader\n",
        "    X_train, Y_train = data\n",
        "    dataset = TensorDataset(X_train, Y_train)\n",
        "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    # Define model\n",
        "    model = nn.Sequential(*layers)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    # Training loop\n",
        "    num_epochs = 5\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Add regularization loss\n",
        "            if lambda_reg > 0:\n",
        "                reg_loss = filter_reg(model[0].weight, lam=lambda_reg)\n",
        "                loss += reg_loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloader.dataset)\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    return model, epoch_loss\n",
        "\n",
        "def run_nn(lambda_reg=0):\n",
        "    imsize = 1024\n",
        "    prob_white = 0.1\n",
        "\n",
        "    # Load data\n",
        "    data = get_image_data_1d(1000, imsize, prob_white)\n",
        "\n",
        "    # Trials\n",
        "    for trial in range(3):\n",
        "        num_filters = 1\n",
        "        kernel_size = 2\n",
        "        strides = 1\n",
        "        padding = 1\n",
        "\n",
        "        # Define layers\n",
        "        layer_1 = nn.Conv1d(in_channels=1, out_channels=num_filters, kernel_size=kernel_size, stride=strides, padding=padding, bias=False)\n",
        "        num_units = imsize + 1\n",
        "        layer_3 = nn.Linear(num_units, 1, bias=False)\n",
        "        layers = [layer_1, nn.ReLU(), nn.Flatten(), layer_3]\n",
        "\n",
        "        # Train the model\n",
        "        model, err = train_neural_counter(layers, data, lambda_reg)\n",
        "        print(f\"Regularization Lambda: {lambda_reg}\")\n",
        "        print(\"Conv1D weights:\", model[0].weight.data)\n",
        "        print(\"Linear layer mean weight:\", torch.mean(model[-1].weight.data))\n",
        "        print(\"Final Error:\", err)\n",
        "\n",
        "# Run with different lambda values\n",
        "for lam in [0, 1, 10, 1000]:\n",
        "    run_nn(lambda_reg=lam)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nlp7bq_Ev_7F",
        "outputId": "00f2e9a3-0bb2-44e1-80d7-645295b9ebba"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.1326\n",
            "Epoch 2/5, Loss: 0.0906\n",
            "Epoch 3/5, Loss: 0.0835\n",
            "Epoch 4/5, Loss: 0.0791\n",
            "Epoch 5/5, Loss: 0.0749\n",
            "Regularization Lambda: 0\n",
            "Conv1D weights: tensor([[[ 0.4819, -0.5281]]])\n",
            "Linear layer mean weight: tensor(0.0068)\n",
            "Final Error: 0.07493640699982643\n",
            "Epoch 1/5, Loss: 0.1425\n",
            "Epoch 2/5, Loss: 0.0943\n",
            "Epoch 3/5, Loss: 0.0893\n",
            "Epoch 4/5, Loss: 0.0867\n",
            "Epoch 5/5, Loss: 0.0845\n",
            "Regularization Lambda: 0\n",
            "Conv1D weights: tensor([[[-0.0356,  0.3163]]])\n",
            "Linear layer mean weight: tensor(0.0036)\n",
            "Final Error: 0.08451167702674865\n",
            "Epoch 1/5, Loss: 0.1128\n",
            "Epoch 2/5, Loss: 0.0869\n",
            "Epoch 3/5, Loss: 0.0806\n",
            "Epoch 4/5, Loss: 0.0739\n",
            "Epoch 5/5, Loss: 0.0682\n",
            "Regularization Lambda: 0\n",
            "Conv1D weights: tensor([[[ 0.5656, -0.6744]]])\n",
            "Linear layer mean weight: tensor(0.0068)\n",
            "Final Error: 0.06817404597997666\n",
            "Epoch 1/5, Loss: 0.7280\n",
            "Epoch 2/5, Loss: 0.6640\n",
            "Epoch 3/5, Loss: 0.5822\n",
            "Epoch 4/5, Loss: 0.3196\n",
            "Epoch 5/5, Loss: 0.2077\n",
            "Regularization Lambda: 1\n",
            "Conv1D weights: tensor([[[-0.2016,  0.0971]]])\n",
            "Linear layer mean weight: tensor(0.0665)\n",
            "Final Error: 0.20774481773376466\n",
            "Epoch 1/5, Loss: 0.9303\n",
            "Epoch 2/5, Loss: 0.8362\n",
            "Epoch 3/5, Loss: 0.7761\n",
            "Epoch 4/5, Loss: 0.7098\n",
            "Epoch 5/5, Loss: 0.6438\n",
            "Regularization Lambda: 1\n",
            "Conv1D weights: tensor([[[0.1162, 0.4074]]])\n",
            "Linear layer mean weight: tensor(0.0017)\n",
            "Final Error: 0.6437592597007752\n",
            "Epoch 1/5, Loss: 1.0118\n",
            "Epoch 2/5, Loss: 0.9276\n",
            "Epoch 3/5, Loss: 0.7470\n",
            "Epoch 4/5, Loss: 0.5418\n",
            "Epoch 5/5, Loss: 0.4923\n",
            "Regularization Lambda: 1\n",
            "Conv1D weights: tensor([[[-0.5355,  0.1464]]])\n",
            "Linear layer mean weight: tensor(0.0778)\n",
            "Final Error: 0.49225711059570315\n",
            "Epoch 1/5, Loss: 2.8362\n",
            "Epoch 2/5, Loss: 2.0317\n",
            "Epoch 3/5, Loss: 1.4234\n",
            "Epoch 4/5, Loss: 0.8068\n",
            "Epoch 5/5, Loss: 0.2217\n",
            "Regularization Lambda: 10\n",
            "Conv1D weights: tensor([[[-0.2570,  0.2588]]])\n",
            "Linear layer mean weight: tensor(0.0112)\n",
            "Final Error: 0.2216831958591938\n",
            "Epoch 1/5, Loss: 4.7241\n",
            "Epoch 2/5, Loss: 4.0841\n",
            "Epoch 3/5, Loss: 3.4441\n",
            "Epoch 4/5, Loss: 2.8041\n",
            "Epoch 5/5, Loss: 2.1641\n",
            "Regularization Lambda: 10\n",
            "Conv1D weights: tensor([[[-0.1415, -0.0065]]])\n",
            "Linear layer mean weight: tensor(0.0003)\n",
            "Final Error: 2.164114436149597\n",
            "Epoch 1/5, Loss: 0.1835\n",
            "Epoch 2/5, Loss: 0.0869\n",
            "Epoch 3/5, Loss: 0.0817\n",
            "Epoch 4/5, Loss: 0.0810\n",
            "Epoch 5/5, Loss: 0.0773\n",
            "Regularization Lambda: 10\n",
            "Conv1D weights: tensor([[[-0.2202,  0.2201]]])\n",
            "Linear layer mean weight: tensor(0.0140)\n",
            "Final Error: 0.0773497615456581\n",
            "Epoch 1/5, Loss: 946.3155\n",
            "Epoch 2/5, Loss: 882.3164\n",
            "Epoch 3/5, Loss: 818.3172\n",
            "Epoch 4/5, Loss: 754.3177\n",
            "Epoch 5/5, Loss: 690.3181\n",
            "Regularization Lambda: 1000\n",
            "Conv1D weights: tensor([[[-0.1814, -0.4749]]])\n",
            "Linear layer mean weight: tensor(9.1526e-05)\n",
            "Final Error: 690.318056640625\n",
            "Epoch 1/5, Loss: 340.3264\n",
            "Epoch 2/5, Loss: 276.2048\n",
            "Epoch 3/5, Loss: 212.0669\n",
            "Epoch 4/5, Loss: 148.1561\n",
            "Epoch 5/5, Loss: 84.2036\n",
            "Regularization Lambda: 1000\n",
            "Conv1D weights: tensor([[[ 0.1987, -0.2490]]])\n",
            "Linear layer mean weight: tensor(0.0188)\n",
            "Final Error: 84.20363757324219\n",
            "Epoch 1/5, Loss: 6.3457\n",
            "Epoch 2/5, Loss: 0.7629\n",
            "Epoch 3/5, Loss: 0.3270\n",
            "Epoch 4/5, Loss: 0.3136\n",
            "Epoch 5/5, Loss: 0.3256\n",
            "Regularization Lambda: 1000\n",
            "Conv1D weights: tensor([[[-0.4660,  0.4658]]])\n",
            "Linear layer mean weight: tensor(0.0069)\n",
            "Final Error: 0.32561288857460025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs44ze96kHZZ"
      },
      "source": [
        "<b>4G)</b> With the above choice of regularization parameter, what is the mean square error of the best network that you find on the test data? Try a few trials (5 or more) for each data test and report the value of the best network.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAN0k9wylOmz"
      },
      "source": [
        "\n",
        "#### We expect the training to be easier when there are fewer parameters to learn. Consider images of size $128\\times 1$ for the rest of the problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnktFwXRkKNF"
      },
      "source": [
        "<b>4H)</b> Instead of resorting to regularization again, we may instead find a way to reduce the number of parameters. What additional layer can you add to the output of the convolution layer to reduce the number of parameters to be learned without losing any relevant information?\n",
        "\n",
        "<a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week8/week8_homework/\">Refer to Catsoop.</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXgOqKtRkNRP"
      },
      "source": [
        "<b>4I)</b> Add the layer you suggested above to your network and run some tests with data sets of size 1000 on $128\\times 1$ images.  How many parameters are left to learn with the new structure?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8FRQawHkPG9"
      },
      "source": [
        "<b>4J)</b> Mark your observations on the two structures (not using regularization).\n",
        "<a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week8/week8_homework/\">Refer to Catsoop.</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-iTDCrHySde"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQGlJLxI__4A"
      },
      "source": [
        "# 5) MNIST (Digit Classification)\n",
        "\n",
        "In this section, we'll be looking at the MNIST data set seen already in problem 2. This time, we look at the *complete* MNIST problem where our networks will take an image of *any* digit from $0-9$ as input (recall that problem 2 only looked at digits $0$ and $1$) and try to predict that digit. Also, we will now use out-of-the-box neural network implementations using Keras and Tensorflow. State-of-the-art systems have error rates of less that one half of one percent on this data set (see <a href=\"http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354\">this list</a>).  We'll be happy with an error rate less than 2% since we don't have all year...\n",
        "<br>\n",
        "\n",
        "You can access the MNIST data for this problem using:\n",
        "<br><code>train, validation = get_MNIST_data()</code>\n",
        "<br>\n",
        "\n",
        "You can run the fully connected MNIST model, using:\n",
        "<br><code>run_keras_fc_mnist(train, validation, layers, epochs, split=0.1, trials=5)</code>\n",
        "<br>\n",
        "\n",
        "And, you can run the CNN MNIST test, using:\n",
        "<br><code>run_keras_cnn_mnist(train, validation, layers, epochs, split=0.1, trials=5)</code>\n",
        "<br>\n",
        "\n",
        "For all following experiments, please run for 5 trials (use `trials=5`) and report the average accuracy.\n",
        "<br>\n",
        "\n",
        "A word of warning, if you have a machine with a single core and/or very little RAM, you'll be better off running on an Athena workstation. If your solutions are not being accepted, and you are confident in your approach, try with more trials. Also,\n",
        "<br>\n",
        "\n",
        "You will need to design your own `layers` to feed to `run_keras_fc_mnist` and `run_keras_cnn_mnist`, which will be different than the ones specified by `archs()`. For instance, `layers=[Dense(input_dim=64, units=4, activation=\"softmax\")]` defines a single layer with 64 inputs, 4 output units, and softmax activation. Also, we advise you to use the option `verbose=True` when unsure about the progress made during training of your models.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx1jt6P9AUk1"
      },
      "source": [
        "<b> 5A)</b> Look at the code and indicate what the difference is between <code>run_keras_fc_mnist</code> and <code>run_keras_cnn_mnist</code>? <a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week8/week8_homework/\">Refer to the HW8 page.</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5moSfb7CcXd"
      },
      "outputs": [],
      "source": [
        "def run_keras_fc_mnist(train, test, layers, epochs, split=0.1, verbose=True, trials=1):\n",
        "    '''\n",
        "    train, test = input data\n",
        "    layers = list of Keras layers, e.g. [Dense(32, input_dim=784), Dense(10)]\n",
        "    epochs = number of epochs to run the model for each traini\n",
        "    ng trial\n",
        "    trials = number of evaluation trials, resetting weights before each trial\n",
        "    '''\n",
        "    (X_train, y1), (X_val, y2) = train, test\n",
        "    # Flatten the images\n",
        "    m = X_train.shape[1]\n",
        "    X_train = X_train.reshape((X_train.shape[0], m*m))\n",
        "    X_val = X_val.reshape((X_val.shape[0], m*m))\n",
        "    # Categorize the labels\n",
        "    num_classes = 10\n",
        "    y_train = np_utils.to_categorical(y1, num_classes)\n",
        "    y_val = np_utils.to_categorical(y2, num_classes)\n",
        "    # Train, use split for validation\n",
        "    val_acc, test_acc = 0, 0\n",
        "    for trial in range(trials):\n",
        "        # Reset the weights\n",
        "        # See https://github.com/keras-team/keras/issues/341\n",
        "        #session = K.get_session()  #Commented VMohire Sept 2024\n",
        "        session = tf.compat.v1.keras.backend.get_sesssion()\n",
        "        for layer in layers:\n",
        "            for v in layer.__dict__:\n",
        "                v_arg = getattr(layer, v)\n",
        "                if hasattr(v_arg, 'initializer'):\n",
        "                    initializer_func = getattr(v_arg, 'initializer')\n",
        "                    initializer_func.run(session=session)\n",
        "        # Run the model\n",
        "        model, history, vacc, tacc = \\\n",
        "                run_keras(X_train, y_train, X_val, y_val, None, None, layers, epochs, split=split, verbose=verbose)\n",
        "        val_acc += vacc if vacc else 0\n",
        "        test_acc += tacc if tacc else 0\n",
        "    if val_acc:\n",
        "        print (\"\\nAvg. validation accuracy:\"  + str(val_acc/trials))\n",
        "    if test_acc:\n",
        "        print (\"\\nAvg. test accuracy:\"  + str(test_acc/trials))\n",
        "\n",
        "def run_keras_cnn_mnist(train, test, layers, epochs, split=0.1, verbose=True, trials=1):\n",
        "    # Load the dataset\n",
        "    (X_train, y1), (X_val, y2) = train, test\n",
        "    # Add a final dimension indicating the number of channels (only 1 here)\n",
        "    m = X_train.shape[1]\n",
        "    X_train = X_train.reshape((X_train.shape[0], m, m, 1))\n",
        "    X_val = X_val.reshape((X_val.shape[0], m, m, 1))\n",
        "    # Categorize the labels\n",
        "    num_classes = 10\n",
        "    y_train = np_utils.to_categorical(y1, num_classes)\n",
        "    y_val = np_utils.to_categorical(y2, num_classes)\n",
        "    # Train, use split for validation\n",
        "    val_acc, test_acc = 0, 0\n",
        "    for trial in range(trials):\n",
        "        # Reset the weights\n",
        "        # See https://github.com/keras-team/keras/issues/341\n",
        "        #session = K.get_session()\n",
        "        session = tf.compat.v1.keras.backend.get_session()\n",
        "        for layer in layers:\n",
        "            for v in layer.__dict__:\n",
        "                v_arg = getattr(layer, v)\n",
        "                if hasattr(v_arg, 'initializer'):\n",
        "                    initializer_func = getattr(v_arg, 'initializer')\n",
        "                    initializer_func.run(session=session)\n",
        "        # Run the model\n",
        "        model, history, vacc, tacc = \\\n",
        "                run_keras(X_train, y_train, X_val, y_val, None, None, layers, epochs, split=split, verbose=verbose)\n",
        "        val_acc += vacc if vacc else 0\n",
        "        test_acc += tacc if tacc else 0\n",
        "    if val_acc:\n",
        "        print (\"\\nAvg. validation accuracy:\"  + str(val_acc/trials))\n",
        "    if test_acc:\n",
        "        print (\"\\nAvg. test accuracy:\"  + str(test_acc/trials))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sGfqAbICbmE"
      },
      "source": [
        "<b> 5B)</b> Using one epoch of training, what is the accuracy of a network **with no hidden units** (using the <code>run_keras_fc_mnist</code> method) on this data? Hint: this is expected to be terrible. If it's still not working, run for more trials. Remember to use 10 output units (the network predicts a digit from 0-9) and softmax activation!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1VAxZ17DtPQ"
      },
      "outputs": [],
      "source": [
        "layers = None  # Your code\n",
        "train, validation = get_MNIST_data()\n",
        "run_keras_fc_mnist(train, validation, layers, 1, split=0.1, verbose=True, trials=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gndf-ASDEe_"
      },
      "source": [
        "<b> 5C)</b> When creating the keras layer, pass in the following argument to Dense:\n",
        "<code>kernel_initializer=VarianceScaling(scale=0.001, mode='fan_in', distribution='normal', seed=None)</code> and repeat the test.  What is the accuracy now?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2CP5WJQELJA"
      },
      "outputs": [],
      "source": [
        "layers = None  # Your code\n",
        "train, validation = get_MNIST_data()\n",
        "run_keras_fc_mnist(train, validation, layers, 1, split=0.1, verbose=True, trials=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsQ31e1lDE6u"
      },
      "source": [
        "<b> 5D)</b> Now, linearly scale the data so that the pixel values are between 0 and 1 and repeat your test with the original layer (no VarianceScaling). What is the accuracy now?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b-RcZu1EPaj"
      },
      "outputs": [],
      "source": [
        "layers = None  # Your code\n",
        "train, validation = get_MNIST_data()\n",
        "\n",
        "# Scale the images\n",
        "train = (None, train[1])  # Your code\n",
        "validation = (None, validation[1])  # Your code\n",
        "\n",
        "run_keras_fc_mnist(train, validation, layers, 1, split=0.1, verbose=True, trials=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4aBsxAzDFBY"
      },
      "source": [
        "<b> 5E)</b> What is happening? <a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week8/week8_homework/\">Refer to the HW8 page.</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrYGfcOLEr0f"
      },
      "source": [
        "### Important: <b>Always scale the data like in 5D) for subsequent problems.</b>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHoyqJdqDFH5"
      },
      "source": [
        "<b> 5F)</b> Using this same architecture, evaluate validation accuracy for number of training epochs in [5, 10, 15]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8PlbWS_EwTv"
      },
      "outputs": [],
      "source": [
        "train, validation = get_MNIST_data()\n",
        "\n",
        "# Scale the images\n",
        "train = (None, train[1])  # Your code\n",
        "validation = (None, validation[1])  # Your code\n",
        "\n",
        "for epochs in [5,10,15]:\n",
        "    layers = None  # Your code\n",
        "    run_keras_fc_mnist(train, validation, layers, epochs, split=0.1, verbose=True, trials=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zJk4u2-DFNi"
      },
      "source": [
        "<b> 5G a)</b>With the validation accuracy that you just saw on per digit basis using $15$ epochs, and assuming each digit is read independently from the others, what is the probability of reading a 5 digit zip code correctly?<br>\n",
        "\n",
        "<b> 5G b)</b>Now, assume that the accuracy is 0.9985, what is the probability of reading a zip code correctly?<br>\n",
        "\n",
        "\n",
        "This is why people care about dropping the error rates to what at first sound like ridiculous values.\n",
        "\n",
        "<a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week8/week8_homework/\">Refer to the HW8 page.</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCPTuz-tDFTg"
      },
      "source": [
        "<b> 5H)</b> Using one epoch of training, try a single hidden layer with ReLU and gradually increase the units (128, 256, 512, 1024) units.  What are the accuracies?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmpbP_VHFoh1"
      },
      "outputs": [],
      "source": [
        "train, validation = get_MNIST_data()\n",
        "\n",
        "# Scale the images\n",
        "train = (None, train[1])  # Your code\n",
        "validation = (None, validation[1])  # Your code\n",
        "\n",
        "for num in [128,256,512,1024]:\n",
        "    layers = None  # Your code\n",
        "    run_keras_fc_mnist(train, validation, layers, 1, split=0.1, verbose=True, trials=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEM5mZi5DFYS"
      },
      "source": [
        "<b> 5I)</b> Now, try a network with two layers, again using one epoch, with 512 units in the first hidden layer and and 256 units in the second hidden layer.  What is the accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cwp1VR7F06q"
      },
      "outputs": [],
      "source": [
        "train, validation = get_MNIST_data()\n",
        "\n",
        "# Scale the images\n",
        "train = (None, train[1])  # Your code\n",
        "validation = (None, validation[1])  # Your code\n",
        "\n",
        "layers = None  # Your code\n",
        "run_keras_fc_mnist(train, validation, layers, 1, split=0.1, verbose=True, trials=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmnNUT2nDFdi"
      },
      "source": [
        "<b> 5J)</b> Build a convolutional network with the following structure:\n",
        "\n",
        "<ul>\n",
        "<li> A convolutional layer with 32 filters of size 3 × 3, with a ReLU activation\n",
        "<li> A max pooling layer with size 2 × 2\n",
        "<li> A convolutional layer with 64 filters of size 3 × 3, with ReLU activation\n",
        "<li> A max pooling layer with size 2 × 2\n",
        "<li> A flatten layer\n",
        "<li> A fully connected layer with 128 neurons, with ReLU activation\n",
        "<li> A dropout layer with drop probability 0.5\n",
        "<li> A fully-connected layer with 10 neurons with softmax\n",
        "</ul>\n",
        "Train it on MNIST for one epoch, using <code>run_keras_cnn_mnist</code>.  What is the accuracy on the validation set?\n",
        "\n",
        "If you have time to run the training for more epochs, try it, you should see improvement.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-sPW8xKF7EZ"
      },
      "outputs": [],
      "source": [
        "train, validation = get_MNIST_data()\n",
        "\n",
        "# Scale the images\n",
        "train = (None, train[1])  # Your code\n",
        "validation = (None, validation[1])  # Your code\n",
        "\n",
        "layers = None  # Your code\n",
        "\n",
        "run_keras_cnn_mnist(train, validation, layers, 1, split=0.1, verbose=True, trials=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjmqgGvIDFiS"
      },
      "source": [
        "<b> 5K)</b> Now, let's compare the performance of a fully connected model and a CNN on data where the characters have been shifted randomly so that they are no longer centered.  \n",
        "\n",
        "You can build such a data set by calling: <code>train_20, validation_20 = get_MNIST_data(shift=20)</code>. Remember to scale it appropriately.\n",
        "\n",
        "<b>Note that each image is now 48x48, so you will need to change your layer definitions</b>.\n",
        "Run your two-hidden-layer FC architecture from above (problem 5I) on this data and then run the CNN architecture from above (problem 5J), both for one epoch. Report your results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvfiyrN9Gf7X"
      },
      "outputs": [],
      "source": [
        "train_20, validation_20 = get_MNIST_data(shift=20) # Your code (fill in the shift)\n",
        "print(train_20[0].shape)\n",
        "print(validation_20[0].shape)\n",
        "# Scale the images\n",
        "train_20 = (None, train_20[1])  # Your code\n",
        "validation_20 = (None, validation_20[1])  # Your code\n",
        "\n",
        "\n",
        "\n",
        "layers_fc = None  # Your code\n",
        "\n",
        "run_keras_fc_mnist(train_20, validation_20, layers_fc, 1, split=0.1, verbose=True, trials=5)\n",
        "\n",
        "layers_cnn = None  # Your code\n",
        "\n",
        "run_keras_cnn_mnist(train_20, validation_20, layers_cnn, 1, split=0.1, verbose=True, trials=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iLmfPHaC2d8"
      },
      "source": [
        "<b> 5L)</b> Some possible conclusions. <a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week8/week8_homework/\">Refer to the HW8 page.</a>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "IAN0k9wylOmz"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}