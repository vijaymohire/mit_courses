{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xIaEwCD406A"
      },
      "source": [
        "#MIT 6.036 Spring 2019: Homework 8#\n",
        "\n",
        "This colab notebook provides code and a framework for [homework 8](https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week8/week8_homework/).  You can work out your solutions here, then submit your results back on the homework page when ready. By New MIT course 2024\n",
        "\n",
        "## <section>**Setup**</section>\n",
        "\n",
        "First, download the code distribution for this homework that contains test cases and helper functions.\n",
        "\n",
        "Run the next code block to download and import the code for this lab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awwxMVzrVar9",
        "outputId": "62a765e4-32d8-4f7e-c8a4-75a100928c5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.8.0\n",
            "  Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (24.3.25)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.11.0)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.8.0)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.16.0)\n",
            "Collecting tensorboard<2.9,>=2.8 (from tensorflow==2.8.0)\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8.0)\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.0)\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.64.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.32.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\n",
            "Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tf-estimator-nightly, tensorboard-plugin-wit, keras, tensorboard-data-server, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.23.1 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Collecting np_utils\n",
            "  Downloading np_utils-0.6.0.tar.gz (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from np_utils) (1.26.4)\n",
            "Building wheels for collected packages: np_utils\n",
            "  Building wheel for np_utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np_utils: filename=np_utils-0.6.0-py3-none-any.whl size=56437 sha256=c95b89022f1aefc48883b21bfc8b2397ff6275e359cf2f7cb7145431853b9b34\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/c7/50/2307607f44366dd021209f660045f8d51cb976514d30be7cc7\n",
            "Successfully built np_utils\n",
            "Installing collected packages: np_utils\n",
            "Successfully installed np_utils-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.8.0\n",
        "!pip install np_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ms9vAuGXHDw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "session = tf.compat.v1.keras.backend.get_session()\n",
        "from tensorflow.compat.v1.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "batG7aEHaNM7",
        "outputId": "4f1e7916-e361-4b65-9c8d-a9a01b316d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-09-12 14:15:31--  https://introml_oll.odl.mit.edu/cat-soop/_static/6.036/homework/hw08/code_for_hw8.zip\n",
            "Resolving introml_oll.odl.mit.edu (introml_oll.odl.mit.edu)... 3.226.240.108\n",
            "Connecting to introml_oll.odl.mit.edu (introml_oll.odl.mit.edu)|3.226.240.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 95906 (94K) [application/zip]\n",
            "Saving to: ‘code_for_hw8.zip’\n",
            "\n",
            "code_for_hw8.zip    100%[===================>]  93.66K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-09-12 14:15:31 (2.24 MB/s) - ‘code_for_hw8.zip’ saved [95906/95906]\n",
            "\n",
            "Archive:  code_for_hw8.zip\n",
            "   creating: code_for_hw8/\n",
            "  inflating: code_for_hw8/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/code_for_hw8/\n",
            "  inflating: __MACOSX/code_for_hw8/._.DS_Store  \n",
            "  inflating: code_for_hw8/code_for_hw8_oop.py  \n",
            "  inflating: __MACOSX/code_for_hw8/._code_for_hw8_oop.py  \n",
            "   creating: code_for_hw8/data/\n",
            "  inflating: code_for_hw8/data/data3_train.csv  \n",
            "   creating: __MACOSX/code_for_hw8/data/\n",
            "  inflating: __MACOSX/code_for_hw8/data/._data3_train.csv  \n",
            "  inflating: code_for_hw8/data/data4_train.csv  \n",
            "  inflating: code_for_hw8/data/data4_validate.csv  \n",
            "  inflating: code_for_hw8/data/data3_validate.csv  \n",
            "  inflating: code_for_hw8/data/dataXor_train.csv  \n",
            "  inflating: code_for_hw8/data/data2_train.csv  \n",
            "  inflating: code_for_hw8/data/data2_validate.csv  \n",
            "  inflating: code_for_hw8/data/data3class_train.csv  \n",
            "  inflating: code_for_hw8/data/data1_validate.csv  \n",
            "  inflating: code_for_hw8/data/data1_train.csv  \n",
            "  inflating: code_for_hw8/code_for_hw8_keras.py  \n",
            "  inflating: __MACOSX/code_for_hw8/._code_for_hw8_keras.py  \n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!rm -rf code_for_hw8*\n",
        "!rm -rf data\n",
        "!rm -rf mnist_data\n",
        "!rm -rf *.zip\n",
        "!rm -rf test*/\n",
        "!rm -rf *.py\n",
        "!rm -rf *.pt\n",
        "!rm -rf __*\n",
        "\n",
        "!wget https://introml_oll.odl.mit.edu/cat-soop/_static/6.036/homework/hw08/code_for_hw8.zip --no-check-certificate\n",
        "\n",
        "!unzip code_for_hw8.zip\n",
        "!mv code_for_hw8/* .\n",
        "\n",
        "from code_for_hw8 import *\n",
        "\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "import math as m\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision\n",
        "\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "\n",
        "import os\n",
        "!pwd\n",
        "\n",
        "os.environ['KERAS_BACKEND']='tensorflow'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxUlVG1XcIQd",
        "outputId": "436217ed-d007-4512-af6f-d582660cf58a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Rs195tWcNRu",
        "outputId": "0444e027-fc38-4d6b-a361-b087075dee87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extraction completed.\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to your ZIP file and extraction folder\n",
        "zip_file_path = '/content/drive/My Drive/Colab Notebooks/code_for_hw8.zip'\n",
        "extract_folder = '/content/drive/My Drive/Colab Notebooks/code_for_hw8/'\n",
        "\n",
        "# Create the extraction folder if it doesn't exist\n",
        "os.makedirs(extract_folder, exist_ok=True)\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "print(\"Extraction completed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGPGhQhYvb19"
      },
      "outputs": [],
      "source": [
        "#   Data Sets\n",
        "######################################################################\n",
        "\n",
        "def super_simple_separable_through_origin():\n",
        "    X = np.array([[2, 3, 9, 12],\n",
        "                  [5, 1, 6, 5]])\n",
        "    y = np.array([[1, 0, 1, 0]])\n",
        "    return X, for_softmax(y)\n",
        "\n",
        "\n",
        "def super_simple_separable():\n",
        "    X = np.array([[2, 3, 9, 12],\n",
        "                  [5, 2, 6, 5]])\n",
        "    y = np.array([[1, 0, 1, 0]])\n",
        "    return X, for_softmax(y)\n",
        "\n",
        "\n",
        "def xor():\n",
        "    X = np.array([[1, 2, 1, 2],\n",
        "                  [1, 2, 2, 1]])\n",
        "    y = np.array([[1, 1, 0, 0]])\n",
        "    return X, for_softmax(y)\n",
        "\n",
        "\n",
        "def xor_more():\n",
        "    X = np.array([[1, 2, 1, 2, 2, 4, 1, 3],\n",
        "                  [1, 2, 2, 1, 3, 1, 3, 3]])\n",
        "    y = np.array([[1, 1, 0, 0, 1, 1, 0, 0]])\n",
        "    return X, for_softmax(y)\n",
        "\n",
        "\n",
        "def hard():\n",
        "    X = np.array([[-0.23390341, 1.18151883, -2.46493986, 1.55322202, 1.27621763,\n",
        "                   2.39710997, -1.3440304, -0.46903436, -0.64673502, -1.44029872,\n",
        "                   -1.37537243, 1.05994811, -0.93311512, 1.02735575, -0.84138778,\n",
        "                   -2.22585412, -0.42591102, 1.03561105, 0.91125595, -2.26550369],\n",
        "                  [-0.92254932, -1.1030963, -2.41956036, -1.15509002, -1.04805327,\n",
        "                   0.08717325, 0.8184725, -0.75171045, 0.60664705, 0.80410947,\n",
        "                   -0.11600488, 1.03747218, -0.67210575, 0.99944446, -0.65559838,\n",
        "                   -0.40744784, -0.58367642, 1.0597278, -0.95991874, -1.41720255]])\n",
        "    y = np.array([[1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
        "                   1., 0., 0., 0., 1., 1., 0.]])\n",
        "    return X, for_softmax(y)\n",
        "\n",
        "\n",
        "def for_softmax(y):\n",
        "    return np.vstack([1 - y, y])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwTiqqRRvult"
      },
      "outputs": [],
      "source": [
        "######################################################################\n",
        "# Tests\n",
        "######################################################################\n",
        "\n",
        "def unit_test(name, expected, actual):\n",
        "    if actual is None:\n",
        "        print(name + \": unimplemented\")\n",
        "    elif np.allclose(expected, actual):\n",
        "        print(name + \": OK\")\n",
        "    else:\n",
        "        print(name + \": FAILED\")\n",
        "        print(\"expected: \" + str(expected))\n",
        "        print(\"but was: \" + str(actual))\n",
        "\n",
        "\n",
        "def sgd_test(nn, test_values):\n",
        "    \"\"\"Run one step of SGD on a simple dataset with the specified\n",
        "    network, and with batch size (b) = len(dataset)\n",
        "\n",
        "    :param nn: A \"Sequential\" object representing a neural network\n",
        "\n",
        "    :param test_values: A dictionary containing the expected values\n",
        "    for the necessary unit tests\n",
        "\n",
        "    \"\"\"\n",
        "    lrate = 0.005\n",
        "    # data\n",
        "    X, Y = super_simple_separable()\n",
        "\n",
        "    # define the modules\n",
        "    assert len(nn.modules) == 4\n",
        "    (linear_1, f_1, linear_2, f_2) = nn.modules\n",
        "    Loss = nn.loss\n",
        "\n",
        "    unit_test('linear_1.W', test_values['linear_1.W'], linear_1.W)\n",
        "    unit_test('linear_1.W0', test_values['linear_1.W0'], linear_1.W0)\n",
        "    unit_test('linear_2.W', test_values['linear_2.W'], linear_2.W)\n",
        "    unit_test('linear_2.W0', test_values['linear_2.W0'], linear_2.W0)\n",
        "\n",
        "    z_1 = linear_1.forward(X)\n",
        "    unit_test('z_1', test_values['z_1'], z_1)\n",
        "    a_1 = f_1.forward(z_1)\n",
        "    unit_test('a_1', test_values['a_1'], a_1)\n",
        "    z_2 = linear_2.forward(a_1)\n",
        "    unit_test('z_2', test_values['z_2'], z_2)\n",
        "    a_2 = f_2.forward(z_2)\n",
        "    unit_test('a_2', test_values['a_2'], a_2)\n",
        "\n",
        "    Ypred = a_2\n",
        "    loss = Loss.forward(Ypred, Y)\n",
        "    unit_test('loss', test_values['loss'], loss)\n",
        "    dloss = Loss.backward()\n",
        "    unit_test('dloss', test_values['dloss'], dloss)\n",
        "\n",
        "    dL_dz2 = f_2.backward(dloss)\n",
        "    unit_test('dL_dz2', test_values['dL_dz2'], dL_dz2)\n",
        "    dL_da1 = linear_2.backward(dL_dz2)\n",
        "    unit_test('dL_da1', test_values['dL_da1'], dL_da1)\n",
        "    dL_dz1 = f_1.backward(dL_da1)\n",
        "    unit_test('dL_dz1', test_values['dL_dz1'], dL_dz1)\n",
        "    dL_dX = linear_1.backward(dL_dz1)\n",
        "    unit_test('dL_dX', test_values['dL_dX'], dL_dX)\n",
        "\n",
        "    linear_1.sgd_step(lrate)\n",
        "    unit_test('updated_linear_1.W', test_values['updated_linear_1.W'], linear_1.W)\n",
        "    unit_test('updated_linear_1.W0', test_values['updated_linear_1.W0'], linear_1.W0)\n",
        "    linear_2.sgd_step(lrate)\n",
        "    unit_test('updated_linear_2.W', test_values['updated_linear_2.W'], linear_2.W)\n",
        "    unit_test('updated_linear_2.W0', test_values['updated_linear_2.W0'], linear_2.W0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axGaRO1wz65o"
      },
      "outputs": [],
      "source": [
        "test_1_values = {'X': np.array([[2, 3, 9, 12],\n",
        "                                [5, 2, 6, 5]]),\n",
        "                 'Y': np.array([[0, 1, 0, 1],\n",
        "                                [1, 0, 1, 0]]),\n",
        "                 'linear_1.W': np.array([[1.24737338, 0.28295388, 0.69207227],\n",
        "                                         [1.58455078, 1.32056292, -0.69103982]]),\n",
        "                 'linear_1.W0': np.array([[0],\n",
        "                                          [0],\n",
        "                                          [0]]),\n",
        "                 'linear_2.W': np.array([[0.5485338, -0.08738612],\n",
        "                                         [-0.05959343, 0.23705916],\n",
        "                                         [0.08316359, 0.83962520]]),\n",
        "                 'linear_2.W0': np.array([[0],\n",
        "                                          [0]]),\n",
        "                 'z_1': np.array([[10.41750064, 6.91122168, 20.73366505, 22.8912344],\n",
        "                                  [7.16872235, 3.48998746, 10.46996239, 9.9982611],\n",
        "                                  [-2.07105455, 0.69413716, 2.08241149, 4.84966811]]),\n",
        "                 'a_1': np.array([[1., 0.99999801, 1., 1.],\n",
        "                                  [0.99999881, 0.99814108, 1., 1.],\n",
        "                                  [-0.96871843, 0.60063321, 0.96941021, 0.99987736]]),\n",
        "                 'z_2': np.array([[0.40837833, 0.53900088, 0.56956001, 0.57209377],\n",
        "                                  [-0.66368766, 0.65353931, 0.96361427, 0.98919526]]),\n",
        "                 'a_2': np.array([[0.74498961, 0.47139666, 0.4027417, 0.39721055],\n",
        "                                  [0.25501039, 0.52860334, 0.5972583, 0.60278945]]),\n",
        "                 'loss': 3.5572007784781565,\n",
        "                 'dloss': np.array([[0.74498961, -0.52860334, 0.4027417, -0.60278945],\n",
        "                                    [-0.74498961, 0.52860334, -0.4027417, 0.60278945]]),\n",
        "                 'dL_dz2': np.array([[0.74498961, -0.52860334, 0.4027417, -0.60278945],\n",
        "                                     [-0.74498961, 0.52860334, -0.4027417, 0.60278945]]),\n",
        "                 'dL_da1': np.array([[0.47375374, -0.3361494, 0.25611147, -0.38332583],\n",
        "                                     [-0.2210031, 0.15681155, -0.11947437, 0.17881905],\n",
        "                                     [-0.56355604, 0.39986813, -0.30465863, 0.45598708]]),\n",
        "                 'dL_dz1': np.array([[1.69467553e-09, -1.33530535e-06, 0.00000000e+00, -0.00000000e+00],\n",
        "                                     [-5.24547376e-07, 5.82459519e-04, -3.84805202e-10, 1.47943038e-09],\n",
        "                                     [-3.47063705e-02, 2.55611604e-01, -1.83538094e-02, 1.11838432e-04]]),\n",
        "                 'dL_dX': np.array([[-2.40194628e-02, 1.77064845e-01, -1.27021626e-02, 7.74006953e-05],\n",
        "                                    [2.39827939e-02, -1.75870737e-01, 1.26832126e-02, -7.72828555e-05]]),\n",
        "                 'updated_linear_1.W': np.array([[1.2473734,  0.28294514,  0.68940437],\n",
        "                                                 [1.58455079, 1.32055711, -0.69218045]]),\n",
        "                 'updated_linear_1.W0': np.array([[6.66805339e-09],\n",
        "                                                  [-2.90968033e-06],\n",
        "                                                  [-1.01331631e-03]]),\n",
        "                 'updated_linear_2.W': np.array([[0.54845211, -0.08730443],\n",
        "                                                 [-0.05968003, 0.23714576],\n",
        "                                                 [0.08942097, 0.83336782]]),\n",
        "                 'updated_linear_2.W0': np.array([[-8.16925787e-05],\n",
        "                                                  [8.16925787e-05]])}\n",
        "\n",
        "test_2_values = {'X': np.array([[2, 3, 9, 12],\n",
        "                                [5, 2, 6, 5]]),\n",
        "                 'Y': np.array([[0, 1, 0, 1],\n",
        "                                [1, 0, 1, 0]]),\n",
        "                 'linear_1.W': np.array([[1.24737338, 0.28295388, 0.69207227],\n",
        "                                         [1.58455078, 1.32056292, -0.69103982]]),\n",
        "                 'linear_1.W0': np.array([[0],\n",
        "                                          [0],\n",
        "                                          [0]]),\n",
        "                 'linear_2.W': np.array([[0.5485338, -0.08738612],\n",
        "                                         [-0.05959343, 0.23705916],\n",
        "                                         [0.08316359, 0.83962520]]),\n",
        "                 'linear_2.W0': np.array([[0],\n",
        "                                          [0]]),\n",
        "                 'z_1': np.array([[10.41750064, 6.91122168, 20.73366505, 22.8912344],\n",
        "                                  [7.16872235, 3.48998746, 10.46996239, 9.9982611],\n",
        "                                  [-2.07105455, 0.69413716, 2.08241149, 4.84966811]]),\n",
        "                 'a_1': np.array([[10.41750064, 6.91122168, 20.73366505, 22.8912344],\n",
        "                                  [7.16872235, 3.48998746, 10.46996239, 9.9982611],\n",
        "                                  [0., 0.69413716, 2.08241149, 4.84966811]]),\n",
        "                 'z_2': np.array([[5.28714248, 3.64078533, 10.92235599, 12.36410102],\n",
        "                                  [0.78906625, 0.80620366, 2.41861097, 4.44170662]]),\n",
        "                 'a_2': np.array([[9.88992134e-01, 9.44516196e-01, 9.99797333e-01, 9.99637598e-01],\n",
        "                                  [1.10078665e-02, 5.54838042e-02, 2.02666719e-04, 3.62401857e-04]]),\n",
        "                 'loss': 13.070537746542422,\n",
        "                 'dloss': np.array([[9.88992134e-01, -5.54838042e-02, 9.99797333e-01, -3.62401857e-04],\n",
        "                                    [-9.88992134e-01, 5.54838042e-02, -9.99797333e-01, 3.62401857e-04]]),\n",
        "                 'dL_dz2': np.array([[9.88992134e-01, -5.54838042e-02, 9.99797333e-01, -3.62401857e-04],\n",
        "                                     [-9.88992134e-01, 5.54838042e-02, -9.99797333e-01, 3.62401857e-04]]),\n",
        "                 'dL_da1': np.array([[6.28919807e-01, -3.52832568e-02, 6.35791049e-01, -2.30458563e-04],\n",
        "                                     [-2.93387075e-01, 1.64594141e-02, -2.96592466e-01, 1.07507449e-04],\n",
        "                                     [-7.48134578e-01, 4.19713676e-02, -7.56308297e-01, 2.74143091e-04]]),\n",
        "                 'dL_dz1': np.array([[6.28919807e-01, -3.52832568e-02, 6.35791049e-01, -2.30458563e-04],\n",
        "                                     [-2.93387075e-01, 1.64594141e-02, -2.96592466e-01, 1.07507449e-04],\n",
        "                                     [-0.00000000e+00, 4.19713676e-02, -7.56308297e-01, 2.74143091e-04]]),\n",
        "                 'dL_dX': np.array([[7.01482813e-01, -1.03069207e-02, 1.85726843e-01, -6.73213966e-05],\n",
        "                                    [6.09119276e-01, -6.31763062e-02, 1.13841333e+00, -4.12646736e-04]]),\n",
        "                 'updated_linear_1.W': np.array([[1.21301666, 0.29898107, 0.72546012],\n",
        "                                                 [1.55011264, 1.33662809, -0.66877713]]),\n",
        "                 'updated_linear_1.W0': np.array([[-0.00614599],\n",
        "                                                  [0.00286706],\n",
        "                                                  [0.00357031]]),\n",
        "                 'updated_linear_2.W': np.array([[0.39533114, 0.06581654],\n",
        "                                                 [-0.14639538, 0.3238611],\n",
        "                                                 [0.072955, 0.84983379]]),\n",
        "                 'updated_linear_2.W0': np.array([[-0.00966472],\n",
        "                                                  [0.00966472]])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-sSs7N4mMiX"
      },
      "source": [
        "# 2) Implementing Mini-batch Gradient Descent and Batch Normalization (OPTIONAL)\n",
        "\n",
        "** Note: You can click the arrow on the left of this text block to collapse/expand this optional section and all its code blocks **\n",
        "\n",
        "Last week we implemented a framework for building neural networks from scratch. We trained our models using *stochastic* gradient descent. In this problem, we explore how we can implement batch normalization as a module `BatchNorm` in our framework. It is the same module which you analyzed in problem 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgxmIfXVmVwd"
      },
      "source": [
        "Key to the concept of batch normalization is the doing gradient descent on batches of data. So we instead of using last week's stochastic gradient descent, we will first implement the *mini-batch* gradient descent method `mini_gd`, which is a hybrid between *stochastic* gradient descent and *batch* gradient descent. The lecture notes on <a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week7/neural_networks_2/1?activate_block_id=block-v1%3AMITx%2B6.036%2B2019_Spring%2Btype%40vertical%2Bblock%40neural_networks_2_optimizing_neural_network_parameters_vert\"> optimizing neural network parameters</a> are helpful for this part.\n",
        "\n",
        "In *mini-batch* gradient descent, for a mini-batch of size $K$, we select $K$ distinct data points uniformly at random from the data set and update the network weights based only on their contributions to the gradient:\n",
        "$$W := W - \\eta\\sum_{i=1}^K \\nabla_W \\mathcal{L}(h(x^{(i)}; W), y^{(i)})\\;\\;.$$\n",
        "\n",
        "Our *mini-batch* method `mini_gd` will be implemented within the `Sequential` python class (see homework 7 problem 2) and will take the following as inputs:\n",
        "\n",
        "* `X`: a standard data array (d by n)\n",
        "* `y`: a standard labels row vector (1 by n)\n",
        "* `iters`: the number of updates to perform on weights $W$\n",
        "* `lrate`: the learning rate used\n",
        "* `K`: the mini-batch size to be used\n",
        "\n",
        "One call of `mini_gd` should call `Sequential.backward` for back-propagation and `Sequential.step` for updating the weights, for a total of `iters` times, using `lrate` as the learning rate. As in our implementation of `sgd` from homework 7, we compute the predicted output for a mini-batch of data with the `Sequential.forward` method. We compute the loss between our predictions and the true labels using the assigned `Sequential.loss` method. (Note that in homework 7, `Sequential.step` was called `Sequential.sgd_step`. While the functionality of the step function is the same, it has been renamed for convenience. The same is true for the `module.step` function of each module we implemented, where applicable.)\n",
        "\n",
        "For picking $K$ unique data points at random from our large data-set for each mini-batch, we will implement the following strategy: we will first shuffle our data points `X` (and associated labels `y`). Then, we get <math>\\frac{n}{k}</math> (rounded down to the nearest integer) different mini-batches by grouping each $K$ consecutive points from this shuffled array. If we end up iterating over all the points but need more mini-batches, we will repeat the shuffling and the batching process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr1kWI08mdo4"
      },
      "source": [
        "<b>2A)</b>You need to fill in the missing code below. We have implemented the shuffling of indices and have provided you with the outer and inner loops."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_lvmO9Z22bH"
      },
      "source": [
        "** This OPTIONAL problem has you extend your homework 7 implementation for building neural networks. **\n",
        "### PLEASE COPY IN YOUR CODE FROM HOMEWORK 7 TO COMPLEMENT THE CLASSES GIVEN HERE\n",
        "\n",
        "Recall that your implementation from homework 7 included the following classes:\n",
        "    \n",
        "  * Module\n",
        "  * Linear\n",
        "  * Tanh\n",
        "  * ReLU\n",
        "  * SoftMax\n",
        "  * NLL\n",
        "  * Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f46u0j2yVL6"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Module:\n",
        "    def sgd_step(self, lrate): pass  # For modules w/o weights\n",
        "\n",
        "\n",
        "class Linear(Module):\n",
        "    def __init__(self, m, n):\n",
        "        self.m, self.n = (m, n)  # (in size, out size)\n",
        "        self.W0 = np.zeros([self.n, 1])  # (n x 1)\n",
        "        self.W = np.random.normal(0, 1.0 * m ** (-.5), [m, n])  # (m x n)\n",
        "\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        return np.dot(self.W.T, A) + self.W0  # (m x n)^T (m x b) = (n x b)\n",
        "\n",
        "    def backward(self, dLdZ):  # dLdZ is (n x b), uses stored self.A\n",
        "        self.dLdW = np.dot(self.A, dLdZ.T)                  # (m x n)\n",
        "        self.dLdW0 = dLdZ.sum(axis=1).reshape((self.n, 1))  # (n x 1)\n",
        "        return np.dot(self.W, dLdZ)                         # (m x b)\n",
        "\n",
        "    def sgd_step(self, lrate):  # Gradient descent step\n",
        "        self.W -= lrate*self.dLdW\n",
        "        self.W0 -= lrate*self.dLdW0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdcdDSS_sO3g",
        "outputId": "e41cc4fe-a73f-41de-9465-0d711979f4bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "linear_forward: OK\n",
            "linear_backward: OK\n",
            "linear_sgd_step_W: OK\n",
            "linear_sgd_step_W0: OK\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "# data\n",
        "X, Y = super_simple_separable()\n",
        "\n",
        "# module\n",
        "linear_1 = Linear(2, 3)\n",
        "\n",
        "#hyperparameters\n",
        "lrate = 0.005\n",
        "\n",
        "# test case\n",
        "# forward\n",
        "z_1 = linear_1.forward(X)\n",
        "exp_z_1 =  np.array([[10.41750064, 6.91122168, 20.73366505, 22.8912344],\n",
        "                     [7.16872235, 3.48998746, 10.46996239, 9.9982611],\n",
        "                     [-2.07105455, 0.69413716, 2.08241149, 4.84966811]])\n",
        "unit_test(\"linear_forward\", exp_z_1, z_1)\n",
        "\n",
        "# backward\n",
        "dL_dz1 = np.array([[1.69467553e-09, -1.33530535e-06, 0.00000000e+00, -0.00000000e+00],\n",
        "                                     [-5.24547376e-07, 5.82459519e-04, -3.84805202e-10, 1.47943038e-09],\n",
        "                                     [-3.47063705e-02, 2.55611604e-01, -1.83538094e-02, 1.11838432e-04]])\n",
        "exp_dLdX = np.array([[-2.40194628e-02, 1.77064845e-01, -1.27021626e-02, 7.74006953e-05],\n",
        "                                    [2.39827939e-02, -1.75870737e-01, 1.26832126e-02, -7.72828555e-05]])\n",
        "dLdX = linear_1.backward(dL_dz1)\n",
        "unit_test(\"linear_backward\", exp_dLdX, dLdX)\n",
        "\n",
        "# sgd step\n",
        "linear_1.sgd_step(lrate)\n",
        "exp_linear_1_W = np.array([[1.2473734,  0.28294514,  0.68940437],\n",
        "                           [1.58455079, 1.32055711, -0.69218045]]),\n",
        "unit_test(\"linear_sgd_step_W\",  exp_linear_1_W,  linear_1.W)\n",
        "\n",
        "exp_linear_1_W0 = np.array([[6.66805339e-09],\n",
        "                            [-2.90968033e-06],\n",
        "                            [-1.01331631e-03]]),\n",
        "unit_test(\"linear_sgd_step_W0\", exp_linear_1_W0, linear_1.W0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ljk9yH_Dq6m6"
      },
      "outputs": [],
      "source": [
        "class Tanh(Module):            # Layer activation\n",
        "    def forward(self, Z):\n",
        "        self.A = np.tanh(Z)\n",
        "        return self.A\n",
        "\n",
        "    def backward(self, dLdA):    # Uses stored self.A\n",
        "        return dLdA * (1.0 - (self.A ** 2))        # Your code: return dLdZ (?, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93W7rxLyrCit"
      },
      "outputs": [],
      "source": [
        "class ReLU(Module):              # Layer activation\n",
        "    def forward(self, Z):\n",
        "        self.A = np.maximum(0, Z)\n",
        "        return self.A\n",
        "\n",
        "    def backward(self, dLdA):    # uses stored self.A\n",
        "        return dLdA * (self.A != 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndr2GcSXrO_w"
      },
      "outputs": [],
      "source": [
        "class SoftMax(Module):           # Output activation\n",
        "    def forward(self, Z):\n",
        "        return np.exp(Z) / np.sum(np.exp(Z), axis=0)\n",
        "\n",
        "    def backward(self, dLdZ):    # Assume that dLdZ is passed in\n",
        "        return dLdZ\n",
        "\n",
        "    def class_fun(self, Ypred):  # Return class indices\n",
        "        return np.argmax(Ypred, axis=0)   # Your code: (1, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5QgXHD-rQpf"
      },
      "outputs": [],
      "source": [
        "class NLL(Module):       # Loss\n",
        "    def forward(self, Ypred, Y):\n",
        "        self.Ypred = Ypred\n",
        "        self.Y = Y\n",
        "        return float(np.sum(-Y * np.log(Ypred)))\n",
        "\n",
        "    def backward(self):  # Use stored self.Ypred, self.Y\n",
        "        return self.Ypred - self.Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilSx8GJHzABr"
      },
      "outputs": [],
      "source": [
        " import math as m\n",
        "\n",
        " class Sequential:\n",
        "    def __init__(self, modules, loss):            # List of modules, loss module\n",
        "        self.modules = modules\n",
        "        self.loss = loss\n",
        "\n",
        "    def sgd(self, X, Y, iters=100, lrate=0.005):  # Train\n",
        "        D, N = X.shape\n",
        "        sum_loss = 0\n",
        "        for it in range(iters):\n",
        "            i = np.random.randint(N)\n",
        "            Xt = X[:, i:i+1]\n",
        "            Yt = Y[:, i:i+1]\n",
        "            Ypred = self.forward(Xt)\n",
        "            sum_loss += self.loss.forward(Ypred, Yt)\n",
        "            err = self.loss.backward()\n",
        "            self.backward(err)\n",
        "            self.sgd_step(lrate)\n",
        "\n",
        "    def forward(self, Xt):                        # Compute Ypred\n",
        "        for m in self.modules: Xt = m.forward(Xt)\n",
        "        return Xt\n",
        "\n",
        "    def backward(self, delta):                    # Update dLdW and dLdW0\n",
        "        # Note reversed list of modules\n",
        "        for m in self.modules[::-1]: delta = m.backward(delta)\n",
        "\n",
        "    def sgd_step(self, lrate):                    # Gradient descent step\n",
        "        for m in self.modules: m.sgd_step(lrate)\n",
        "\n",
        "    def print_accuracy(self, it, X, Y, cur_loss, every=250):\n",
        "        # Utility method to print accuracy on full dataset, should\n",
        "        # improve over time when doing SGD. Also prints current loss,\n",
        "        # which should decrease over time. Call this on each iteration\n",
        "        # of SGD!\n",
        "        if it % every == 1:\n",
        "            cf = self.modules[-1].class_fun\n",
        "            acc = np.mean(cf(self.forward(X)) == cf(Y))\n",
        "            print('Iteration =', it, '\tAcc =', acc, '\tLoss =', cur_loss)\n",
        "\n",
        "    def mini_gd(self, X, Y, iters, lrate, notif_each=None, K=10):\n",
        "        D, N = X.shape\n",
        "\n",
        "        np.random.seed(0)\n",
        "        num_updates = 0\n",
        "        indices = np.arange(N)\n",
        "        while num_updates < iters:\n",
        "\n",
        "            np.random.shuffle(indices)\n",
        "            X = X[:,indices]  # Your code\n",
        "            Y = Y[:,indices]  # Your code\n",
        "\n",
        "            for j in range(m.floor(N/K)):\n",
        "                if num_updates >= iters: break\n",
        "\n",
        "                # Implement the main part of mini_gd here\n",
        "                # Your code\n",
        "                Xt = X[:,j*K:(j+1)*K]\n",
        "                Yt = Y[:,j*K:(j+1)*K]\n",
        "                Ypred = self.forward(Xt)\n",
        "                loss = self.loss.forward(Ypred, Yt)\n",
        "                dLdZ = self.loss.backward()\n",
        "                self.backward(dLdZ)\n",
        "                self.step(lrate)\n",
        "                num_updates += 1\n",
        "\n",
        "    def step(self, lrate):\n",
        "        for m in self.modules: m.step(lrate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8cJS_XbsdGP",
        "outputId": "248bca72-a5c5-480a-d395-29a39515b368"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "linear_1.W: OK\n",
            "linear_1.W0: OK\n",
            "linear_2.W: OK\n",
            "linear_2.W0: OK\n",
            "z_1: OK\n",
            "a_1: OK\n",
            "z_2: OK\n",
            "a_2: OK\n",
            "loss: OK\n",
            "dloss: OK\n",
            "dL_dz2: OK\n",
            "dL_da1: OK\n",
            "dL_dz1: OK\n",
            "dL_dX: OK\n",
            "updated_linear_1.W: OK\n",
            "updated_linear_1.W0: OK\n",
            "updated_linear_2.W: OK\n",
            "updated_linear_2.W0: OK\n"
          ]
        }
      ],
      "source": [
        "# TEST 1: sgd_test for Tanh activation and SoftMax output\n",
        "np.random.seed(0)\n",
        "sgd_test(Sequential([Linear(2,3), Tanh(), Linear(3,2), SoftMax()], NLL()), test_1_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARsPy3UhseUU",
        "outputId": "da107d39-7153-46ad-a265-c24a0b1e31ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "linear_1.W: OK\n",
            "linear_1.W0: OK\n",
            "linear_2.W: OK\n",
            "linear_2.W0: OK\n",
            "z_1: OK\n",
            "a_1: OK\n",
            "z_2: OK\n",
            "a_2: OK\n",
            "loss: OK\n",
            "dloss: OK\n",
            "dL_dz2: OK\n",
            "dL_da1: OK\n",
            "dL_dz1: OK\n",
            "dL_dX: OK\n",
            "updated_linear_1.W: OK\n",
            "updated_linear_1.W0: OK\n",
            "updated_linear_2.W: OK\n",
            "updated_linear_2.W0: OK\n"
          ]
        }
      ],
      "source": [
        "# TEST 2: sgd_test for ReLU activation and SoftMax output\n",
        "np.random.seed(0)\n",
        "sgd_test(Sequential([Linear(2,3), ReLU(), Linear(3,2), SoftMax()], NLL()), test_2_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGR1xmjd0y7f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#import numpy as np\n",
        "\n",
        "####################\n",
        "# SUPPORT AND DISPLAY CODE\n",
        "####################\n",
        "\n",
        "# Takes a list of numbers and returns a row vector: 1 x n\n",
        "def rv(value_list):\n",
        "    return np.array([value_list])\n",
        "\n",
        "\n",
        "def cv(value_list):\n",
        "    return np.transpose(rv(value_list))\n",
        "\n",
        "\n",
        "def tidy_plot(xmin, xmax, ymin, ymax, center=False, title=None,\n",
        "              xlabel=None, ylabel=None):\n",
        "    plt.figure(facecolor=\"white\")\n",
        "    ax = plt.subplot()\n",
        "    if center:\n",
        "        ax.spines['left'].set_position('zero')\n",
        "        ax.spines['right'].set_color('none')\n",
        "        ax.spines['bottom'].set_position('zero')\n",
        "        ax.spines['top'].set_color('none')\n",
        "        ax.spines['left'].set_smart_bounds(True)\n",
        "        ax.spines['bottom'].set_smart_bounds(True)\n",
        "        ax.xaxis.set_ticks_position('bottom')\n",
        "        ax.yaxis.set_ticks_position('left')\n",
        "    else:\n",
        "        ax.spines[\"top\"].set_visible(False)\n",
        "        ax.spines[\"right\"].set_visible(False)\n",
        "        ax.get_xaxis().tick_bottom()\n",
        "        ax.get_yaxis().tick_left()\n",
        "    eps = .05\n",
        "    plt.xlim(xmin - eps, xmax + eps)\n",
        "    plt.ylim(ymin - eps, ymax + eps)\n",
        "    if title: ax.set_title(title)\n",
        "    if xlabel: ax.set_xlabel(xlabel)\n",
        "    if ylabel: ax.set_ylabel(ylabel)\n",
        "    return ax\n",
        "\n",
        "\n",
        "def plot_points(x, y, ax=None, clear=False,\n",
        "                xmin=None, xmax=None, ymin=None, ymax=None,\n",
        "                style='or-', equal=False):\n",
        "    padup = lambda v: v + 0.05 * abs(v)\n",
        "    paddown = lambda v: v - 0.05 * abs(v)\n",
        "    if ax is None:\n",
        "        if xmin == None: xmin = paddown(np.min(x))\n",
        "        if xmax == None: xmax = padup(np.max(x))\n",
        "        if ymin == None: ymin = paddown(np.min(y))\n",
        "        if ymax == None: ymax = padup(np.max(y))\n",
        "        ax = tidy_plot(xmin, xmax, ymin, ymax)\n",
        "        x_range = xmax - xmin;\n",
        "        y_range = ymax - ymin\n",
        "        if equal and .1 < x_range / y_range < 10:\n",
        "            # ax.set_aspect('equal')\n",
        "            plt.axis('equal')\n",
        "            if x_range > y_range:\n",
        "                ax.set_xlim((xmin, xmax))\n",
        "            else:\n",
        "                ax.set_ylim((ymin, ymax))\n",
        "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
        "    elif clear:\n",
        "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
        "        ax.clear()\n",
        "    else:\n",
        "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
        "    ax.plot(x, y, style, markeredgewidth=0.0, linewidth=5.0)\n",
        "    # Seems to occasionally mess up the limits\n",
        "    ax.set_xlim(xlim);\n",
        "    ax.set_ylim(ylim)\n",
        "    ax.grid(True, which='both')\n",
        "    return ax\n",
        "\n",
        "\n",
        "def add_ones(X):\n",
        "    return np.vstack([X, np.ones(X.shape[1])])\n",
        "\n",
        "\n",
        "def plot_data(data, labels, ax=None,\n",
        "              xmin=None, xmax=None, ymin=None, ymax=None):\n",
        "    # Handle 1D data\n",
        "    if data.shape[0] == 1:\n",
        "        data = add_ones(data)\n",
        "    if ax is None:\n",
        "        if xmin == None: xmin = np.min(data[0, :]) - 0.5\n",
        "        if xmax == None: xmax = np.max(data[0, :]) + 0.5\n",
        "        if ymin == None: ymin = np.min(data[1, :]) - 0.5\n",
        "        if ymax == None: ymax = np.max(data[1, :]) + 0.5\n",
        "        ax = tidy_plot(xmin, xmax, ymin, ymax)\n",
        "\n",
        "        x_range = xmax - xmin\n",
        "        y_range = ymax - ymin\n",
        "        if .1 < x_range / y_range < 10:\n",
        "            ax.set_aspect('equal')\n",
        "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
        "    else:\n",
        "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
        "    for yi in set([int(_y) for _y in set(labels.flatten().tolist())]):\n",
        "        color = ['r', 'g', 'b'][yi]\n",
        "        marker = ['X', 'o', 'v'][yi]\n",
        "        cl = np.where(labels[1, :] == yi)\n",
        "        ax.scatter(data[0, cl], data[1, cl], c=color, marker=marker, s=50,\n",
        "                   edgecolors='none')\n",
        "    ax.set_xlim(xlim)\n",
        "    ax.set_ylim(ylim)\n",
        "    ax.grid(True, which='both')\n",
        "    return ax\n",
        "\n",
        "\n",
        "def plot_objective_2d(J, xmin=-5, xmax=5,\n",
        "                      ymin=-5, ymax=5,\n",
        "                      cmin=None, cmax=None,\n",
        "                      res=50, ax=None):\n",
        "    if ax is None:\n",
        "        ax = tidy_plot(xmin, xmax, ymin, ymax)\n",
        "    else:\n",
        "        if xmin == None:\n",
        "            xmin, xmax = ax.get_xlim()\n",
        "            ymin, ymax = ax.get_ylim()\n",
        "        else:\n",
        "            ax.set_xlim((xmin, xmax))\n",
        "            ax.set_ylim((ymin, ymax))\n",
        "\n",
        "    ima = np.array([[J(cv([x1i, x2i])) \\\n",
        "                     for x1i in np.linspace(xmin, xmax, res)] \\\n",
        "                    for x2i in np.linspace(ymin, ymax, res)])\n",
        "    im = ax.imshow(np.flipud(ima), interpolation='none',\n",
        "                   extent=[xmin, xmax, ymin, ymax],\n",
        "                   cmap='viridis')\n",
        "    if cmin is not None or cmax is not None:\n",
        "        if cmin is None: cmin = min(ima)\n",
        "        if cmax is None: cmax = max(ima)\n",
        "        im.set_clim(cmin, cmax)\n",
        "    plt.colorbar(im)\n",
        "    return ax\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk-0rjSuXrF7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def classify(X, Y, nn, it=10000, lr=0.005):\n",
        "    D = X.shape[0]\n",
        "    N = X.shape[1]\n",
        "    O = Y.shape[0]\n",
        "    # Modifies the weights and biases\n",
        "    nn.sgd(X, Y, it, lr)\n",
        "\n",
        "    # Draw it...\n",
        "    def predict(x):\n",
        "        return nn.modules[-1].class_fun(nn.forward(x))[0]\n",
        "\n",
        "    xmin, ymin = np.min(X, axis=1) - 1\n",
        "    xmax, ymax = np.max(X, axis=1) + 1\n",
        "    print(xmin, ymin, xmax, ymax)\n",
        "    nax = plot_objective_2d(lambda x: predict(x), xmin, xmax, ymin, ymax)\n",
        "    plot_data(X, Y, nax)\n",
        "    plt.show()\n",
        "\n",
        "    return nn\n",
        "\n",
        "\n",
        "####################\n",
        "# SUPPORT AND DISPLAY CODE\n",
        "####################\n",
        "\n",
        "# Takes a list of numbers and returns a row vector: 1 x n\n",
        "def rv(value_list):\n",
        "    return np.array([value_list])\n",
        "\n",
        "\n",
        "def cv(value_list):\n",
        "    return np.transpose(rv(value_list))\n",
        "\n",
        "\n",
        "def tidy_plot(xmin, xmax, ymin, ymax, center=False, title=None,\n",
        "              xlabel=None, ylabel=None):\n",
        "    plt.figure(facecolor=\"white\")\n",
        "    ax = plt.subplot()\n",
        "    if center:\n",
        "        ax.spines['left'].set_position('zero')\n",
        "        ax.spines['right'].set_color('none')\n",
        "        ax.spines['bottom'].set_position('zero')\n",
        "        ax.spines['top'].set_color('none')\n",
        "        ax.spines['left'].set_smart_bounds(True)\n",
        "        ax.spines['bottom'].set_smart_bounds(True)\n",
        "        ax.xaxis.set_ticks_position('bottom')\n",
        "        ax.yaxis.set_ticks_position('left')\n",
        "    else:\n",
        "        ax.spines[\"top\"].set_visible(False)\n",
        "        ax.spines[\"right\"].set_visible(False)\n",
        "        ax.get_xaxis().tick_bottom()\n",
        "        ax.get_yaxis().tick_left()\n",
        "    eps = .05\n",
        "    plt.xlim(xmin - eps, xmax + eps)\n",
        "    plt.ylim(ymin - eps, ymax + eps)\n",
        "    if title: ax.set_title(title)\n",
        "    if xlabel: ax.set_xlabel(xlabel)\n",
        "    if ylabel: ax.set_ylabel(ylabel)\n",
        "    return ax\n",
        "\n",
        "\n",
        "def plot_points(x, y, ax=None, clear=False,\n",
        "                xmin=None, xmax=None, ymin=None, ymax=None,\n",
        "                style='or-', equal=False):\n",
        "    padup = lambda v: v + 0.05 * abs(v)\n",
        "    paddown = lambda v: v - 0.05 * abs(v)\n",
        "    if ax is None:\n",
        "        if xmin == None: xmin = paddown(np.min(x))\n",
        "        if xmax == None: xmax = padup(np.max(x))\n",
        "        if ymin == None: ymin = paddown(np.min(y))\n",
        "        if ymax == None: ymax = padup(np.max(y))\n",
        "        ax = tidy_plot(xmin, xmax, ymin, ymax)\n",
        "        x_range = xmax - xmin;\n",
        "        y_range = ymax - ymin\n",
        "        if equal and .1 < x_range / y_range < 10:\n",
        "            # ax.set_aspect('equal')\n",
        "            plt.axis('equal')\n",
        "            if x_range > y_range:\n",
        "                ax.set_xlim((xmin, xmax))\n",
        "            else:\n",
        "                ax.set_ylim((ymin, ymax))\n",
        "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
        "    elif clear:\n",
        "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
        "        ax.clear()\n",
        "    else:\n",
        "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
        "    ax.plot(x, y, style, markeredgewidth=0.0, linewidth=5.0)\n",
        "    # Seems to occasionally mess up the limits\n",
        "    ax.set_xlim(xlim);\n",
        "    ax.set_ylim(ylim)\n",
        "    ax.grid(True, which='both')\n",
        "    return ax\n",
        "\n",
        "\n",
        "def add_ones(X):\n",
        "    return np.vstack([X, np.ones(X.shape[1])])\n",
        "\n",
        "\n",
        "def plot_data(data, labels, ax=None,\n",
        "              xmin=None, xmax=None, ymin=None, ymax=None):\n",
        "    # Handle 1D data\n",
        "    if data.shape[0] == 1:\n",
        "        data = add_ones(data)\n",
        "    if ax is None:\n",
        "        if xmin == None: xmin = np.min(data[0, :]) - 0.5\n",
        "        if xmax == None: xmax = np.max(data[0, :]) + 0.5\n",
        "        if ymin == None: ymin = np.min(data[1, :]) - 0.5\n",
        "        if ymax == None: ymax = np.max(data[1, :]) + 0.5\n",
        "        ax = tidy_plot(xmin, xmax, ymin, ymax)\n",
        "\n",
        "        x_range = xmax - xmin\n",
        "        y_range = ymax - ymin\n",
        "        if .1 < x_range / y_range < 10:\n",
        "            ax.set_aspect('equal')\n",
        "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
        "    else:\n",
        "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
        "    for yi in set([int(_y) for _y in set(labels.flatten().tolist())]):\n",
        "        color = ['r', 'g', 'b'][yi]\n",
        "        marker = ['X', 'o', 'v'][yi]\n",
        "        cl = np.where(labels[1, :] == yi)\n",
        "        ax.scatter(data[0, cl], data[1, cl], c=color, marker=marker, s=50,\n",
        "                   edgecolors='none')\n",
        "    ax.set_xlim(xlim)\n",
        "    ax.set_ylim(ylim)\n",
        "    ax.grid(True, which='both')\n",
        "    return ax\n",
        "\n",
        "\n",
        "def plot_objective_2d(J, xmin=-5, xmax=5,\n",
        "                      ymin=-5, ymax=5,\n",
        "                      cmin=None, cmax=None,\n",
        "                      res=50, ax=None):\n",
        "    if ax is None:\n",
        "        ax = tidy_plot(xmin, xmax, ymin, ymax)\n",
        "    else:\n",
        "        if xmin == None:\n",
        "            xmin, xmax = ax.get_xlim()\n",
        "            ymin, ymax = ax.get_ylim()\n",
        "        else:\n",
        "            ax.set_xlim((xmin, xmax))\n",
        "            ax.set_ylim((ymin, ymax))\n",
        "\n",
        "    ima = np.array([[J(cv([x1i, x2i])) \\\n",
        "                     for x1i in np.linspace(xmin, xmax, res)] \\\n",
        "                    for x2i in np.linspace(ymin, ymax, res)])\n",
        "    im = ax.imshow(np.flipud(ima), interpolation='none',\n",
        "                   extent=[xmin, xmax, ymin, ymax],\n",
        "                   cmap='viridis')\n",
        "    if cmin is not None or cmax is not None:\n",
        "        if cmin is None: cmin = min(ima)\n",
        "        if cmax is None: cmax = max(ima)\n",
        "        im.set_clim(cmin, cmax)\n",
        "    plt.colorbar(im)\n",
        "    return ax\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "Wd70xOccsrRr",
        "outputId": "8bf8320f-3b49-4ab1-a99f-102ba8394418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-3.46493986 -3.41956036 3.39710997 2.0597278\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<__main__.Sequential at 0x7f6b862fb010>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TEST 3: you should achieve 100% accuracy on the hard dataset (note that we provided plotting code), see Hw7 file: modules_disp\n",
        "X, Y = hard()\n",
        "nn = Sequential([Linear(2, 10), ReLU(), Linear(10, 10), ReLU(), Linear(10,2), SoftMax()], NLL())\n",
        "classify(X, Y, nn, it=100000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JZeeKXkm6YI"
      },
      "source": [
        "<b>2B)</b> We are now ready to implement batch normalization into our neural network framework! Our module `BatchNorm` will sit between consecutive layers of neurons, such as the $l^{th}$ and $(l+1)^{th}$ layers, acting as a \"corrector\" which allows $W^l$ to change freely, producing outputs $z^l$, but then the module corrects the covariate shift induced in the signals before they reach the $(l+1)^{th}$ layer, converting $z^l$ to $\\widehat{Z}^l$.\n",
        "\n",
        "The following is a summmary what is described in the <a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week7/neural_networks_2/2\">lecture notes</a>, and it should guide your implementation of the module.\n",
        "\n",
        "Any normalization between the $l^{th}$ and $(l+1)^{th}$ layers is done *separately* for each of the $n^l$ input connections leading to the $(l+1)^{th}$ layer. We handle a mini-batch of data of size $K$, and $Z^l$ is $n^l \\times K$, and the output $\\widehat{Z}^l$is of the same shape.\n",
        "\n",
        "We first compute $n^l$ *batchwise* means and\n",
        "standard deviations.  Let $\\mu^l$ be the $n^l \\times 1$ vector (`self.mus`) where\n",
        "$$\\mu^l_i = \\frac{1}{K} \\sum_{j = 1}^K Z^l_{ij}\\;\\;,$$\n",
        "and let $\\sigma^l$ be the $n^l \\times 1$ vector (`self.vars`) where\n",
        "$$\\sigma^l_i = \\sqrt{\\frac{1}{K} \\sum_{j = 1}^K (Z^l_{ij} - \\mu_i)^2}\\;\\;.$$\n",
        "\n",
        "The normalized data `self.norm` is the matrix $\\overline{Z}$, where\n",
        "$$\\overline{Z}^l_{ij} = \\frac{Z^l_{ij} - \\mu^l_i}{\\sigma^l_i + \\epsilon}\\;\\;,$$\n",
        "and where $\\epsilon$ is a very small constant to guard against division by\n",
        "zero.\n",
        "\n",
        "We define weights $G^l$ (`self.G`) and $B^l$ (`self.B`), each being an $n^l \\times 1$ vector, which we use to to shift and scale the outputs:\n",
        "$$\\widehat{Z}^l_{ij} = G^l_i \\overline{Z}^l_{ij} + B^l_i\\;\\;.$$\n",
        "\n",
        "The outputs are finally ready to be passed to the $(l+1)^{th}$ layer.\n",
        "\n",
        "A slight warning (that we will not worry about here) about `BatchNorm` is that during the *test* phase, if the test mini-batch size is too small (imagine we are deploying a neural network that deals with live video frames), then the lack of samples would cause the freshly-calculated $\\mu^l$ and $\\sigma^l$ to be far off from their true values that the module's parameters $G^l$ and $B^l$ were trained to be compatible with. To fix that, people usually compute a running average of $\\mu^l$ and $\\sigma^l$ during training, to be used at test time. We will assume our test mini-batches are large enough.\n",
        "\n",
        "In this problem we only implement the `BatchNorm.forward` and `BatchNorm.step` methods. We provide you with the implementation for `BatchNorm.backward` and the lecture notes contain the details of the derivations. You will need to fill in the missing code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlXP26plm8R7"
      },
      "outputs": [],
      "source": [
        "class BatchNorm(Module):\n",
        "    def __init__(self, m):\n",
        "        np.random.seed(0)\n",
        "        self.eps = 1e-20\n",
        "        self.m = m  # number of input channels\n",
        "\n",
        "        # Init learned shifts and scaling factors\n",
        "        self.B = np.zeros([self.m, 1])\n",
        "        self.G = np.random.normal(0, 1.0 * self.m ** (-.5), [self.m, 1])\n",
        "\n",
        "    # Works on m x b matrices of m input channels and b different inputs\n",
        "    def forward(self, A):# A is m x K: m input channels and mini-batch size K\n",
        "        # Store last inputs and K for next backward() call\n",
        "        self.A = A\n",
        "        self.K = A.shape[1]\n",
        "\n",
        "        self.mus = np.mean(A, axis=1, keepdims=True)  # Your Code\n",
        "        self.vars = np.var(A, axis=1, keepdims=True)  # Your Code\n",
        "\n",
        "        # Normalize inputs using their mean and standard deviation\n",
        "        self.norm = (A - self.mus)/(np.sqrt(self.vars) + self.eps)  # Your Code\n",
        "\n",
        "        # Return scaled and shifted versions of self.norm\n",
        "        return self.G * self.norm + self.B  # Your Code\n",
        "\n",
        "    def backward(self, dLdZ):\n",
        "        # Re-usable constants\n",
        "        std_inv = 1/np.sqrt(self.vars+self.eps)\n",
        "        A_min_mu = self.A-self.mus\n",
        "\n",
        "        dLdnorm = dLdZ * self.G\n",
        "        dLdVar = np.sum(dLdnorm * A_min_mu * -0.5 * std_inv**3, axis=1, keepdims=True)\n",
        "        dLdMu = np.sum(dLdnorm*(-std_inv), axis=1, keepdims=True) + dLdVar * (-2/self.K) * np.sum(A_min_mu, axis=1, keepdims=True)\n",
        "        dLdX = (dLdnorm * std_inv) + (dLdVar * (2/self.K) * A_min_mu) + (dLdMu/self.K)\n",
        "\n",
        "        self.dLdB = np.sum(dLdZ, axis=1, keepdims=True)\n",
        "        self.dLdG = np.sum(dLdZ * self.norm, axis=1, keepdims=True)\n",
        "        return dLdX\n",
        "\n",
        "    def step(self, lrate):\n",
        "        self.B = self.B - lrate*self.dLdB  # Your Code\n",
        "        self.G = self.G - lrate*self.dLdG  # Your Code\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65LKUAHD_77Y"
      },
      "source": [
        "# 3) 2D Datasets\n",
        "\n",
        "For the 2D datasets, we have provided the following function:\n",
        "\n",
        "\n",
        "```\n",
        "run_keras_2d(data_name, layers, epochs, split=0.25, display=True, trials=5)\n",
        "```\n",
        "\n",
        "\n",
        "where:\n",
        "\n",
        "data_name is a string, such as '1', '2', etc.\n",
        "layers is a list of Keras layer definitions for a Sequential model, e.g.\n",
        "```\n",
        "[Dense(input_dim=2, units=10, activation='relu'), Dense(units=2, activation='softmax')]\n",
        "```\n",
        "\n",
        "epochs is an integer indicating how many times to go through the data in training\n",
        "split is a fraction of the training data to use for validation if a validation set is not defined\n",
        "display whether to display result plots\n",
        "verbose whether to print loss and accuracy (percent correctly labeled) each epoch\n",
        "trials is an integer indicating how many times to perform the training and testing\n",
        "2D Data\n",
        "The two-class datasets have data_names: '1','2','3','4'. Target accuracies (percent correct) on the validation set are (99%, 90.5%, 96%, 94%).\n",
        "\n",
        "In this problem, try the following 5 architectures, specified by the number of units in the hidden layers:\n",
        "\n",
        "1: (0), 2: (10), 3: (100), 4: (10, 10), 5: (100, 100))\n",
        "You may find the archs function in the code file to be helpful here.\n",
        "Some of these questions ask for the \"simplest\" architecture; the list above is ordered starting with the simplest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R4IZ2XoGU0h"
      },
      "outputs": [],
      "source": [
        "import np_utils\n",
        "import pdb\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp-RWPD7FUeo"
      },
      "outputs": [],
      "source": [
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.compat.v1.keras.models import Sequential\n",
        "from tensorflow.compat.v1.keras.optimizers import SGD, Adam\n",
        "from tensorflow.compat.v1.keras.layers import Conv1D, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
        "from tensorflow.compat.v1.keras import utils\n",
        "from tensorflow.compat.v1.keras.callbacks import Callback\n",
        "from tensorflow.compat.v1.keras.datasets import mnist\n",
        "from tensorflow.compat.v1.keras.initializers import VarianceScaling\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow.keras.backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ano7Xnigy7e2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def run_keras_2d(data_name, layers, epochs, display=True, split=0.25, verbose=True, trials=1):\n",
        "    print('Keras FC: dataset=', data_name)\n",
        "    (train_dataset, val_dataset, test_dataset) = dataset_paths(data_name)\n",
        "\n",
        "    # Load the datasets\n",
        "    X_train, y, num_classes = get_data_set(train_dataset)\n",
        "    X_val, y2, _ = get_data_set(val_dataset)\n",
        "    X_test, y3, _ = get_data_set(test_dataset)\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    y_train = utils.to_categorical(y, num_classes)\n",
        "    y_val = utils.to_categorical(y2, num_classes) if X_val is not None else None\n",
        "    y_test = utils.to_categorical(y3, num_classes) if X_test is not None else None\n",
        "\n",
        "    val_acc, test_acc = 0, 0\n",
        "    for trial in range(trials):\n",
        "        # Reset the weights for TensorFlow 1.x compatibility\n",
        "        sess = tf.compat.v1.keras.backend.get_session()\n",
        "        for layer in layers:\n",
        "            for v in layer.__dict__:\n",
        "                v_arg = getattr(layer, v)\n",
        "                if hasattr(v_arg, 'initializer'):\n",
        "                    initializer_func = getattr(v_arg, 'initializer')\n",
        "                    initializer_func.run(session=sess)\n",
        "\n",
        "        # Run the model\n",
        "        model, history, vacc, tacc = run_keras(X_train, y_train, X_val, y_val, X_test, y_test, layers, epochs, split=split, verbose=verbose)\n",
        "        val_acc += vacc if vacc else 0\n",
        "        test_acc += tacc if tacc else 0\n",
        "\n",
        "        if display:\n",
        "            # Plot classifier landscape on training data\n",
        "            plot_heat(X_train, y, model)\n",
        "            plt.title('Training data')\n",
        "            plt.show()\n",
        "\n",
        "            if X_test is not None:\n",
        "                # Plot classifier landscape on testing data\n",
        "                plot_heat(X_test, y3, model)\n",
        "                plt.title('Testing data')\n",
        "                plt.show()\n",
        "\n",
        "            # Plot epoch loss\n",
        "            if 'epoch_loss' in history.values and 'epoch_val_loss' in history.values:\n",
        "                plt.plot(history.values['epoch_loss'], label='loss')\n",
        "                plt.plot(history.values['epoch_val_loss'], label='val_loss')\n",
        "                plt.xlabel('epoch')\n",
        "                plt.ylabel('loss')\n",
        "                plt.title('Epoch val_loss and loss')\n",
        "                plt.legend()\n",
        "                plt.show()\n",
        "\n",
        "            # Plot epoch accuracy\n",
        "            if 'epoch_acc' in history.values and 'epoch_val_acc' in history.values:\n",
        "                plt.plot(history.values['epoch_acc'], label='accuracy')\n",
        "                plt.plot(history.values['epoch_val_acc'], label='val_accuracy')\n",
        "                plt.xlabel('epoch')\n",
        "                plt.ylabel('accuracy')\n",
        "                plt.title('Epoch val_acc and acc')\n",
        "                plt.legend()\n",
        "                plt.show()\n",
        "\n",
        "    if val_acc:\n",
        "        print(\"\\nAvg. validation accuracy:\" + str(val_acc / trials))\n",
        "    if test_acc:\n",
        "        print(\"\\nAvg. test accuracy:\" + str(test_acc / trials))\n",
        "\n",
        "    return X_train, y, model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79NIEopsLzr2"
      },
      "outputs": [],
      "source": [
        "######################################################################\n",
        "# Problem 3 - 2D data\n",
        "######################################################################\n",
        "import tensorflow as tf\n",
        "\n",
        "def archs(classes):\n",
        "    return [\n",
        "        [tf.compat.v1.keras.layers.Dense(input_dim=2, units=classes, activation=\"softmax\")],\n",
        "        [tf.compat.v1.keras.layers.Dense(input_dim=2, units=10, activation='relu'),\n",
        "         tf.compat.v1.keras.layers.Dense(units=classes, activation=\"softmax\")],\n",
        "        [tf.compat.v1.keras.layers.Dense(input_dim=2, units=100, activation='relu'),\n",
        "         tf.compat.v1.keras.layers.Dense(units=classes, activation=\"softmax\")],\n",
        "        [tf.compat.v1.keras.layers.Dense(input_dim=2, units=10, activation='relu'),\n",
        "         tf.compat.v1.keras.layers.Dense(units=10, activation='relu'),\n",
        "         tf.compat.v1.keras.layers.Dense(units=classes, activation=\"softmax\")],\n",
        "        [tf.compat.v1.keras.layers.Dense(input_dim=2, units=100, activation='relu'),\n",
        "         tf.compat.v1.keras.layers.Dense(units=100, activation='relu'),\n",
        "         tf.compat.v1.keras.layers.Dense(units=classes, activation=\"softmax\")]\n",
        "    ]\n",
        "\n",
        "# Read the simple 2D dataset files\n",
        "def get_data_set(name):\n",
        "    try:\n",
        "        data = np.loadtxt(name, skiprows=0, delimiter = ' ')\n",
        "    except:\n",
        "        return None, None, None\n",
        "    np.random.shuffle(data)             # shuffle the data\n",
        "    # The data uses ROW vectors for a data point, that's what Keras assumes.\n",
        "    _, d = data.shape\n",
        "    X = data[:,0:d-1]\n",
        "    Y = data[:,d-1:d]\n",
        "    y = Y.T[0]\n",
        "    classes = set(y)\n",
        "    if classes == set([-1.0, 1.0]):\n",
        "        print('Convert from -1,1 to 0,1')\n",
        "        y = 0.5*(y+1)\n",
        "    print('Loading X', X.shape, 'y', y.shape, 'classes', set(y))\n",
        "    return X, y, len(classes)\n",
        "\n",
        "######################################################################\n",
        "# General helpers for Problems 3-5\n",
        "######################################################################\n",
        "\n",
        "class LossHistory(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.keys = ['loss', 'acc', 'val_loss', 'val_acc']\n",
        "        self.values = {}\n",
        "        for k in self.keys:\n",
        "            self.values['batch_'+k] = []\n",
        "            self.values['epoch_'+k] = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        for k in self.keys:\n",
        "            bk = 'batch_'+k\n",
        "            if k in logs:\n",
        "                self.values[bk].append(logs[k])\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        for k in self.keys:\n",
        "            ek = 'epoch_'+k\n",
        "            if k in logs:\n",
        "                self.values[ek].append(logs[k])\n",
        "\n",
        "    def plot(self, keys):\n",
        "        for key in keys:\n",
        "            plt.plot(np.arange(len(self.values[key])), np.array(self.values[key]), label=key)\n",
        "        plt.legend()\n",
        "\n",
        "    # Added function VMohire Sept 2024\n",
        "def run_keras(X_train, y_train, X_val, y_val, X_test, y_test, layers, epochs, split=0.25, verbose=True):\n",
        "    # Build the model\n",
        "    model = Sequential()\n",
        "    for layer in layers:\n",
        "        model.add(layer)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=32,\n",
        "                        validation_data=(X_val, y_val) if X_val is not None else None,\n",
        "                        verbose=verbose)\n",
        "\n",
        "    # Evaluate the model\n",
        "    if X_val is not None:\n",
        "        val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "    else:\n",
        "        val_loss, val_acc = None, None\n",
        "\n",
        "    if X_test is not None:\n",
        "        test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    else:\n",
        "        test_loss, test_acc = None, None\n",
        "\n",
        "    # Return the model, history, and accuracy/loss values\n",
        "    return model, history, val_acc, test_acc\n",
        "\n",
        "def dataset_paths(data_name):\n",
        "    return [\"data/data\"+data_name+\"_\"+suffix+\".csv\" for suffix in (\"train\", \"validate\", \"test\")]\n",
        "\n",
        "# The name is a string such as \"1\" or \"Xor\"\n",
        "def run_keras_2d(data_name, layers, epochs, display=True, split=0.25, verbose=True, trials=1):\n",
        "    print('Keras FC: dataset=', data_name)\n",
        "    (train_dataset, val_dataset, test_dataset) = dataset_paths(data_name)\n",
        "    # Load the datasets\n",
        "    X_train, y, num_classes = get_data_set(train_dataset)\n",
        "    X_val, y2, _ = get_data_set(val_dataset)\n",
        "    X_test, y3, _ = get_data_set(test_dataset)\n",
        "    # Categorize the labels\n",
        "    #y_train = np_utils.to_categorical(y, num_classes) # one-hot\n",
        "    y_train = utils.to_categorical(y, num_classes)   #VMohire Sept 2024\n",
        "    y_val = y_test = None\n",
        "    if X_val is not None:\n",
        "        #y_val = np_utils.to_categorical(y2, num_classes) # one-hot\n",
        "        y_val = utils.to_categorical(y2, num_classes)   #VMohire Sept 2024\n",
        "    if X_test is not None:\n",
        "        #y_test = np_utils.to_categorical(y3, num_classes) # one-hot\n",
        "        utils.to_categorical(y, num_classes)   #VMohire Sept 2024\n",
        "    val_acc, test_acc = 0, 0\n",
        "    for trial in range(trials):\n",
        "        # Reset the weights\n",
        "        # See https://github.com/keras-team/keras/issues/341\n",
        "        #session = K.get_session()\n",
        "        session = tf.compat.v1.keras.backend.get_session()\n",
        "        for layer in layers:\n",
        "            for v in layer.__dict__:\n",
        "                v_arg = getattr(layer, v)\n",
        "                if hasattr(v_arg, 'initializer'):\n",
        "                    initializer_func = getattr(v_arg, 'initializer')\n",
        "                    initializer_func.run(session=session)\n",
        "        # Run the model\n",
        "        model, history, vacc, tacc, = \\\n",
        "               run_keras(X_train, y_train, X_val, y_val, X_test, y_test, layers, epochs,\n",
        "                         split=split, verbose=verbose)\n",
        "        val_acc += vacc if vacc else 0\n",
        "        test_acc += tacc if tacc else 0\n",
        "        if display:\n",
        "            # plot classifier landscape on training data\n",
        "            plot_heat(X_train, y, model)\n",
        "            plt.title('Training data')\n",
        "            plt.show()\n",
        "            if X_test is not None:\n",
        "                # plot classifier landscape on testing data\n",
        "                plot_heat(X_test, y3, model)\n",
        "                plt.title('Testing data')\n",
        "                plt.show()\n",
        "            # Plot epoch loss\n",
        "            history.plot(['epoch_loss', 'epoch_val_loss'])\n",
        "            plt.xlabel('epoch')\n",
        "            plt.ylabel('loss')\n",
        "            plt.title('Epoch val_loss and loss')\n",
        "            plt.show()\n",
        "            # Plot epoch accuracy\n",
        "            history.plot(['epoch_acc', 'epoch_val_acc'])\n",
        "            plt.xlabel('epoch')\n",
        "            plt.ylabel('accuracy')\n",
        "            plt.title('Epoch val_acc and acc')\n",
        "            plt.show()\n",
        "    if val_acc:\n",
        "        print (\"\\nAvg. validation accuracy:\"  + str(val_acc/trials))\n",
        "    if test_acc:\n",
        "        print (\"\\nAvg. test accuracy:\"  + str(test_acc/trials))\n",
        "    return X_train, y, model\n",
        "\n",
        "######################################################################\n",
        "# Helper functions for\n",
        "# OPTIONAL: Problem 4 - Weight Sharing\n",
        "######################################################################\n",
        "\n",
        "def generate_1d_images(nsamples,image_size,prob):\n",
        "    Xs=[]\n",
        "    Ys=[]\n",
        "    for i in range(0,nsamples):\n",
        "        X=np.random.binomial(1, prob, size=image_size)\n",
        "        Y=count_objects_1d(X)\n",
        "        Xs.append(X)\n",
        "        Ys.append(Y)\n",
        "    Xs=np.array(Xs)\n",
        "    Ys=np.array(Ys)\n",
        "    return Xs,Ys\n",
        "\n",
        "\n",
        "#count the number of objects in a 1d array\n",
        "def count_objects_1d(array):\n",
        "    count=0\n",
        "    for i in range(len(array)):\n",
        "        num=array[i]\n",
        "        if num==0:\n",
        "            if i==0 or array[i-1]==1:\n",
        "                count+=1\n",
        "    return count\n",
        "\n",
        "def l1_reg(weight_matrix):\n",
        "    return 0.01 * K.sum(K.abs(weight_matrix))\n",
        "\n",
        "\n",
        "def filter_reg(weights):\n",
        "    lam=0\n",
        "    return lam* val\n",
        "\n",
        "def get_image_data_1d(tsize,image_size,prob):\n",
        "    #prob controls the density of white pixels\n",
        "    #tsize is the size of the training and test sets\n",
        "    vsize=int(0.2*tsize)\n",
        "    X_train,Y_train=generate_1d_images(tsize,image_size,prob)\n",
        "    X_val,Y_val=generate_1d_images(vsize,image_size,prob)\n",
        "    X_test,Y_test=generate_1d_images(tsize,image_size,prob)\n",
        "    #reshape the input data for the convolutional layer\n",
        "    X_train=np.expand_dims(X_train,axis=2)\n",
        "    X_val=np.expand_dims(X_val,axis=2)\n",
        "    X_test=np.expand_dims(X_test,axis=2)\n",
        "    data=(X_train,Y_train,X_val,Y_val,X_test,Y_test)\n",
        "    return data\n",
        "\n",
        "def train_neural_counter(layers,data,loss_func='mse',display=False):\n",
        "    (X_train,Y_train,X_val,Y_val,X_test,Y_test)=data\n",
        "    epochs=10\n",
        "    batch=1\n",
        "\n",
        "    model=Sequential()\n",
        "    for layer in layers:\n",
        "        model.add(layer)\n",
        "    model.summary()\n",
        "    model.compile(loss=loss_func, optimizer=Adam())\n",
        "    history = LossHistory()\n",
        "    model.fit(X_train, Y_train, epochs=epochs, batch_size=batch, validation_data=(X_val, Y_val),callbacks=[history], verbose=True)\n",
        "    err=model.evaluate(X_test,Y_test)\n",
        "    ws=model.layers[-1].get_weights()[0]\n",
        "    if display:\n",
        "        plt.plot(ws)\n",
        "        plt.show()\n",
        "    return model,err\n",
        "\n",
        "######################################################################\n",
        "# Problem 5\n",
        "######################################################################\n",
        "\n",
        "def shifted(X, shift):\n",
        "    n = X.shape[0]\n",
        "    m = X.shape[1]\n",
        "    size = m + shift\n",
        "    X_sh = np.zeros((n, size, size))\n",
        "    plt.ion()\n",
        "    for i in range(n):\n",
        "        sh1 = np.random.randint(shift)\n",
        "        sh2 = np.random.randint(shift)\n",
        "        X_sh[i, sh1:sh1+m, sh2:sh2+m] = X[i, :, :]\n",
        "        # If you want to see the shifts, uncomment\n",
        "        #plt.figure(1); plt.imshow(X[i])\n",
        "        #plt.figure(2); plt.imshow(X_sh[i])\n",
        "        #plt.show()\n",
        "        #input('Go?')\n",
        "    return X_sh\n",
        "\n",
        "def get_MNIST_data(shift=0):\n",
        "    (X_train, y1), (X_val, y2) = mnist.load_data()\n",
        "    if shift:\n",
        "        size = 28+shift\n",
        "        X_train = shifted(X_train, shift)\n",
        "        X_val = shifted(X_val, shift)\n",
        "    return (X_train, y1), (X_val, y2)\n",
        "\n",
        "# Example Usage:\n",
        "# train, validation = get_MNIST_data()\n",
        "\n",
        "def run_keras_fc_mnist(train, test, layers, epochs, split=0.1, verbose=True, trials=1):\n",
        "    (X_train, y1), (X_val, y2) = train, test\n",
        "    # Flatten the images\n",
        "    m = X_train.shape[1]\n",
        "    X_train = X_train.reshape((X_train.shape[0], m*m))\n",
        "    X_val = X_val.reshape((X_val.shape[0], m*m))\n",
        "    # Categorize the labels\n",
        "    num_classes = 10\n",
        "    y_train = np_utils.to_categorical(y1, num_classes)\n",
        "    y_val = np_utils.to_categorical(y2, num_classes)\n",
        "    # Train, use split for validation\n",
        "    val_acc, test_acc = 0, 0\n",
        "    for trial in range(trials):\n",
        "        # Reset the weights\n",
        "        # See https://github.com/keras-team/keras/issues/341\n",
        "        #session = K.get_session()\n",
        "        session = tf.compat.v1.keras.backend.get_session()\n",
        "        for layer in layers:\n",
        "            for v in layer.__dict__:\n",
        "                v_arg = getattr(layer, v)\n",
        "                if hasattr(v_arg, 'initializer'):\n",
        "                    initializer_func = getattr(v_arg, 'initializer')\n",
        "                    initializer_func.run(session=session)\n",
        "        # Run the model\n",
        "        model, history, vacc, tacc = \\\n",
        "                run_keras(X_train, y_train, X_val, y_val, None, None, layers, epochs, split=split, verbose=verbose)\n",
        "        val_acc += vacc if vacc else 0\n",
        "        test_acc += tacc if tacc else 0\n",
        "    if val_acc:\n",
        "        print (\"\\nAvg. validation accuracy:\"  + str(val_acc/trials))\n",
        "    if test_acc:\n",
        "        print (\"\\nAvg. test accuracy:\"  + str(test_acc/trials))\n",
        "\n",
        "def run_keras_cnn_mnist(train, test, layers, epochs, split=0.1, verbose=True, trials=1):\n",
        "    # Load the dataset\n",
        "    (X_train, y1), (X_val, y2) = train, test\n",
        "    # Add a final dimension indicating the number of channels (only 1 here)\n",
        "    m = X_train.shape[1]\n",
        "    X_train = X_train.reshape((X_train.shape[0], m, m, 1))\n",
        "    X_val = X_val.reshape((X_val.shape[0], m, m, 1))\n",
        "    # Categorize the labels\n",
        "    num_classes = 10\n",
        "    y_train = np_utils.to_categorical(y1, num_classes)\n",
        "    y_val = np_utils.to_categorical(y2, num_classes)\n",
        "    # Train, use split for validation\n",
        "    val_acc, test_acc = 0, 0\n",
        "    for trial in range(trials):\n",
        "        # Reset the weights\n",
        "        # See https://github.com/keras-team/keras/issues/341\n",
        "        #session = K.get_session()\n",
        "        session = tf.compat.v1.keras.backend.get_session()\n",
        "        for layer in layers:\n",
        "            for v in layer.__dict__:\n",
        "                v_arg = getattr(layer, v)\n",
        "                if hasattr(v_arg, 'initializer'):\n",
        "                    initializer_func = getattr(v_arg, 'initializer')\n",
        "                    initializer_func.run(session=session)\n",
        "        # Run the model\n",
        "        model, history, vacc, tacc = \\\n",
        "                run_keras(X_train, y_train, X_val, y_val, None, None, layers, epochs, split=split, verbose=verbose)\n",
        "        val_acc += vacc if vacc else 0\n",
        "        test_acc += tacc if tacc else 0\n",
        "    if val_acc:\n",
        "        print (\"\\nAvg. validation accuracy:\"  + str(val_acc/trials))\n",
        "    if test_acc:\n",
        "        print (\"\\nAvg. test accuracy:\"  + str(test_acc/trials))\n",
        "\n",
        "# Example usage:\n",
        "# train, validation = get_MNIST_data()\n",
        "# layers = [Dense(input_dim=???, units=???, activation='softmax')]\n",
        "# run_keras_fc_mnist(train, validation, layers, 1, split=0.1, verbose=True, trials=5)\n",
        "# Same pattern applies to the function: run_keras_cnn_mnist\n",
        "\n",
        "######################################################################\n",
        "# Plotting Functions\n",
        "######################################################################\n",
        "\n",
        "def plot_heat(X, y, model, res = 200):\n",
        "    eps = .1\n",
        "    xmin = np.min(X[:,0]) - eps; xmax = np.max(X[:,0]) + eps\n",
        "    ymin = np.min(X[:,1]) - eps; ymax = np.max(X[:,1]) + eps\n",
        "    ax = tidyPlot(xmin, xmax, ymin, ymax, xlabel = 'x', ylabel = 'y')\n",
        "    xl = np.linspace(xmin, xmax, res)\n",
        "    yl = np.linspace(ymin, ymax, res)\n",
        "    xx, yy = np.meshgrid(xl, yl, sparse=False)\n",
        "    zz = np.argmax(model.predict(np.c_[xx.ravel(), yy.ravel()]), axis=1)\n",
        "    im = ax.imshow(np.flipud(zz.reshape((res,res))), interpolation = 'none',\n",
        "                   extent = [xmin, xmax, ymin, ymax],\n",
        "                   cmap = 'viridis')\n",
        "    plt.colorbar(im)\n",
        "    for yi in set([int(_y) for _y in set(y)]):\n",
        "        color = ['r', 'g', 'b'][yi]\n",
        "        marker = ['X', 'o', 'v'][yi]\n",
        "        cl = np.where(y==yi)\n",
        "        ax.scatter(X[cl,0], X[cl,1], c = color, marker = marker, s=80,\n",
        "                   edgecolors = 'none')\n",
        "    return ax\n",
        "\n",
        "def tidyPlot(xmin, xmax, ymin, ymax, center = False, title = None,\n",
        "                 xlabel = None, ylabel = None):\n",
        "    plt.figure(facecolor=\"white\")\n",
        "    ax = plt.subplot()\n",
        "    if center:\n",
        "        ax.spines['left'].set_position('zero')\n",
        "        ax.spines['right'].set_color('none')\n",
        "        ax.spines['bottom'].set_position('zero')\n",
        "        ax.spines['top'].set_color('none')\n",
        "        ax.spines['left'].set_smart_bounds(True)\n",
        "        ax.spines['bottom'].set_smart_bounds(True)\n",
        "        ax.xaxis.set_ticks_position('bottom')\n",
        "        ax.yaxis.set_ticks_position('left')\n",
        "    else:\n",
        "        ax.spines[\"top\"].set_visible(False)\n",
        "        ax.spines[\"right\"].set_visible(False)\n",
        "        ax.get_xaxis().tick_bottom()\n",
        "        ax.get_yaxis().tick_left()\n",
        "    eps = .05\n",
        "    plt.xlim(xmin-eps, xmax+eps)\n",
        "    plt.ylim(ymin-eps, ymax+eps)\n",
        "    if title: ax.set_title(title)\n",
        "    if xlabel: ax.set_xlabel(xlabel)\n",
        "    if ylabel: ax.set_ylabel(ylabel)\n",
        "    return ax\n",
        "\n",
        "def plot_separator(ax, th, th_0):\n",
        "    xmin, xmax = ax.get_xlim()\n",
        "    ymin,ymax = ax.get_ylim()\n",
        "    pts = []\n",
        "    eps = 1.0e-6\n",
        "    # xmin boundary crossing is when xmin th[0] + y th[1] + th_0 = 0\n",
        "    # that is, y = (-th_0 - xmin th[0]) / th[1]\n",
        "    if abs(th[1,0]) > eps:\n",
        "        pts += [np.array([x, (-th_0 - x * th[0,0]) / th[1,0]]) \\\n",
        "                                                        for x in (xmin, xmax)]\n",
        "    if abs(th[0,0]) > 1.0e-6:\n",
        "        pts += [np.array([(-th_0 - y * th[1,0]) / th[0,0], y]) \\\n",
        "                                                         for y in (ymin, ymax)]\n",
        "    in_pts = []\n",
        "    for p in pts:\n",
        "        if (xmin-eps) <= p[0] <= (xmax+eps) and \\\n",
        "           (ymin-eps) <= p[1] <= (ymax+eps):\n",
        "            duplicate = False\n",
        "            for p1 in in_pts:\n",
        "                if np.max(np.abs(p - p1)) < 1.0e-6:\n",
        "                    duplicate = True\n",
        "            if not duplicate:\n",
        "                in_pts.append(p)\n",
        "    if in_pts and len(in_pts) >= 2:\n",
        "        # Plot separator\n",
        "        vpts = np.vstack(in_pts)\n",
        "        ax.plot(vpts[:,0], vpts[:,1], 'k-', lw=2)\n",
        "        # Plot normal\n",
        "        vmid = 0.5*(in_pts[0] + in_pts[1])\n",
        "        scale = np.sum(th*th)**0.5\n",
        "        diff = in_pts[0] - in_pts[1]\n",
        "        dist = max(xmax-xmin, ymax-ymin)\n",
        "        vnrm = vmid + (dist/10)*(th.T[0]/scale)\n",
        "        vpts = np.vstack([vmid, vnrm])\n",
        "        ax.plot(vpts[:,0], vpts[:,1], 'k-', lw=2)\n",
        "        # Try to keep limits from moving around\n",
        "        ax.set_xlim((xmin, xmax))\n",
        "        ax.set_ylim((ymin, ymax))\n",
        "    else:\n",
        "        print('Separator not in plot range')\n",
        "\n",
        "def plot_decision(data, cl, diff=False):\n",
        "    layers = archs(cl)[0]\n",
        "    X, y, model = run_keras_2d(data, layers, 10, trials=1, verbose=False, display=False)\n",
        "    ax = plot_heat(X,y,model)\n",
        "    W = layers[0].get_weights()[0]\n",
        "    W0 = layers[0].get_weights()[1].reshape((cl,1))\n",
        "    if diff:\n",
        "        for i,j in list(itertools.combinations(range(cl),2)):\n",
        "            plot_separator(ax, W[:,i:i+1] - W[:,j:j+1], W0[i:i+1,:] - W0[j:j+1,:])\n",
        "    else:\n",
        "        for i in range(cl):\n",
        "            plot_separator(ax, W[:,i:i+1], W0[i:i+1,:])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YWbWX47_9Tr",
        "outputId": "cfde9af0-6cee-4f48-ea3b-d9f4e532fd20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keras FC: dataset= 3\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy:0.9399999976158142\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([[ 2.68572445e-01,  9.19915554e-01],\n",
              "        [-2.48121610e+00, -1.36699313e+00],\n",
              "        [ 5.56595729e-01, -9.68298445e-01],\n",
              "        [ 1.25180445e+00, -1.31323403e+00],\n",
              "        [ 1.49791013e+00, -9.05810242e-01],\n",
              "        [ 5.31870945e-01,  6.12922734e-03],\n",
              "        [ 1.83689989e-01, -2.78607469e-01],\n",
              "        [ 1.63904127e-01,  8.16453466e-01],\n",
              "        [-4.14832677e-01, -7.61685543e-01],\n",
              "        [ 9.89600289e-01,  1.26694159e+00],\n",
              "        [ 8.37403896e-01,  7.07465258e-01],\n",
              "        [-6.40393302e-02, -2.09756863e-01],\n",
              "        [ 1.03949361e+00, -9.53568987e-01],\n",
              "        [ 1.05421974e+00, -1.32045158e+00],\n",
              "        [ 3.80551397e+00,  1.49137866e-01],\n",
              "        [ 5.75533547e-01, -1.77035812e+00],\n",
              "        [-3.27830527e-01,  1.18556267e+00],\n",
              "        [ 1.49376800e-01,  6.48015791e-01],\n",
              "        [ 1.27208381e-01,  1.33817514e+00],\n",
              "        [-2.84390861e-01,  1.28516740e-01],\n",
              "        [-2.91308358e-01, -1.32297240e+00],\n",
              "        [-1.18857664e+00,  1.33689522e+00],\n",
              "        [ 2.40553070e-01,  7.52439524e-01],\n",
              "        [ 4.81312605e-01,  9.71724691e-01],\n",
              "        [ 9.64624265e-01, -1.72598657e+00],\n",
              "        [ 1.98167116e-01,  1.19834281e+00],\n",
              "        [-5.14657260e-01,  1.25692322e+00],\n",
              "        [-4.93084898e-01,  7.83595885e-01],\n",
              "        [-5.68201865e-01,  9.97233331e-01],\n",
              "        [-1.11206353e+00, -1.69493671e+00],\n",
              "        [-2.58962352e-01,  9.36627693e-01],\n",
              "        [-2.80759883e-01, -6.54796310e-01],\n",
              "        [-1.80086374e-01, -1.62109929e+00],\n",
              "        [-1.02646091e+00,  7.30186986e-01],\n",
              "        [-9.66556680e-02,  1.17882331e+00],\n",
              "        [ 4.86250026e-01, -1.56351910e+00],\n",
              "        [ 1.34281872e+00, -1.98908865e+00],\n",
              "        [ 6.37641117e-01,  9.24521718e-01],\n",
              "        [-9.00916800e-01,  1.09612133e+00],\n",
              "        [-1.60947813e+00,  1.00125605e+00],\n",
              "        [ 2.01124258e+00, -6.50151870e-01],\n",
              "        [ 6.21830757e-01,  1.03110956e+00],\n",
              "        [-9.51855250e-01, -2.25623806e+00],\n",
              "        [ 1.51944832e+00,  6.69433159e-01],\n",
              "        [-1.56887718e+00,  1.58366785e+00],\n",
              "        [-7.19309633e-01, -9.10266737e-01],\n",
              "        [-5.33350199e-01, -7.01342176e-01],\n",
              "        [-9.89379259e-01,  1.43420494e+00],\n",
              "        [ 1.64094544e+00, -7.78994384e-01],\n",
              "        [-9.97925058e-01,  7.41648174e-01],\n",
              "        [ 2.02584111e+00,  4.63471587e-03],\n",
              "        [ 1.63713564e+00, -2.17432334e+00],\n",
              "        [-4.73362117e-01,  5.83668048e-01],\n",
              "        [-8.55522699e-01, -4.78157321e-01],\n",
              "        [-3.92251702e-01, -5.99675561e-01],\n",
              "        [-8.76150821e-01,  9.38246134e-01],\n",
              "        [ 4.82131302e-01, -7.66786885e-01],\n",
              "        [ 4.51101916e-01,  1.05104320e+00],\n",
              "        [ 3.70332689e-01, -2.35719846e+00],\n",
              "        [-1.00421449e+00,  9.21219259e-01],\n",
              "        [-6.46615721e-02,  7.29392228e-01],\n",
              "        [-1.79255442e-01,  9.04111402e-01],\n",
              "        [-1.40386913e+00, -1.02071773e+00],\n",
              "        [ 8.71930256e-01,  9.44092465e-01],\n",
              "        [ 2.69701928e-01, -3.44847643e-01],\n",
              "        [-1.14015107e+00,  6.75329607e-01],\n",
              "        [-1.15840553e+00,  1.15352059e+00],\n",
              "        [-7.32381388e-01, -3.16439954e-01],\n",
              "        [ 5.01637382e-02, -1.86205461e-01],\n",
              "        [ 3.11442245e-01,  1.10354795e+00],\n",
              "        [-1.64588447e+00, -1.79336505e+00],\n",
              "        [-1.10963737e+00, -7.21441528e-01],\n",
              "        [ 1.47028284e+00, -1.02889795e+00],\n",
              "        [-6.09169793e-01,  1.21864793e+00],\n",
              "        [-1.54337318e+00, -5.27867198e-01],\n",
              "        [-1.24643954e+00,  1.49863868e-01],\n",
              "        [-3.23073838e-01, -1.53094630e+00],\n",
              "        [-8.19227913e-01,  1.13638010e+00],\n",
              "        [-8.98607781e-01,  1.32135061e+00],\n",
              "        [-3.98901569e-01, -1.37282347e+00],\n",
              "        [ 2.84183705e-01,  9.97209950e-01],\n",
              "        [ 3.07141783e-01, -5.24623805e-01],\n",
              "        [-1.94083970e-01,  1.25165885e+00],\n",
              "        [ 7.15681337e-01, -7.61277410e-02],\n",
              "        [-9.67562269e-02, -1.04634812e+00],\n",
              "        [ 1.22280969e+00, -6.34011641e-01],\n",
              "        [ 1.61815412e+00, -1.41098154e+00],\n",
              "        [ 1.65836601e-01,  1.04371696e+00],\n",
              "        [ 1.56110391e+00, -4.70849410e-01],\n",
              "        [-6.44300389e-01,  1.14495920e+00],\n",
              "        [-2.81881752e-01, -8.84938507e-01],\n",
              "        [ 2.97069152e-01, -1.18341697e+00],\n",
              "        [-7.36329438e-01,  8.31344915e-01],\n",
              "        [-6.25363136e-01, -2.16919689e+00],\n",
              "        [ 7.10252376e-01,  1.10546805e+00],\n",
              "        [ 2.27937491e+00, -5.31454264e-01],\n",
              "        [-8.71517413e-02, -1.67901807e+00],\n",
              "        [ 1.84385841e+00, -1.19911559e+00],\n",
              "        [ 1.53031689e+00, -1.42527722e+00],\n",
              "        [-1.89499918e-01,  8.55965739e-01],\n",
              "        [-1.28541366e+00,  8.89537258e-01],\n",
              "        [ 1.08570167e+00, -9.29783088e-01],\n",
              "        [ 1.10434286e+00, -1.11628861e+00],\n",
              "        [-1.44035415e+00,  1.00674819e+00],\n",
              "        [-2.21627523e+00, -1.43020809e+00],\n",
              "        [ 2.22795714e+00,  1.13783995e+00],\n",
              "        [ 7.82625350e-02,  7.77665351e-01],\n",
              "        [-1.00263655e+00,  6.72766167e-01],\n",
              "        [ 4.51483402e-01,  6.79791225e-01],\n",
              "        [-1.33650871e-01, -9.32036395e-01],\n",
              "        [ 2.70581984e-01,  8.32604236e-01],\n",
              "        [ 2.83963318e-01,  1.12920018e+00],\n",
              "        [ 1.09315404e+00,  1.25350731e+00],\n",
              "        [-5.66103130e-02, -1.74011165e+00],\n",
              "        [ 3.27494621e+00, -3.78799528e-01],\n",
              "        [-2.60818351e-02,  1.01596097e+00],\n",
              "        [ 7.24363038e-01, -3.74497572e-01],\n",
              "        [ 2.97793904e-01,  9.73662817e-01],\n",
              "        [-8.88840612e-01,  9.57599953e-01],\n",
              "        [ 5.41193475e-01, -1.16136205e+00],\n",
              "        [-1.25241081e-01,  7.65571558e-01],\n",
              "        [-1.14914412e-01, -1.66416399e-01],\n",
              "        [-1.59015462e+00,  7.44042740e-02],\n",
              "        [-2.94792699e-01, -6.86119747e-01],\n",
              "        [-2.43518124e+00, -1.33467556e+00],\n",
              "        [ 4.61412128e-01,  1.62721884e+00],\n",
              "        [-1.22825580e+00,  6.62205401e-01],\n",
              "        [-8.19510632e-01,  9.16036256e-01],\n",
              "        [-4.83400521e-01,  5.84297393e-01],\n",
              "        [ 1.40697557e+00,  8.38761777e-01],\n",
              "        [-1.66460869e+00, -9.50342075e-01],\n",
              "        [ 1.44416641e+00,  3.36156387e-01],\n",
              "        [-2.48854241e+00,  6.00533278e-01],\n",
              "        [ 6.10165824e-01, -7.02758659e-01],\n",
              "        [ 1.25901523e+00,  1.11166169e+00],\n",
              "        [-1.77364406e-01, -9.63714670e-01],\n",
              "        [-1.48038581e+00,  1.05573465e+00],\n",
              "        [-2.62825570e+00, -1.17227297e+00],\n",
              "        [ 1.07186791e+00, -6.00332252e-01],\n",
              "        [ 6.91740501e-01,  9.32466520e-01],\n",
              "        [ 3.56311070e-01, -1.83422288e+00],\n",
              "        [ 2.52094708e+00,  1.11913471e+00],\n",
              "        [ 1.12891929e-01,  9.84968701e-01],\n",
              "        [ 7.76414305e-01, -7.84042128e-01],\n",
              "        [-1.27959872e-01,  1.42780257e+00],\n",
              "        [-6.11864335e-01, -3.04394204e-01],\n",
              "        [ 2.82678103e-01, -1.52199667e+00],\n",
              "        [-3.73398803e-02, -1.92251617e+00],\n",
              "        [-2.19315340e-01,  1.31915105e+00],\n",
              "        [-1.17264210e+00, -2.10489761e+00],\n",
              "        [-5.62743687e-01,  1.05045366e+00],\n",
              "        [ 1.92377126e-01, -1.50177035e-01],\n",
              "        [-1.40281568e+00, -9.50144300e-01],\n",
              "        [-1.60869714e+00,  1.04500028e+00],\n",
              "        [-6.74971949e-01,  1.23686691e+00],\n",
              "        [ 7.58980601e-01,  1.17926749e+00],\n",
              "        [-9.15863874e-01,  1.16368824e+00],\n",
              "        [ 7.44323809e-01, -1.11690801e+00],\n",
              "        [-1.55593397e+00,  1.54091974e+00],\n",
              "        [ 3.31873096e-01,  1.16156475e+00],\n",
              "        [-3.13859609e-01,  1.08169038e+00],\n",
              "        [ 3.43319427e-01, -1.58022728e+00],\n",
              "        [-1.12435698e+00, -4.30035232e-01],\n",
              "        [-5.97566850e-01, -2.36224337e-01],\n",
              "        [ 2.56817317e+00,  1.00347317e+00],\n",
              "        [-1.92028794e-01,  6.18618137e-01],\n",
              "        [-3.12358157e-01, -1.47095439e+00],\n",
              "        [ 2.89462527e-01,  8.06161465e-01],\n",
              "        [-1.03777338e+00,  8.71249143e-01],\n",
              "        [ 1.62752185e-01,  9.21716731e-01],\n",
              "        [ 1.15606866e-01,  6.01664637e-01],\n",
              "        [ 1.30783537e+00,  8.72599493e-01],\n",
              "        [-1.34882284e+00, -2.41377262e+00],\n",
              "        [ 8.29727566e-01, -1.71167084e+00],\n",
              "        [-6.07685719e-01, -9.00295674e-01],\n",
              "        [-2.69641336e-01, -1.31882248e+00],\n",
              "        [ 5.25962696e-01, -2.00777506e+00],\n",
              "        [ 1.43637773e+00,  8.88204900e-01],\n",
              "        [ 6.12599632e-01, -6.08357600e-01],\n",
              "        [-1.69731484e-02, -1.73171939e+00],\n",
              "        [-4.98048222e-01, -2.05324570e+00],\n",
              "        [ 1.99083423e+00,  7.39232662e-01],\n",
              "        [ 4.42338898e-01, -7.90399307e-01],\n",
              "        [-2.66744646e-01,  1.24707267e+00],\n",
              "        [-1.21620968e+00,  6.83049065e-01],\n",
              "        [-8.72351116e-01,  6.33199395e-01],\n",
              "        [ 8.49637322e-01, -1.29314599e-01],\n",
              "        [ 1.32115979e+00,  1.08700327e+00],\n",
              "        [-6.21091558e-03, -1.53802337e+00],\n",
              "        [-5.12638604e-01, -1.66997181e+00],\n",
              "        [-6.36989768e-01,  8.95222556e-01],\n",
              "        [ 9.33095520e-02, -1.34614077e+00],\n",
              "        [ 3.38379307e-01,  1.31134144e+00],\n",
              "        [-2.78095935e+00,  1.33528844e+00],\n",
              "        [ 2.88990304e-01, -3.04575699e-01],\n",
              "        [ 1.20849816e+00, -5.16103953e-01],\n",
              "        [-9.49084956e-01,  1.13001262e+00],\n",
              "        [ 1.24379850e+00, -1.24186239e+00],\n",
              "        [ 1.80089979e-01,  8.68041199e-01],\n",
              "        [-1.37496427e+00, -2.14360387e+00],\n",
              "        [-1.26693058e-01, -7.50666180e-01],\n",
              "        [ 1.00844652e+00,  1.30543156e+00],\n",
              "        [-5.98009083e-02,  8.22694316e-01],\n",
              "        [-1.91133900e-01, -1.35711833e+00],\n",
              "        [-1.10192400e-01, -1.62969750e+00],\n",
              "        [-2.77688414e-01, -7.44748537e-01],\n",
              "        [ 6.06949123e-01, -1.92695095e+00],\n",
              "        [ 3.76946605e-03, -2.19287900e+00],\n",
              "        [ 1.55592533e+00,  9.77496170e-01],\n",
              "        [-1.56985091e+00,  1.81721816e-01],\n",
              "        [-7.03010715e-01, -8.36794524e-01],\n",
              "        [-1.30422169e-01, -8.92018698e-01],\n",
              "        [-1.67530495e+00,  1.03949695e+00],\n",
              "        [ 4.74916742e-01, -1.14933559e+00],\n",
              "        [-5.02895716e-01,  1.03914579e+00],\n",
              "        [-5.01996284e-02,  9.92626678e-01],\n",
              "        [ 1.02885868e+00,  1.03520193e+00],\n",
              "        [ 2.18459391e+00,  9.08547003e-01],\n",
              "        [ 4.20037118e-01,  1.03254396e+00],\n",
              "        [ 1.13615505e+00,  9.34159707e-01],\n",
              "        [-1.45586427e+00,  1.06759553e+00],\n",
              "        [ 1.26251243e+00, -1.33798222e+00],\n",
              "        [ 4.82659146e-01, -1.18185819e+00],\n",
              "        [ 1.66128608e+00,  1.59085862e+00],\n",
              "        [ 1.03489991e+00,  1.19767297e+00],\n",
              "        [-1.10877497e+00,  1.14858995e+00],\n",
              "        [-1.95634261e-02,  1.08597651e+00],\n",
              "        [-5.76529670e-01, -9.03522018e-01],\n",
              "        [ 2.98144973e-01,  5.57058930e-01],\n",
              "        [-2.06423656e+00, -1.49811482e+00],\n",
              "        [ 6.42911514e-01,  9.43444347e-01],\n",
              "        [-9.45670383e-01,  2.91358459e-01],\n",
              "        [-9.78487004e-01,  1.33753667e+00],\n",
              "        [ 1.55798065e-01,  9.80926148e-01],\n",
              "        [-5.62944237e-01, -1.81517397e+00],\n",
              "        [ 7.50266447e-01,  4.23964853e-01],\n",
              "        [ 5.10668351e-01,  1.43624362e+00],\n",
              "        [ 8.70593920e-02,  1.16291413e+00],\n",
              "        [-1.06101136e+00,  9.01626186e-01],\n",
              "        [-3.55639647e-02,  1.26847710e+00],\n",
              "        [ 4.96845017e-01,  8.59549327e-01],\n",
              "        [-2.07979093e+00,  3.40368771e-01],\n",
              "        [ 2.15120831e-01, -1.07328215e+00],\n",
              "        [-6.57027257e-01,  1.04703625e+00],\n",
              "        [-1.91870264e+00, -9.72408379e-01],\n",
              "        [ 7.74967979e-01, -5.45248881e-02],\n",
              "        [-8.59917131e-01, -7.74332383e-01],\n",
              "        [-5.15713362e-01, -2.05668156e+00],\n",
              "        [ 5.93103644e-01,  1.20379038e+00],\n",
              "        [ 6.65228620e-01,  1.05274437e+00],\n",
              "        [ 9.04075035e-01, -4.19988897e-01],\n",
              "        [ 2.33610938e-02, -1.84518665e+00],\n",
              "        [ 4.17050342e-01,  1.06947274e+00],\n",
              "        [-5.30929289e-01,  1.37027026e+00],\n",
              "        [-2.79335783e-01, -8.87909018e-01],\n",
              "        [-5.89184200e-01, -7.13968242e-01],\n",
              "        [-1.47108290e+00,  9.47191900e-01],\n",
              "        [ 1.61892082e-02,  7.50985464e-01],\n",
              "        [-5.10468330e-01,  7.41753970e-01],\n",
              "        [ 3.60688993e-01, -1.41913281e+00],\n",
              "        [-8.60042024e-01,  6.82399393e-01],\n",
              "        [ 1.99009149e+00,  9.04658862e-01],\n",
              "        [ 1.62749494e+00, -1.17694401e+00],\n",
              "        [-7.36954920e-01, -1.99090996e+00],\n",
              "        [ 3.19006021e-01,  7.05395797e-01],\n",
              "        [-3.44366268e-01, -1.36434668e+00],\n",
              "        [-1.55859064e-01, -9.93383540e-01],\n",
              "        [-1.05234752e+00, -1.19191135e+00],\n",
              "        [-1.10907769e+00,  6.14530338e-01],\n",
              "        [ 1.34999576e+00,  5.94932219e-01],\n",
              "        [ 6.44335216e-01, -9.07492218e-01],\n",
              "        [-1.72375519e+00, -7.07488608e-01],\n",
              "        [-4.72235332e-02,  1.12898458e+00],\n",
              "        [ 1.15960716e+00, -1.52652878e+00],\n",
              "        [-1.78366045e-01,  1.05159727e+00],\n",
              "        [-9.22451178e-01,  1.55938011e+00],\n",
              "        [ 4.45047706e-01, -8.43962960e-01],\n",
              "        [ 1.24118132e-01, -1.30177445e+00],\n",
              "        [-1.29854547e+00, -1.78213954e+00],\n",
              "        [ 1.52537231e+00, -7.05544863e-01],\n",
              "        [-3.38696894e-01,  2.09506699e-01],\n",
              "        [ 3.39483309e-01, -1.53777198e+00],\n",
              "        [ 1.45250817e+00, -1.98062295e+00],\n",
              "        [ 3.71876077e-01,  1.20938305e+00],\n",
              "        [-1.47834412e+00, -4.58217735e-01],\n",
              "        [-6.04300483e-01, -1.27031016e+00],\n",
              "        [-9.03762539e-01, -1.97830405e+00],\n",
              "        [ 4.04713428e-01,  1.39722625e+00],\n",
              "        [-1.74711514e-01, -2.36960028e+00],\n",
              "        [-4.21253088e-01, -8.18917818e-01],\n",
              "        [ 1.03397734e+00,  9.94625504e-01],\n",
              "        [-9.10797208e-01, -1.51408134e+00],\n",
              "        [ 1.17643799e+00, -7.50069105e-02],\n",
              "        [ 3.17664339e-01,  1.14073734e+00],\n",
              "        [-1.42672828e+00, -1.68955108e+00],\n",
              "        [-1.24458639e+00,  7.30610549e-01],\n",
              "        [-6.38776473e-01, -1.49137041e+00],\n",
              "        [ 6.65546340e-01, -4.87610678e-01],\n",
              "        [ 6.13678993e-01, -1.17730862e+00],\n",
              "        [-1.55601351e-01, -4.15193470e-01],\n",
              "        [-1.02974722e+00,  8.08029008e-01],\n",
              "        [ 1.10961771e+00, -1.71291812e+00],\n",
              "        [ 7.74771870e-01, -1.12994088e+00],\n",
              "        [-1.47211524e-01, -6.12836186e-01],\n",
              "        [-6.37157920e-01, -4.27618581e-01],\n",
              "        [-6.50672262e-01,  1.22474875e+00],\n",
              "        [ 2.97567420e-02, -1.70729600e+00],\n",
              "        [-9.28369699e-01,  1.09835499e+00],\n",
              "        [-1.07412296e-01,  1.18497910e+00],\n",
              "        [ 1.53758454e+00,  4.26999405e-01],\n",
              "        [ 5.05644320e-01, -1.31135357e+00],\n",
              "        [ 8.09768501e-01,  1.25234471e+00],\n",
              "        [-1.09673065e-01, -9.38314921e-01],\n",
              "        [ 1.02194219e+00, -5.46483705e-01],\n",
              "        [-9.70534473e-01,  1.13151763e+00],\n",
              "        [-4.22725606e-01, -2.40543697e+00],\n",
              "        [-1.74344996e+00,  9.97776869e-01],\n",
              "        [-1.45236904e+00,  4.70368522e-01],\n",
              "        [-5.09257270e-01,  1.47036827e+00],\n",
              "        [ 9.82494282e-01, -1.33938777e+00],\n",
              "        [ 1.50096157e+00, -1.67580194e+00],\n",
              "        [ 1.34258818e+00,  9.03842338e-01],\n",
              "        [ 3.05757245e+00,  8.02533863e-02],\n",
              "        [-7.02131498e-01, -6.29810247e-01],\n",
              "        [-6.11094774e-01, -1.75893850e+00],\n",
              "        [ 7.26888772e-01,  1.01551074e+00],\n",
              "        [-1.29386870e+00,  8.96543019e-01],\n",
              "        [-8.20603757e-01,  7.74998455e-01],\n",
              "        [ 1.43609074e+00,  5.39197880e-01],\n",
              "        [ 3.53483649e-01, -1.04684497e+00],\n",
              "        [ 6.82230917e-01,  1.43235646e+00],\n",
              "        [-8.66231054e-01,  1.14435380e+00],\n",
              "        [ 2.04669999e+00, -1.01775787e+00],\n",
              "        [ 3.59507195e-01,  7.53390980e-01],\n",
              "        [ 6.97383772e-01, -2.26678389e+00],\n",
              "        [ 8.65776779e-01, -1.21762329e+00],\n",
              "        [ 4.28358501e-01, -1.10757364e+00],\n",
              "        [-7.93915442e-02,  5.93908225e-01],\n",
              "        [-1.07724068e+00, -9.62656450e-01],\n",
              "        [-2.09114448e-01,  4.01341583e-01],\n",
              "        [ 3.01511975e-01,  6.02119507e-01],\n",
              "        [ 3.59454556e-02, -4.94537729e-01],\n",
              "        [ 1.24289721e+00,  3.87016394e-01],\n",
              "        [-1.00235028e+00, -7.98731516e-01],\n",
              "        [-6.74156049e-01,  8.03037965e-01],\n",
              "        [-1.18822392e+00,  6.05652299e-01],\n",
              "        [ 1.10922347e+00, -1.68327194e+00],\n",
              "        [-4.54727548e-01,  8.28009080e-01],\n",
              "        [ 1.51880196e-01, -1.13827324e+00],\n",
              "        [ 1.17325348e-01, -1.47735832e+00],\n",
              "        [ 1.16818754e+00, -4.06042985e-01],\n",
              "        [-6.24272716e-01,  1.25215523e+00],\n",
              "        [-8.83476976e-01,  1.09421850e+00],\n",
              "        [ 1.29299584e+00,  1.13473841e+00],\n",
              "        [ 1.65294623e+00, -1.25610734e+00],\n",
              "        [ 8.73755570e-01,  7.88411817e-01],\n",
              "        [ 2.50246022e-01,  1.16369383e+00],\n",
              "        [ 4.10510520e-01, -5.62003310e-01],\n",
              "        [-9.19477385e-01, -8.83574263e-01],\n",
              "        [-6.53755185e-01,  1.22121044e+00],\n",
              "        [-1.14506636e+00, -6.01617601e-01],\n",
              "        [-1.23416151e+00,  1.19439315e+00],\n",
              "        [-4.61139539e-01, -7.41682510e-01],\n",
              "        [-1.54098934e+00, -1.19598653e+00],\n",
              "        [ 7.87116585e-01, -5.48711063e-01],\n",
              "        [ 1.25803015e+00, -1.32034853e+00],\n",
              "        [ 8.25923398e-01,  1.33663561e+00],\n",
              "        [ 4.69102326e-01,  1.00753548e+00],\n",
              "        [ 7.70115634e-01,  7.80058089e-01],\n",
              "        [-1.93393136e+00,  1.03763746e+00],\n",
              "        [ 5.14712326e-01,  1.11414252e+00],\n",
              "        [ 7.34556744e-01,  1.12729093e+00],\n",
              "        [-7.97818459e-01,  1.73665182e-01],\n",
              "        [-2.50691573e+00, -5.61748430e-01],\n",
              "        [ 6.27158849e-02,  1.13288371e+00],\n",
              "        [-9.26586783e-01,  2.04149817e+00],\n",
              "        [ 7.17487011e-01,  1.40977888e+00],\n",
              "        [-3.90784151e-01,  9.14456623e-01],\n",
              "        [-1.80173222e-01,  8.91152061e-01],\n",
              "        [-3.44555998e-01,  4.75899767e-03],\n",
              "        [-2.87826838e-01,  8.75110161e-01],\n",
              "        [-3.90186213e-01,  8.66811674e-01],\n",
              "        [-1.61810048e-01,  1.17513901e+00],\n",
              "        [ 7.14038234e-01,  1.02249603e+00],\n",
              "        [ 6.44314599e-01,  9.56992667e-01],\n",
              "        [-1.05960887e+00,  1.27313945e+00],\n",
              "        [-1.48656535e+00,  7.84957559e-01],\n",
              "        [-7.59563291e-01, -9.90655407e-01],\n",
              "        [-9.17862713e-01, -1.28247051e+00],\n",
              "        [-6.78200836e-02, -7.11586415e-01],\n",
              "        [ 9.33550381e-01, -2.31296466e-01],\n",
              "        [ 2.74061755e-02, -1.06785991e+00],\n",
              "        [ 5.35367865e-01,  1.19632359e+00],\n",
              "        [ 9.05983584e-01,  8.39840174e-01],\n",
              "        [-1.29008702e-01, -6.50680800e-01],\n",
              "        [ 4.70360399e-01,  1.05361224e+00],\n",
              "        [-7.65561520e-01,  1.13055983e+00],\n",
              "        [ 1.07484879e+00,  8.23433889e-01],\n",
              "        [ 9.22557925e-01,  7.22022394e-01],\n",
              "        [-2.69267911e-01, -2.13216450e-02]]),\n",
              " array([1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1.,\n",
              "        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
              "        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
              "        0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
              "        0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
              "        0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
              "        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
              "        0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "        1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
              "        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
              "        1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
              "        1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
              "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
              "        1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
              "        0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
              "        1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
              "        0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "        0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
              "        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
              "        0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
              "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
              "        0., 1., 1., 0., 1., 1., 1., 0., 0.]),\n",
              " <keras.engine.sequential.Sequential at 0x7f6b84ee6ce0>)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#example of run_kfrom tensorflow.compat.v1.keras.layers\n",
        "import tensorflow as tf\n",
        "\n",
        "layer1 = tf.compat.v1.keras.layers.Dense(units=3, activation='relu', use_bias=False)\n",
        "run_keras_2d(\"3\", archs(2)[0], 10, split=0.5, display=False, verbose=False, trials=1)\n",
        "#run_keras_2d_vm(\"3\", archs(2)[0], 10, split=0.5, display=False, verbose=False, trials=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRLsv5LnTpzf",
        "outputId": "52cfea1d-32a8-49e4-adbe-94c7e399997e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keras FC: dataset= 3\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy:0.8799999952316284\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([[ 9.33550381e-01, -2.31296466e-01],\n",
              "        [-2.48121610e+00, -1.36699313e+00],\n",
              "        [-1.78366045e-01,  1.05159727e+00],\n",
              "        [ 8.09768501e-01,  1.25234471e+00],\n",
              "        [ 3.01511975e-01,  6.02119507e-01],\n",
              "        [-4.83400521e-01,  5.84297393e-01],\n",
              "        [ 3.60688993e-01, -1.41913281e+00],\n",
              "        [ 6.65546340e-01, -4.87610678e-01],\n",
              "        [ 6.65228620e-01,  1.05274437e+00],\n",
              "        [-1.45236904e+00,  4.70368522e-01],\n",
              "        [ 3.76946605e-03, -2.19287900e+00],\n",
              "        [-1.91870264e+00, -9.72408379e-01],\n",
              "        [ 8.70593920e-02,  1.16291413e+00],\n",
              "        [ 5.10668351e-01,  1.43624362e+00],\n",
              "        [ 4.61412128e-01,  1.62721884e+00],\n",
              "        [-1.00263655e+00,  6.72766167e-01],\n",
              "        [-9.78487004e-01,  1.33753667e+00],\n",
              "        [ 1.50096157e+00, -1.67580194e+00],\n",
              "        [ 3.05757245e+00,  8.02533863e-02],\n",
              "        [-6.53755185e-01,  1.22121044e+00],\n",
              "        [-9.19477385e-01, -8.83574263e-01],\n",
              "        [ 3.19006021e-01,  7.05395797e-01],\n",
              "        [ 1.52537231e+00, -7.05544863e-01],\n",
              "        [ 1.24379850e+00, -1.24186239e+00],\n",
              "        [-1.00421449e+00,  9.21219259e-01],\n",
              "        [-7.32381388e-01, -3.16439954e-01],\n",
              "        [ 7.24363038e-01, -3.74497572e-01],\n",
              "        [-9.17862713e-01, -1.28247051e+00],\n",
              "        [ 6.91740501e-01,  9.32466520e-01],\n",
              "        [ 1.25180445e+00, -1.31323403e+00],\n",
              "        [-5.02895716e-01,  1.03914579e+00],\n",
              "        [ 6.12599632e-01, -6.08357600e-01],\n",
              "        [-7.93915442e-02,  5.93908225e-01],\n",
              "        [ 1.10922347e+00, -1.68327194e+00],\n",
              "        [-1.26693058e-01, -7.50666180e-01],\n",
              "        [ 1.10961771e+00, -1.71291812e+00],\n",
              "        [-3.90784151e-01,  9.14456623e-01],\n",
              "        [ 1.99009149e+00,  9.04658862e-01],\n",
              "        [ 3.70332689e-01, -2.35719846e+00],\n",
              "        [ 7.76414305e-01, -7.84042128e-01],\n",
              "        [ 1.03397734e+00,  9.94625504e-01],\n",
              "        [-8.19510632e-01,  9.16036256e-01],\n",
              "        [-5.33350199e-01, -7.01342176e-01],\n",
              "        [ 3.31873096e-01,  1.16156475e+00],\n",
              "        [-1.69731484e-02, -1.73171939e+00],\n",
              "        [-1.14015107e+00,  6.75329607e-01],\n",
              "        [ 6.37641117e-01,  9.24521718e-01],\n",
              "        [-7.59563291e-01, -9.90655407e-01],\n",
              "        [-1.02646091e+00,  7.30186986e-01],\n",
              "        [-6.74971949e-01,  1.23686691e+00],\n",
              "        [-4.54727548e-01,  8.28009080e-01],\n",
              "        [-8.19227913e-01,  1.13638010e+00],\n",
              "        [-4.98048222e-01, -2.05324570e+00],\n",
              "        [ 9.82494282e-01, -1.33938777e+00],\n",
              "        [-9.67562269e-02, -1.04634812e+00],\n",
              "        [-1.24458639e+00,  7.30610549e-01],\n",
              "        [ 1.24289721e+00,  3.87016394e-01],\n",
              "        [ 1.49791013e+00, -9.05810242e-01],\n",
              "        [-4.72235332e-02,  1.12898458e+00],\n",
              "        [ 3.07141783e-01, -5.24623805e-01],\n",
              "        [-8.55522699e-01, -4.78157321e-01],\n",
              "        [-2.69641336e-01, -1.31882248e+00],\n",
              "        [ 2.74061755e-02, -1.06785991e+00],\n",
              "        [ 6.13678993e-01, -1.17730862e+00],\n",
              "        [ 4.10510520e-01, -5.62003310e-01],\n",
              "        [ 1.45250817e+00, -1.98062295e+00],\n",
              "        [ 5.25962696e-01, -2.00777506e+00],\n",
              "        [ 2.40553070e-01,  7.52439524e-01],\n",
              "        [ 1.63713564e+00, -2.17432334e+00],\n",
              "        [ 3.71876077e-01,  1.20938305e+00],\n",
              "        [ 4.82659146e-01, -1.18185819e+00],\n",
              "        [-1.60869714e+00,  1.04500028e+00],\n",
              "        [ 4.45047706e-01, -8.43962960e-01],\n",
              "        [-3.12358157e-01, -1.47095439e+00],\n",
              "        [ 4.04713428e-01,  1.39722625e+00],\n",
              "        [-8.71517413e-02, -1.67901807e+00],\n",
              "        [ 1.64094544e+00, -7.78994384e-01],\n",
              "        [-9.26586783e-01,  2.04149817e+00],\n",
              "        [-9.03762539e-01, -1.97830405e+00],\n",
              "        [ 3.43319427e-01, -1.58022728e+00],\n",
              "        [-1.55859064e-01, -9.93383540e-01],\n",
              "        [-9.00916800e-01,  1.09612133e+00],\n",
              "        [-5.62743687e-01,  1.05045366e+00],\n",
              "        [-1.05234752e+00, -1.19191135e+00],\n",
              "        [-5.15713362e-01, -2.05668156e+00],\n",
              "        [-1.91133900e-01, -1.35711833e+00],\n",
              "        [-2.69267911e-01, -2.13216450e-02],\n",
              "        [-5.89184200e-01, -7.13968242e-01],\n",
              "        [-8.88840612e-01,  9.57599953e-01],\n",
              "        [ 1.40697557e+00,  8.38761777e-01],\n",
              "        [ 1.07484879e+00,  8.23433889e-01],\n",
              "        [-6.57027257e-01,  1.04703625e+00],\n",
              "        [ 4.51101916e-01,  1.05104320e+00],\n",
              "        [ 1.51880196e-01, -1.13827324e+00],\n",
              "        [ 5.01637382e-02, -1.86205461e-01],\n",
              "        [-8.98607781e-01,  1.32135061e+00],\n",
              "        [ 8.29727566e-01, -1.71167084e+00],\n",
              "        [-1.15840553e+00,  1.15352059e+00],\n",
              "        [-1.80173222e-01,  8.91152061e-01],\n",
              "        [ 2.97069152e-01, -1.18341697e+00],\n",
              "        [-1.95634261e-02,  1.08597651e+00],\n",
              "        [-4.22725606e-01, -2.40543697e+00],\n",
              "        [ 8.65776779e-01, -1.21762329e+00],\n",
              "        [-9.66556680e-02,  1.17882331e+00],\n",
              "        [-1.93393136e+00,  1.03763746e+00],\n",
              "        [ 1.12891929e-01,  9.84968701e-01],\n",
              "        [-1.09673065e-01, -9.38314921e-01],\n",
              "        [-6.25363136e-01, -2.16919689e+00],\n",
              "        [-1.48038581e+00,  1.05573465e+00],\n",
              "        [-1.18822392e+00,  6.05652299e-01],\n",
              "        [ 3.17664339e-01,  1.14073734e+00],\n",
              "        [ 1.15606866e-01,  6.01664637e-01],\n",
              "        [-6.11094774e-01, -1.75893850e+00],\n",
              "        [ 1.27208381e-01,  1.33817514e+00],\n",
              "        [ 8.73755570e-01,  7.88411817e-01],\n",
              "        [-1.00235028e+00, -7.98731516e-01],\n",
              "        [-3.23073838e-01, -1.53094630e+00],\n",
              "        [ 4.42338898e-01, -7.90399307e-01],\n",
              "        [-6.21091558e-03, -1.53802337e+00],\n",
              "        [-5.01996284e-02,  9.92626678e-01],\n",
              "        [-8.72351116e-01,  6.33199395e-01],\n",
              "        [-9.28369699e-01,  1.09835499e+00],\n",
              "        [ 3.39483309e-01, -1.53777198e+00],\n",
              "        [ 6.27158849e-02,  1.13288371e+00],\n",
              "        [-7.97818459e-01,  1.73665182e-01],\n",
              "        [ 1.47028284e+00, -1.02889795e+00],\n",
              "        [-5.09257270e-01,  1.47036827e+00],\n",
              "        [ 3.56311070e-01, -1.83422288e+00],\n",
              "        [-1.23416151e+00,  1.19439315e+00],\n",
              "        [-2.80759883e-01, -6.54796310e-01],\n",
              "        [ 2.50246022e-01,  1.16369383e+00],\n",
              "        [ 7.34556744e-01,  1.12729093e+00],\n",
              "        [ 8.71930256e-01,  9.44092465e-01],\n",
              "        [ 2.56817317e+00,  1.00347317e+00],\n",
              "        [ 7.87116585e-01, -5.48711063e-01],\n",
              "        [ 3.11442245e-01,  1.10354795e+00],\n",
              "        [-6.44300389e-01,  1.14495920e+00],\n",
              "        [ 1.56110391e+00, -4.70849410e-01],\n",
              "        [-6.24272716e-01,  1.25215523e+00],\n",
              "        [ 2.52094708e+00,  1.11913471e+00],\n",
              "        [-1.64588447e+00, -1.79336505e+00],\n",
              "        [ 4.51483402e-01,  6.79791225e-01],\n",
              "        [-9.51855250e-01, -2.25623806e+00],\n",
              "        [ 7.74967979e-01, -5.45248881e-02],\n",
              "        [ 8.49637322e-01, -1.29314599e-01],\n",
              "        [ 5.93103644e-01,  1.20379038e+00],\n",
              "        [-1.61810048e-01,  1.17513901e+00],\n",
              "        [-1.10963737e+00, -7.21441528e-01],\n",
              "        [ 1.15960716e+00, -1.52652878e+00],\n",
              "        [ 2.22795714e+00,  1.13783995e+00],\n",
              "        [ 9.33095520e-02, -1.34614077e+00],\n",
              "        [-2.84390861e-01,  1.28516740e-01],\n",
              "        [ 7.58980601e-01,  1.17926749e+00],\n",
              "        [-2.87826838e-01,  8.75110161e-01],\n",
              "        [ 4.28358501e-01, -1.10757364e+00],\n",
              "        [-8.60042024e-01,  6.82399393e-01],\n",
              "        [ 7.14038234e-01,  1.02249603e+00],\n",
              "        [ 1.24118132e-01, -1.30177445e+00],\n",
              "        [-9.97925058e-01,  7.41648174e-01],\n",
              "        [-1.56985091e+00,  1.81721816e-01],\n",
              "        [ 7.10252376e-01,  1.10546805e+00],\n",
              "        [-1.10192400e-01, -1.62969750e+00],\n",
              "        [ 1.05421974e+00, -1.32045158e+00],\n",
              "        [-2.50691573e+00, -5.61748430e-01],\n",
              "        [ 7.15681337e-01, -7.61277410e-02],\n",
              "        [-5.12638604e-01, -1.66997181e+00],\n",
              "        [-4.21253088e-01, -8.18917818e-01],\n",
              "        [ 1.44416641e+00,  3.36156387e-01],\n",
              "        [ 2.68572445e-01,  9.19915554e-01],\n",
              "        [ 4.17050342e-01,  1.06947274e+00],\n",
              "        [ 1.20849816e+00, -5.16103953e-01],\n",
              "        [-1.29008702e-01, -6.50680800e-01],\n",
              "        [-1.07724068e+00, -9.62656450e-01],\n",
              "        [-2.77688414e-01, -7.44748537e-01],\n",
              "        [ 7.50266447e-01,  4.23964853e-01],\n",
              "        [ 1.34999576e+00,  5.94932219e-01],\n",
              "        [-1.06101136e+00,  9.01626186e-01],\n",
              "        [ 1.92377126e-01, -1.50177035e-01],\n",
              "        [ 1.55798065e-01,  9.80926148e-01],\n",
              "        [-1.21620968e+00,  6.83049065e-01],\n",
              "        [-2.07979093e+00,  3.40368771e-01],\n",
              "        [-2.48854241e+00,  6.00533278e-01],\n",
              "        [ 7.26888772e-01,  1.01551074e+00],\n",
              "        [ 1.25803015e+00, -1.32034853e+00],\n",
              "        [-3.44555998e-01,  4.75899767e-03],\n",
              "        [-5.97566850e-01, -2.36224337e-01],\n",
              "        [ 1.61815412e+00, -1.41098154e+00],\n",
              "        [-1.17264210e+00, -2.10489761e+00],\n",
              "        [-8.66231054e-01,  1.14435380e+00],\n",
              "        [ 5.41193475e-01, -1.16136205e+00],\n",
              "        [-3.55639647e-02,  1.26847710e+00],\n",
              "        [ 5.14712326e-01,  1.11414252e+00],\n",
              "        [ 1.49376800e-01,  6.48015791e-01],\n",
              "        [ 2.70581984e-01,  8.32604236e-01],\n",
              "        [-3.90186213e-01,  8.66811674e-01],\n",
              "        [ 2.69701928e-01, -3.44847643e-01],\n",
              "        [-5.76529670e-01, -9.03522018e-01],\n",
              "        [ 5.31870945e-01,  6.12922734e-03],\n",
              "        [ 7.44323809e-01, -1.11690801e+00],\n",
              "        [-1.27959872e-01,  1.42780257e+00],\n",
              "        [ 4.82131302e-01, -7.66786885e-01],\n",
              "        [ 1.02885868e+00,  1.03520193e+00],\n",
              "        [-3.92251702e-01, -5.99675561e-01],\n",
              "        [-6.36989768e-01,  8.95222556e-01],\n",
              "        [-1.89499918e-01,  8.55965739e-01],\n",
              "        [-1.07412296e-01,  1.18497910e+00],\n",
              "        [ 5.35367865e-01,  1.19632359e+00],\n",
              "        [ 1.22280969e+00, -6.34011641e-01],\n",
              "        [ 1.43637773e+00,  8.88204900e-01],\n",
              "        [-1.79255442e-01,  9.04111402e-01],\n",
              "        [-2.43518124e+00, -1.33467556e+00],\n",
              "        [-1.03777338e+00,  8.71249143e-01],\n",
              "        [ 1.99083423e+00,  7.39232662e-01],\n",
              "        [-6.74156049e-01,  8.03037965e-01],\n",
              "        [-3.27830527e-01,  1.18556267e+00],\n",
              "        [-1.05960887e+00,  1.27313945e+00],\n",
              "        [ 9.22557925e-01,  7.22022394e-01],\n",
              "        [-1.56887718e+00,  1.58366785e+00],\n",
              "        [ 4.69102326e-01,  1.00753548e+00],\n",
              "        [ 9.89600289e-01,  1.26694159e+00],\n",
              "        [ 4.74916742e-01, -1.14933559e+00],\n",
              "        [-1.37496427e+00, -2.14360387e+00],\n",
              "        [-2.79335783e-01, -8.87909018e-01],\n",
              "        [ 1.61892082e-02,  7.50985464e-01],\n",
              "        [-1.42672828e+00, -1.68955108e+00],\n",
              "        [-1.33650871e-01, -9.32036395e-01],\n",
              "        [ 1.25901523e+00,  1.11166169e+00],\n",
              "        [-5.62944237e-01, -1.81517397e+00],\n",
              "        [-2.62825570e+00, -1.17227297e+00],\n",
              "        [ 1.02194219e+00, -5.46483705e-01],\n",
              "        [-7.19309633e-01, -9.10266737e-01],\n",
              "        [-1.28541366e+00,  8.89537258e-01],\n",
              "        [-9.45670383e-01,  2.91358459e-01],\n",
              "        [-1.22825580e+00,  6.62205401e-01],\n",
              "        [-2.19315340e-01,  1.31915105e+00],\n",
              "        [-9.22451178e-01,  1.55938011e+00],\n",
              "        [ 4.81312605e-01,  9.71724691e-01],\n",
              "        [ 3.59454556e-02, -4.94537729e-01],\n",
              "        [ 3.53483649e-01, -1.04684497e+00],\n",
              "        [-7.03010715e-01, -8.36794524e-01],\n",
              "        [-2.09114448e-01,  4.01341583e-01],\n",
              "        [ 1.66128608e+00,  1.59085862e+00],\n",
              "        [-3.38696894e-01,  2.09506699e-01],\n",
              "        [-9.70534473e-01,  1.13151763e+00],\n",
              "        [-1.47108290e+00,  9.47191900e-01],\n",
              "        [ 6.44314599e-01,  9.56992667e-01],\n",
              "        [-1.25241081e-01,  7.65571558e-01],\n",
              "        [ 1.63904127e-01,  8.16453466e-01],\n",
              "        [-5.14657260e-01,  1.25692322e+00],\n",
              "        [ 1.07186791e+00, -6.00332252e-01],\n",
              "        [-1.80086374e-01, -1.62109929e+00],\n",
              "        [-1.47834412e+00, -4.58217735e-01],\n",
              "        [ 1.83689989e-01, -2.78607469e-01],\n",
              "        [ 2.02584111e+00,  4.63471587e-03],\n",
              "        [-6.09169793e-01,  1.21864793e+00],\n",
              "        [ 4.20037118e-01,  1.03254396e+00],\n",
              "        [-3.13859609e-01,  1.08169038e+00],\n",
              "        [-1.11206353e+00, -1.69493671e+00],\n",
              "        [ 4.70360399e-01,  1.05361224e+00],\n",
              "        [-2.91308358e-01, -1.32297240e+00],\n",
              "        [-8.83476976e-01,  1.09421850e+00],\n",
              "        [ 2.33610938e-02, -1.84518665e+00],\n",
              "        [-6.78200836e-02, -7.11586415e-01],\n",
              "        [ 2.83963318e-01,  1.12920018e+00],\n",
              "        [ 2.01124258e+00, -6.50151870e-01],\n",
              "        [-2.21627523e+00, -1.43020809e+00],\n",
              "        [ 8.37403896e-01,  7.07465258e-01],\n",
              "        [ 8.25923398e-01,  1.33663561e+00],\n",
              "        [ 6.10165824e-01, -7.02758659e-01],\n",
              "        [-1.74344996e+00,  9.97776869e-01],\n",
              "        [ 1.84385841e+00, -1.19911559e+00],\n",
              "        [-1.92028794e-01,  6.18618137e-01],\n",
              "        [ 1.26251243e+00, -1.33798222e+00],\n",
              "        [ 2.82678103e-01, -1.52199667e+00],\n",
              "        [-1.54098934e+00, -1.19598653e+00],\n",
              "        [-7.36954920e-01, -1.99090996e+00],\n",
              "        [-8.59917131e-01, -7.74332383e-01],\n",
              "        [-2.78095935e+00,  1.33528844e+00],\n",
              "        [-1.14914412e-01, -1.66416399e-01],\n",
              "        [ 2.27937491e+00, -5.31454264e-01],\n",
              "        [ 1.62752185e-01,  9.21716731e-01],\n",
              "        [-1.55593397e+00,  1.54091974e+00],\n",
              "        [ 1.03489991e+00,  1.19767297e+00],\n",
              "        [-1.47211524e-01, -6.12836186e-01],\n",
              "        [ 1.34281872e+00, -1.98908865e+00],\n",
              "        [-9.10797208e-01, -1.51408134e+00],\n",
              "        [ 7.82625350e-02,  7.77665351e-01],\n",
              "        [ 2.88990304e-01, -3.04575699e-01],\n",
              "        [ 5.56595729e-01, -9.68298445e-01],\n",
              "        [-1.72375519e+00, -7.07488608e-01],\n",
              "        [ 1.43609074e+00,  5.39197880e-01],\n",
              "        [-6.37157920e-01, -4.27618581e-01],\n",
              "        [-6.11864335e-01, -3.04394204e-01],\n",
              "        [-5.10468330e-01,  7.41753970e-01],\n",
              "        [ 1.53758454e+00,  4.26999405e-01],\n",
              "        [-1.55601351e-01, -4.15193470e-01],\n",
              "        [ 9.64624265e-01, -1.72598657e+00],\n",
              "        [-5.66103130e-02, -1.74011165e+00],\n",
              "        [-6.07685719e-01, -9.00295674e-01],\n",
              "        [ 7.74771870e-01, -1.12994088e+00],\n",
              "        [ 6.42911514e-01,  9.43444347e-01],\n",
              "        [-4.61139539e-01, -7.41682510e-01],\n",
              "        [-4.93084898e-01,  7.83595885e-01],\n",
              "        [ 2.97567420e-02, -1.70729600e+00],\n",
              "        [-6.50672262e-01,  1.22474875e+00],\n",
              "        [ 5.05644320e-01, -1.31135357e+00],\n",
              "        [ 1.55592533e+00,  9.77496170e-01],\n",
              "        [ 1.17325348e-01, -1.47735832e+00],\n",
              "        [ 1.03949361e+00, -9.53568987e-01],\n",
              "        [ 1.98167116e-01,  1.19834281e+00],\n",
              "        [ 1.00844652e+00,  1.30543156e+00],\n",
              "        [ 1.34258818e+00,  9.03842338e-01],\n",
              "        [-2.60818351e-02,  1.01596097e+00],\n",
              "        [ 9.04075035e-01, -4.19988897e-01],\n",
              "        [-1.40281568e+00, -9.50144300e-01],\n",
              "        [-1.59015462e+00,  7.44042740e-02],\n",
              "        [ 1.17643799e+00, -7.50069105e-02],\n",
              "        [ 1.30783537e+00,  8.72599493e-01],\n",
              "        [ 7.70115634e-01,  7.80058089e-01],\n",
              "        [ 1.32115979e+00,  1.08700327e+00],\n",
              "        [-5.68201865e-01,  9.97233331e-01],\n",
              "        [ 5.75533547e-01, -1.77035812e+00],\n",
              "        [-3.98901569e-01, -1.37282347e+00],\n",
              "        [ 7.17487011e-01,  1.40977888e+00],\n",
              "        [ 9.05983584e-01,  8.39840174e-01],\n",
              "        [-8.76150821e-01,  9.38246134e-01],\n",
              "        [ 3.38379307e-01,  1.31134144e+00],\n",
              "        [-1.14506636e+00, -6.01617601e-01],\n",
              "        [ 6.06949123e-01, -1.92695095e+00],\n",
              "        [ 2.98144973e-01,  5.57058930e-01],\n",
              "        [-3.73398803e-02, -1.92251617e+00],\n",
              "        [-9.49084956e-01,  1.13001262e+00],\n",
              "        [-1.10877497e+00,  1.14858995e+00],\n",
              "        [ 3.27494621e+00, -3.78799528e-01],\n",
              "        [-9.15863874e-01,  1.16368824e+00],\n",
              "        [ 1.65836601e-01,  1.04371696e+00],\n",
              "        [ 2.89462527e-01,  8.06161465e-01],\n",
              "        [-8.20603757e-01,  7.74998455e-01],\n",
              "        [-2.66744646e-01,  1.24707267e+00],\n",
              "        [ 2.97793904e-01,  9.73662817e-01],\n",
              "        [-6.40393302e-02, -2.09756863e-01],\n",
              "        [-1.02974722e+00,  8.08029008e-01],\n",
              "        [ 6.82230917e-01,  1.43235646e+00],\n",
              "        [ 1.08570167e+00, -9.29783088e-01],\n",
              "        [-4.14832677e-01, -7.61685543e-01],\n",
              "        [-1.40386913e+00, -1.02071773e+00],\n",
              "        [ 1.16818754e+00, -4.06042985e-01],\n",
              "        [-1.54337318e+00, -5.27867198e-01],\n",
              "        [-1.66460869e+00, -9.50342075e-01],\n",
              "        [-9.89379259e-01,  1.43420494e+00],\n",
              "        [-1.30422169e-01, -8.92018698e-01],\n",
              "        [-2.06423656e+00, -1.49811482e+00],\n",
              "        [ 2.18459391e+00,  9.08547003e-01],\n",
              "        [ 1.65294623e+00, -1.25610734e+00],\n",
              "        [-1.44035415e+00,  1.00674819e+00],\n",
              "        [-1.12435698e+00, -4.30035232e-01],\n",
              "        [-2.58962352e-01,  9.36627693e-01],\n",
              "        [-4.73362117e-01,  5.83668048e-01],\n",
              "        [ 1.53031689e+00, -1.42527722e+00],\n",
              "        [-6.04300483e-01, -1.27031016e+00],\n",
              "        [-6.46615721e-02,  7.29392228e-01],\n",
              "        [-7.65561520e-01,  1.13055983e+00],\n",
              "        [-1.29386870e+00,  8.96543019e-01],\n",
              "        [ 2.84183705e-01,  9.97209950e-01],\n",
              "        [ 1.09315404e+00,  1.25350731e+00],\n",
              "        [-1.94083970e-01,  1.25165885e+00],\n",
              "        [ 2.15120831e-01, -1.07328215e+00],\n",
              "        [ 3.59507195e-01,  7.53390980e-01],\n",
              "        [-1.77364406e-01, -9.63714670e-01],\n",
              "        [-2.94792699e-01, -6.86119747e-01],\n",
              "        [ 1.13615505e+00,  9.34159707e-01],\n",
              "        [-1.34882284e+00, -2.41377262e+00],\n",
              "        [-5.30929289e-01,  1.37027026e+00],\n",
              "        [-1.67530495e+00,  1.03949695e+00],\n",
              "        [-1.29854547e+00, -1.78213954e+00],\n",
              "        [ 3.80551397e+00,  1.49137866e-01],\n",
              "        [ 1.10434286e+00, -1.11628861e+00],\n",
              "        [ 6.21830757e-01,  1.03110956e+00],\n",
              "        [ 1.80089979e-01,  8.68041199e-01],\n",
              "        [ 2.04669999e+00, -1.01775787e+00],\n",
              "        [-1.60947813e+00,  1.00125605e+00],\n",
              "        [-2.81881752e-01, -8.84938507e-01],\n",
              "        [ 6.44335216e-01, -9.07492218e-01],\n",
              "        [ 4.96845017e-01,  8.59549327e-01],\n",
              "        [-5.98009083e-02,  8.22694316e-01],\n",
              "        [-1.45586427e+00,  1.06759553e+00],\n",
              "        [ 6.97383772e-01, -2.26678389e+00],\n",
              "        [ 1.62749494e+00, -1.17694401e+00],\n",
              "        [-1.18857664e+00,  1.33689522e+00],\n",
              "        [ 4.86250026e-01, -1.56351910e+00],\n",
              "        [-7.36329438e-01,  8.31344915e-01],\n",
              "        [-3.44366268e-01, -1.36434668e+00],\n",
              "        [ 1.29299584e+00,  1.13473841e+00],\n",
              "        [-1.24643954e+00,  1.49863868e-01],\n",
              "        [-1.74711514e-01, -2.36960028e+00],\n",
              "        [-1.48656535e+00,  7.84957559e-01],\n",
              "        [-6.38776473e-01, -1.49137041e+00],\n",
              "        [-7.02131498e-01, -6.29810247e-01],\n",
              "        [ 1.51944832e+00,  6.69433159e-01],\n",
              "        [-1.10907769e+00,  6.14530338e-01]]),\n",
              " array([0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
              "        0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
              "        0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
              "        1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
              "        0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
              "        0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
              "        1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
              "        1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
              "        1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "        0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
              "        0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
              "        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
              "        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
              "        0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1.,\n",
              "        1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
              "        0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
              "        1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
              "        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
              "        0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
              "        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
              "        0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
              "        0., 1., 0., 0., 1., 0., 0., 1., 1.]),\n",
              " <keras.engine.sequential.Sequential at 0x7f6b843bc7c0>)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_keras_2d(\"3\", [Dense(units=2, activation='softmax')], 10, split=0.5, display=False, verbose=False, trials=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDZUZvbNTphY",
        "outputId": "9d6e21e5-8263-4ad6-f1b1-e4c7a77a80e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keras FC: dataset= 3\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy:0.9350000023841858\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([[ 1.50096157e+00, -1.67580194e+00],\n",
              "        [ 1.10961771e+00, -1.71291812e+00],\n",
              "        [ 1.84385841e+00, -1.19911559e+00],\n",
              "        [-1.67530495e+00,  1.03949695e+00],\n",
              "        [ 3.43319427e-01, -1.58022728e+00],\n",
              "        [-5.15713362e-01, -2.05668156e+00],\n",
              "        [ 1.51880196e-01, -1.13827324e+00],\n",
              "        [-2.07979093e+00,  3.40368771e-01],\n",
              "        [ 7.34556744e-01,  1.12729093e+00],\n",
              "        [-1.10907769e+00,  6.14530338e-01],\n",
              "        [-9.15863874e-01,  1.16368824e+00],\n",
              "        [ 2.04669999e+00, -1.01775787e+00],\n",
              "        [-6.11094774e-01, -1.75893850e+00],\n",
              "        [ 4.82659146e-01, -1.18185819e+00],\n",
              "        [ 8.71930256e-01,  9.44092465e-01],\n",
              "        [ 2.40553070e-01,  7.52439524e-01],\n",
              "        [ 7.58980601e-01,  1.17926749e+00],\n",
              "        [-1.48038581e+00,  1.05573465e+00],\n",
              "        [ 1.53758454e+00,  4.26999405e-01],\n",
              "        [-9.49084956e-01,  1.13001262e+00],\n",
              "        [-1.02974722e+00,  8.08029008e-01],\n",
              "        [-3.27830527e-01,  1.18556267e+00],\n",
              "        [ 1.24118132e-01, -1.30177445e+00],\n",
              "        [-1.74711514e-01, -2.36960028e+00],\n",
              "        [ 1.99009149e+00,  9.04658862e-01],\n",
              "        [ 6.37641117e-01,  9.24521718e-01],\n",
              "        [-1.05960887e+00,  1.27313945e+00],\n",
              "        [-1.28541366e+00,  8.89537258e-01],\n",
              "        [ 6.65228620e-01,  1.05274437e+00],\n",
              "        [-1.18857664e+00,  1.33689522e+00],\n",
              "        [-3.73398803e-02, -1.92251617e+00],\n",
              "        [-1.80086374e-01, -1.62109929e+00],\n",
              "        [-4.73362117e-01,  5.83668048e-01],\n",
              "        [ 6.21830757e-01,  1.03110956e+00],\n",
              "        [ 2.82678103e-01, -1.52199667e+00],\n",
              "        [ 9.82494282e-01, -1.33938777e+00],\n",
              "        [-5.76529670e-01, -9.03522018e-01],\n",
              "        [-3.23073838e-01, -1.53094630e+00],\n",
              "        [-1.06101136e+00,  9.01626186e-01],\n",
              "        [-1.21620968e+00,  6.83049065e-01],\n",
              "        [ 3.76946605e-03, -2.19287900e+00],\n",
              "        [-3.90186213e-01,  8.66811674e-01],\n",
              "        [ 7.14038234e-01,  1.02249603e+00],\n",
              "        [-1.25241081e-01,  7.65571558e-01],\n",
              "        [ 1.12891929e-01,  9.84968701e-01],\n",
              "        [-3.12358157e-01, -1.47095439e+00],\n",
              "        [ 7.87116585e-01, -5.48711063e-01],\n",
              "        [-1.37496427e+00, -2.14360387e+00],\n",
              "        [-1.00421449e+00,  9.21219259e-01],\n",
              "        [ 1.15606866e-01,  6.01664637e-01],\n",
              "        [ 5.41193475e-01, -1.16136205e+00],\n",
              "        [ 1.64094544e+00, -7.78994384e-01],\n",
              "        [-8.60042024e-01,  6.82399393e-01],\n",
              "        [ 1.52537231e+00, -7.05544863e-01],\n",
              "        [-8.88840612e-01,  9.57599953e-01],\n",
              "        [ 4.51101916e-01,  1.05104320e+00],\n",
              "        [-6.53755185e-01,  1.22121044e+00],\n",
              "        [-1.55601351e-01, -4.15193470e-01],\n",
              "        [-1.33650871e-01, -9.32036395e-01],\n",
              "        [ 4.20037118e-01,  1.03254396e+00],\n",
              "        [-8.59917131e-01, -7.74332383e-01],\n",
              "        [-1.92028794e-01,  6.18618137e-01],\n",
              "        [ 3.11442245e-01,  1.10354795e+00],\n",
              "        [ 3.07141783e-01, -5.24623805e-01],\n",
              "        [ 4.70360399e-01,  1.05361224e+00],\n",
              "        [ 1.27208381e-01,  1.33817514e+00],\n",
              "        [ 1.47028284e+00, -1.02889795e+00],\n",
              "        [ 1.55592533e+00,  9.77496170e-01],\n",
              "        [-1.56887718e+00,  1.58366785e+00],\n",
              "        [ 2.15120831e-01, -1.07328215e+00],\n",
              "        [ 3.59507195e-01,  7.53390980e-01],\n",
              "        [-1.56985091e+00,  1.81721816e-01],\n",
              "        [ 9.04075035e-01, -4.19988897e-01],\n",
              "        [-7.19309633e-01, -9.10266737e-01],\n",
              "        [-6.21091558e-03, -1.53802337e+00],\n",
              "        [ 1.15960716e+00, -1.52652878e+00],\n",
              "        [ 3.01511975e-01,  6.02119507e-01],\n",
              "        [-8.19227913e-01,  1.13638010e+00],\n",
              "        [ 3.19006021e-01,  7.05395797e-01],\n",
              "        [ 2.33610938e-02, -1.84518665e+00],\n",
              "        [-2.06423656e+00, -1.49811482e+00],\n",
              "        [-8.83476976e-01,  1.09421850e+00],\n",
              "        [-9.70534473e-01,  1.13151763e+00],\n",
              "        [-4.83400521e-01,  5.84297393e-01],\n",
              "        [-2.48121610e+00, -1.36699313e+00],\n",
              "        [ 1.03397734e+00,  9.94625504e-01],\n",
              "        [ 4.86250026e-01, -1.56351910e+00],\n",
              "        [-4.14832677e-01, -7.61685543e-01],\n",
              "        [ 1.65836601e-01,  1.04371696e+00],\n",
              "        [-1.27959872e-01,  1.42780257e+00],\n",
              "        [-1.05234752e+00, -1.19191135e+00],\n",
              "        [ 3.80551397e+00,  1.49137866e-01],\n",
              "        [-1.23416151e+00,  1.19439315e+00],\n",
              "        [-5.02895716e-01,  1.03914579e+00],\n",
              "        [ 2.84183705e-01,  9.97209950e-01],\n",
              "        [-1.10192400e-01, -1.62969750e+00],\n",
              "        [-2.81881752e-01, -8.84938507e-01],\n",
              "        [-1.17264210e+00, -2.10489761e+00],\n",
              "        [-1.47211524e-01, -6.12836186e-01],\n",
              "        [ 1.53031689e+00, -1.42527722e+00],\n",
              "        [-4.98048222e-01, -2.05324570e+00],\n",
              "        [ 1.92377126e-01, -1.50177035e-01],\n",
              "        [-1.12435698e+00, -4.30035232e-01],\n",
              "        [ 5.05644320e-01, -1.31135357e+00],\n",
              "        [ 2.02584111e+00,  4.63471587e-03],\n",
              "        [ 1.29299584e+00,  1.13473841e+00],\n",
              "        [-6.46615721e-02,  7.29392228e-01],\n",
              "        [ 1.80089979e-01,  8.68041199e-01],\n",
              "        [ 2.27937491e+00, -5.31454264e-01],\n",
              "        [ 1.56110391e+00, -4.70849410e-01],\n",
              "        [-9.22451178e-01,  1.55938011e+00],\n",
              "        [-8.71517413e-02, -1.67901807e+00],\n",
              "        [-1.00263655e+00,  6.72766167e-01],\n",
              "        [ 1.25901523e+00,  1.11166169e+00],\n",
              "        [-2.79335783e-01, -8.87909018e-01],\n",
              "        [ 1.13615505e+00,  9.34159707e-01],\n",
              "        [-2.58962352e-01,  9.36627693e-01],\n",
              "        [-3.90784151e-01,  9.14456623e-01],\n",
              "        [ 5.01637382e-02, -1.86205461e-01],\n",
              "        [-9.51855250e-01, -2.25623806e+00],\n",
              "        [-8.55522699e-01, -4.78157321e-01],\n",
              "        [ 7.44323809e-01, -1.11690801e+00],\n",
              "        [ 6.97383772e-01, -2.26678389e+00],\n",
              "        [ 4.42338898e-01, -7.90399307e-01],\n",
              "        [-1.64588447e+00, -1.79336505e+00],\n",
              "        [-2.09114448e-01,  4.01341583e-01],\n",
              "        [-3.44555998e-01,  4.75899767e-03],\n",
              "        [ 5.56595729e-01, -9.68298445e-01],\n",
              "        [-1.79255442e-01,  9.04111402e-01],\n",
              "        [ 1.63904127e-01,  8.16453466e-01],\n",
              "        [ 1.10922347e+00, -1.68327194e+00],\n",
              "        [ 5.93103644e-01,  1.20379038e+00],\n",
              "        [ 3.59454556e-02, -4.94537729e-01],\n",
              "        [ 2.70581984e-01,  8.32604236e-01],\n",
              "        [ 1.16818754e+00, -4.06042985e-01],\n",
              "        [ 5.75533547e-01, -1.77035812e+00],\n",
              "        [ 2.88990304e-01, -3.04575699e-01],\n",
              "        [ 1.49791013e+00, -9.05810242e-01],\n",
              "        [-8.19510632e-01,  9.16036256e-01],\n",
              "        [-1.29854547e+00, -1.78213954e+00],\n",
              "        [-3.55639647e-02,  1.26847710e+00],\n",
              "        [ 4.61412128e-01,  1.62721884e+00],\n",
              "        [-6.25363136e-01, -2.16919689e+00],\n",
              "        [ 4.10510520e-01, -5.62003310e-01],\n",
              "        [-7.97818459e-01,  1.73665182e-01],\n",
              "        [ 7.17487011e-01,  1.40977888e+00],\n",
              "        [-9.10797208e-01, -1.51408134e+00],\n",
              "        [ 4.69102326e-01,  1.00753548e+00],\n",
              "        [-2.69641336e-01, -1.31882248e+00],\n",
              "        [ 1.83689989e-01, -2.78607469e-01],\n",
              "        [-5.14657260e-01,  1.25692322e+00],\n",
              "        [-2.87826838e-01,  8.75110161e-01],\n",
              "        [-6.36989768e-01,  8.95222556e-01],\n",
              "        [ 5.14712326e-01,  1.11414252e+00],\n",
              "        [ 1.05421974e+00, -1.32045158e+00],\n",
              "        [-2.80759883e-01, -6.54796310e-01],\n",
              "        [-4.61139539e-01, -7.41682510e-01],\n",
              "        [-1.54337318e+00, -5.27867198e-01],\n",
              "        [ 3.17664339e-01,  1.14073734e+00],\n",
              "        [ 2.68572445e-01,  9.19915554e-01],\n",
              "        [-1.11206353e+00, -1.69493671e+00],\n",
              "        [-1.91133900e-01, -1.35711833e+00],\n",
              "        [-2.77688414e-01, -7.44748537e-01],\n",
              "        [ 1.02885868e+00,  1.03520193e+00],\n",
              "        [-1.26693058e-01, -7.50666180e-01],\n",
              "        [ 2.50246022e-01,  1.16369383e+00],\n",
              "        [ 1.43637773e+00,  8.88204900e-01],\n",
              "        [ 1.63713564e+00, -2.17432334e+00],\n",
              "        [ 1.55798065e-01,  9.80926148e-01],\n",
              "        [ 7.74967979e-01, -5.45248881e-02],\n",
              "        [ 1.03949361e+00, -9.53568987e-01],\n",
              "        [ 2.74061755e-02, -1.06785991e+00],\n",
              "        [ 6.06949123e-01, -1.92695095e+00],\n",
              "        [ 4.45047706e-01, -8.43962960e-01],\n",
              "        [-7.93915442e-02,  5.93908225e-01],\n",
              "        [ 7.15681337e-01, -7.61277410e-02],\n",
              "        [-6.04300483e-01, -1.27031016e+00],\n",
              "        [-1.10877497e+00,  1.14858995e+00],\n",
              "        [ 6.44314599e-01,  9.56992667e-01],\n",
              "        [-9.89379259e-01,  1.43420494e+00],\n",
              "        [ 3.60688993e-01, -1.41913281e+00],\n",
              "        [ 3.05757245e+00,  8.02533863e-02],\n",
              "        [ 7.50266447e-01,  4.23964853e-01],\n",
              "        [-2.19315340e-01,  1.31915105e+00],\n",
              "        [ 9.33550381e-01, -2.31296466e-01],\n",
              "        [-5.10468330e-01,  7.41753970e-01],\n",
              "        [-4.22725606e-01, -2.40543697e+00],\n",
              "        [ 7.82625350e-02,  7.77665351e-01],\n",
              "        [ 1.49376800e-01,  6.48015791e-01],\n",
              "        [ 2.18459391e+00,  9.08547003e-01],\n",
              "        [ 1.45250817e+00, -1.98062295e+00],\n",
              "        [-9.03762539e-01, -1.97830405e+00],\n",
              "        [ 3.38379307e-01,  1.31134144e+00],\n",
              "        [-9.97925058e-01,  7.41648174e-01],\n",
              "        [-2.94792699e-01, -6.86119747e-01],\n",
              "        [-6.57027257e-01,  1.04703625e+00],\n",
              "        [ 3.53483649e-01, -1.04684497e+00],\n",
              "        [-2.91308358e-01, -1.32297240e+00],\n",
              "        [ 1.07484879e+00,  8.23433889e-01],\n",
              "        [-1.91870264e+00, -9.72408379e-01],\n",
              "        [ 4.82131302e-01, -7.66786885e-01],\n",
              "        [-7.36329438e-01,  8.31344915e-01],\n",
              "        [ 4.04713428e-01,  1.39722625e+00],\n",
              "        [-1.77364406e-01, -9.63714670e-01],\n",
              "        [ 1.61892082e-02,  7.50985464e-01],\n",
              "        [-1.14015107e+00,  6.75329607e-01],\n",
              "        [-3.38696894e-01,  2.09506699e-01],\n",
              "        [ 2.69701928e-01, -3.44847643e-01],\n",
              "        [-3.92251702e-01, -5.99675561e-01],\n",
              "        [-1.24643954e+00,  1.49863868e-01],\n",
              "        [ 7.26888772e-01,  1.01551074e+00],\n",
              "        [-6.78200836e-02, -7.11586415e-01],\n",
              "        [-5.66103130e-02, -1.74011165e+00],\n",
              "        [-1.47834412e+00, -4.58217735e-01],\n",
              "        [ 9.22557925e-01,  7.22022394e-01],\n",
              "        [-1.14914412e-01, -1.66416399e-01],\n",
              "        [ 2.83963318e-01,  1.12920018e+00],\n",
              "        [ 3.70332689e-01, -2.35719846e+00],\n",
              "        [ 1.26251243e+00, -1.33798222e+00],\n",
              "        [-3.13859609e-01,  1.08169038e+00],\n",
              "        [-1.61810048e-01,  1.17513901e+00],\n",
              "        [ 6.12599632e-01, -6.08357600e-01],\n",
              "        [ 4.81312605e-01,  9.71724691e-01],\n",
              "        [-1.72375519e+00, -7.07488608e-01],\n",
              "        [ 8.25923398e-01,  1.33663561e+00],\n",
              "        [-2.69267911e-01, -2.13216450e-02],\n",
              "        [ 2.98144973e-01,  5.57058930e-01],\n",
              "        [-7.59563291e-01, -9.90655407e-01],\n",
              "        [ 1.07186791e+00, -6.00332252e-01],\n",
              "        [ 1.62752185e-01,  9.21716731e-01],\n",
              "        [-1.29386870e+00,  8.96543019e-01],\n",
              "        [-1.93393136e+00,  1.03763746e+00],\n",
              "        [ 5.35367865e-01,  1.19632359e+00],\n",
              "        [ 1.08570167e+00, -9.29783088e-01],\n",
              "        [-3.98901569e-01, -1.37282347e+00],\n",
              "        [ 7.24363038e-01, -3.74497572e-01],\n",
              "        [-5.01996284e-02,  9.92626678e-01],\n",
              "        [ 1.30783537e+00,  8.72599493e-01],\n",
              "        [-7.36954920e-01, -1.99090996e+00],\n",
              "        [ 6.44335216e-01, -9.07492218e-01],\n",
              "        [ 1.25180445e+00, -1.31323403e+00],\n",
              "        [-6.38776473e-01, -1.49137041e+00],\n",
              "        [-5.97566850e-01, -2.36224337e-01],\n",
              "        [ 3.31873096e-01,  1.16156475e+00],\n",
              "        [-6.74971949e-01,  1.23686691e+00],\n",
              "        [ 5.31870945e-01,  6.12922734e-03],\n",
              "        [-2.21627523e+00, -1.43020809e+00],\n",
              "        [ 1.24289721e+00,  3.87016394e-01],\n",
              "        [ 8.49637322e-01, -1.29314599e-01],\n",
              "        [ 1.02194219e+00, -5.46483705e-01],\n",
              "        [-6.74156049e-01,  8.03037965e-01],\n",
              "        [ 2.22795714e+00,  1.13783995e+00],\n",
              "        [-2.48854241e+00,  6.00533278e-01],\n",
              "        [-2.43518124e+00, -1.33467556e+00],\n",
              "        [-1.42672828e+00, -1.68955108e+00],\n",
              "        [-2.50691573e+00, -5.61748430e-01],\n",
              "        [-4.54727548e-01,  8.28009080e-01],\n",
              "        [ 2.97793904e-01,  9.73662817e-01],\n",
              "        [-1.55859064e-01, -9.93383540e-01],\n",
              "        [ 1.99083423e+00,  7.39232662e-01],\n",
              "        [-1.48656535e+00,  7.84957559e-01],\n",
              "        [ 6.82230917e-01,  1.43235646e+00],\n",
              "        [-2.78095935e+00,  1.33528844e+00],\n",
              "        [ 1.00844652e+00,  1.30543156e+00],\n",
              "        [-9.28369699e-01,  1.09835499e+00],\n",
              "        [-3.44366268e-01, -1.36434668e+00],\n",
              "        [ 1.43609074e+00,  5.39197880e-01],\n",
              "        [ 4.51483402e-01,  6.79791225e-01],\n",
              "        [ 8.73755570e-01,  7.88411817e-01],\n",
              "        [-5.33350199e-01, -7.01342176e-01],\n",
              "        [-5.62743687e-01,  1.05045366e+00],\n",
              "        [-7.02131498e-01, -6.29810247e-01],\n",
              "        [-1.29008702e-01, -6.50680800e-01],\n",
              "        [ 1.65294623e+00, -1.25610734e+00],\n",
              "        [ 1.22280969e+00, -6.34011641e-01],\n",
              "        [ 9.64624265e-01, -1.72598657e+00],\n",
              "        [ 8.65776779e-01, -1.21762329e+00],\n",
              "        [-2.84390861e-01,  1.28516740e-01],\n",
              "        [ 1.40697557e+00,  8.38761777e-01],\n",
              "        [ 1.20849816e+00, -5.16103953e-01],\n",
              "        [-7.32381388e-01, -3.16439954e-01],\n",
              "        [-5.62944237e-01, -1.81517397e+00],\n",
              "        [-1.30422169e-01, -8.92018698e-01],\n",
              "        [-1.54098934e+00, -1.19598653e+00],\n",
              "        [-1.45586427e+00,  1.06759553e+00],\n",
              "        [ 7.76414305e-01, -7.84042128e-01],\n",
              "        [-8.66231054e-01,  1.14435380e+00],\n",
              "        [-5.12638604e-01, -1.66997181e+00],\n",
              "        [-1.95634261e-02,  1.08597651e+00],\n",
              "        [ 2.56817317e+00,  1.00347317e+00],\n",
              "        [-5.30929289e-01,  1.37027026e+00],\n",
              "        [ 1.17325348e-01, -1.47735832e+00],\n",
              "        [ 3.39483309e-01, -1.53777198e+00],\n",
              "        [-7.65561520e-01,  1.13055983e+00],\n",
              "        [-6.24272716e-01,  1.25215523e+00],\n",
              "        [-6.09169793e-01,  1.21864793e+00],\n",
              "        [-6.44300389e-01,  1.14495920e+00],\n",
              "        [-1.69731484e-02, -1.73171939e+00],\n",
              "        [-1.15840553e+00,  1.15352059e+00],\n",
              "        [-1.45236904e+00,  4.70368522e-01],\n",
              "        [-1.60869714e+00,  1.04500028e+00],\n",
              "        [-1.07724068e+00, -9.62656450e-01],\n",
              "        [-9.78487004e-01,  1.33753667e+00],\n",
              "        [-1.03777338e+00,  8.71249143e-01],\n",
              "        [-6.40393302e-02, -2.09756863e-01],\n",
              "        [ 6.13678993e-01, -1.17730862e+00],\n",
              "        [-1.24458639e+00,  7.30610549e-01],\n",
              "        [-1.78366045e-01,  1.05159727e+00],\n",
              "        [-8.20603757e-01,  7.74998455e-01],\n",
              "        [ 4.74916742e-01, -1.14933559e+00],\n",
              "        [ 1.51944832e+00,  6.69433159e-01],\n",
              "        [-2.60818351e-02,  1.01596097e+00],\n",
              "        [-1.89499918e-01,  8.55965739e-01],\n",
              "        [-5.89184200e-01, -7.13968242e-01],\n",
              "        [-1.94083970e-01,  1.25165885e+00],\n",
              "        [ 1.03489991e+00,  1.19767297e+00],\n",
              "        [-1.66460869e+00, -9.50342075e-01],\n",
              "        [-5.68201865e-01,  9.97233331e-01],\n",
              "        [ 1.61815412e+00, -1.41098154e+00],\n",
              "        [-6.11864335e-01, -3.04394204e-01],\n",
              "        [ 5.25962696e-01, -2.00777506e+00],\n",
              "        [-1.18822392e+00,  6.05652299e-01],\n",
              "        [ 2.97069152e-01, -1.18341697e+00],\n",
              "        [-7.03010715e-01, -8.36794524e-01],\n",
              "        [-2.66744646e-01,  1.24707267e+00],\n",
              "        [-9.17862713e-01, -1.28247051e+00],\n",
              "        [ 8.29727566e-01, -1.71167084e+00],\n",
              "        [-1.74344996e+00,  9.97776869e-01],\n",
              "        [-9.67562269e-02, -1.04634812e+00],\n",
              "        [-1.40281568e+00, -9.50144300e-01],\n",
              "        [ 6.91740501e-01,  9.32466520e-01],\n",
              "        [ 8.09768501e-01,  1.25234471e+00],\n",
              "        [ 6.27158849e-02,  1.13288371e+00],\n",
              "        [-9.45670383e-01,  2.91358459e-01],\n",
              "        [-1.59015462e+00,  7.44042740e-02],\n",
              "        [-1.44035415e+00,  1.00674819e+00],\n",
              "        [-6.50672262e-01,  1.22474875e+00],\n",
              "        [ 7.70115634e-01,  7.80058089e-01],\n",
              "        [ 8.70593920e-02,  1.16291413e+00],\n",
              "        [ 2.97567420e-02, -1.70729600e+00],\n",
              "        [ 2.01124258e+00, -6.50151870e-01],\n",
              "        [ 1.24379850e+00, -1.24186239e+00],\n",
              "        [-2.62825570e+00, -1.17227297e+00],\n",
              "        [ 7.74771870e-01, -1.12994088e+00],\n",
              "        [-9.19477385e-01, -8.83574263e-01],\n",
              "        [-1.14506636e+00, -6.01617601e-01],\n",
              "        [-9.26586783e-01,  2.04149817e+00],\n",
              "        [-9.66556680e-02,  1.17882331e+00],\n",
              "        [-4.93084898e-01,  7.83595885e-01],\n",
              "        [-1.40386913e+00, -1.02071773e+00],\n",
              "        [ 1.09315404e+00,  1.25350731e+00],\n",
              "        [ 4.28358501e-01, -1.10757364e+00],\n",
              "        [-8.76150821e-01,  9.38246134e-01],\n",
              "        [ 1.34999576e+00,  5.94932219e-01],\n",
              "        [ 3.71876077e-01,  1.20938305e+00],\n",
              "        [ 9.05983584e-01,  8.39840174e-01],\n",
              "        [-1.60947813e+00,  1.00125605e+00],\n",
              "        [ 1.44416641e+00,  3.36156387e-01],\n",
              "        [ 1.25803015e+00, -1.32034853e+00],\n",
              "        [ 2.89462527e-01,  8.06161465e-01],\n",
              "        [-9.00916800e-01,  1.09612133e+00],\n",
              "        [ 1.34281872e+00, -1.98908865e+00],\n",
              "        [ 6.10165824e-01, -7.02758659e-01],\n",
              "        [ 2.52094708e+00,  1.11913471e+00],\n",
              "        [-1.34882284e+00, -2.41377262e+00],\n",
              "        [ 4.96845017e-01,  8.59549327e-01],\n",
              "        [ 1.17643799e+00, -7.50069105e-02],\n",
              "        [ 8.37403896e-01,  7.07465258e-01],\n",
              "        [-4.72235332e-02,  1.12898458e+00],\n",
              "        [ 1.98167116e-01,  1.19834281e+00],\n",
              "        [ 5.10668351e-01,  1.43624362e+00],\n",
              "        [ 1.32115979e+00,  1.08700327e+00],\n",
              "        [-1.09673065e-01, -9.38314921e-01],\n",
              "        [ 1.66128608e+00,  1.59085862e+00],\n",
              "        [ 7.10252376e-01,  1.10546805e+00],\n",
              "        [ 1.10434286e+00, -1.11628861e+00],\n",
              "        [ 4.17050342e-01,  1.06947274e+00],\n",
              "        [-5.98009083e-02,  8.22694316e-01],\n",
              "        [ 6.65546340e-01, -4.87610678e-01],\n",
              "        [-4.21253088e-01, -8.18917818e-01],\n",
              "        [-1.10963737e+00, -7.21441528e-01],\n",
              "        [-1.22825580e+00,  6.62205401e-01],\n",
              "        [ 3.27494621e+00, -3.78799528e-01],\n",
              "        [ 1.62749494e+00, -1.17694401e+00],\n",
              "        [ 3.56311070e-01, -1.83422288e+00],\n",
              "        [-1.02646091e+00,  7.30186986e-01],\n",
              "        [-6.37157920e-01, -4.27618581e-01],\n",
              "        [-5.09257270e-01,  1.47036827e+00],\n",
              "        [ 9.33095520e-02, -1.34614077e+00],\n",
              "        [-8.98607781e-01,  1.32135061e+00],\n",
              "        [-1.55593397e+00,  1.54091974e+00],\n",
              "        [ 6.42911514e-01,  9.43444347e-01],\n",
              "        [-6.07685719e-01, -9.00295674e-01],\n",
              "        [-1.00235028e+00, -7.98731516e-01],\n",
              "        [-1.80173222e-01,  8.91152061e-01],\n",
              "        [ 1.34258818e+00,  9.03842338e-01],\n",
              "        [-1.07412296e-01,  1.18497910e+00],\n",
              "        [-8.72351116e-01,  6.33199395e-01],\n",
              "        [ 9.89600289e-01,  1.26694159e+00],\n",
              "        [-1.47108290e+00,  9.47191900e-01]]),\n",
              " array([0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
              "        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
              "        0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
              "        0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
              "        1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
              "        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
              "        0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
              "        1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
              "        0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
              "        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
              "        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
              "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
              "        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
              "        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
              "        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "        0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
              "        0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
              "        1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
              "        1., 0., 0., 1., 1., 1., 1., 1., 1.]),\n",
              " <keras.engine.sequential.Sequential at 0x7f6b82a827a0>)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_keras_2d(\"3\", [Dense(units=10, activation='relu', input_dim=2), Dense(units=2, activation='softmax')], 10, split=0.5, display=False, verbose=False, trials=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_S2jbp_YD27",
        "outputId": "05a99c78-aa61-4244-9f8f-fffcc5336c72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keras FC: dataset= 1\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 1.5530\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Keras FC: dataset= 1\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.2345\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Keras FC: dataset= 1\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.0337\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Keras FC: dataset= 1\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.4308\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Keras FC: dataset= 1\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.0022\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Results for dataset 1:\n",
            "Architecture 1: Accuracy = 0.015\n",
            "Architecture 2: Accuracy = 0.99\n",
            "Architecture 3: Accuracy = 1.0\n",
            "Architecture 4: Accuracy = 0.67\n",
            "Architecture 5: Accuracy = 1.0\n",
            "Keras FC: dataset= 2\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.5569\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Keras FC: dataset= 2\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.5311\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Keras FC: dataset= 2\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.4149\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Keras FC: dataset= 2\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.5511\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Keras FC: dataset= 2\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.3367\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Results for dataset 2:\n",
            "Architecture 1: Accuracy = 0.6825\n",
            "Architecture 2: Accuracy = 0.7775\n",
            "Architecture 3: Accuracy = 0.8275\n",
            "Architecture 4: Accuracy = 0.755\n",
            "Architecture 5: Accuracy = 0.8625\n",
            "Keras FC: dataset= 3\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.7968\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Keras FC: dataset= 3\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.3000\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Keras FC: dataset= 3\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.1513\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Keras FC: dataset= 3\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.3493\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Keras FC: dataset= 3\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.1133\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Results for dataset 3:\n",
            "Architecture 1: Accuracy = 0.18\n",
            "Architecture 2: Accuracy = 0.9625\n",
            "Architecture 3: Accuracy = 0.965\n",
            "Architecture 4: Accuracy = 0.955\n",
            "Architecture 5: Accuracy = 0.9825\n",
            "Keras FC: dataset= 4\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.6985\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Keras FC: dataset= 4\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.6284\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Keras FC: dataset= 4\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.2934\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Keras FC: dataset= 4\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.5910\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Keras FC: dataset= 4\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 0.1488\n",
            "\n",
            "Avg. test accuracy: 0.0000\n",
            "Results for dataset 4:\n",
            "Architecture 1: Accuracy = 0.4725\n",
            "Architecture 2: Accuracy = 0.555\n",
            "Architecture 3: Accuracy = 0.945\n",
            "Architecture 4: Accuracy = 0.6525\n",
            "Architecture 5: Accuracy = 0.965\n",
            "Simplest architectures that meet the target accuracies:\n",
            "{'1': 2, '3': 2, '4': 3}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the function to compute accuracy\n",
        "def compute_accuracy(model, X, y, num_classes):\n",
        "    y_true = utils.to_categorical(y, num_classes)\n",
        "    y_pred = model.predict(X)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_true, axis=1)\n",
        "    accuracy = np.mean(y_pred_classes == y_true_classes)\n",
        "    return accuracy\n",
        "\n",
        "# Updated run_keras_2d function\n",
        "def run_keras_2d_vm(data_name, layers, epochs, display=True, split=0.25, verbose=True, trials=1):\n",
        "    print('Keras FC: dataset=', data_name)\n",
        "    (train_dataset, val_dataset, test_dataset) = dataset_paths(data_name)\n",
        "\n",
        "    # Load the datasets\n",
        "    X_train, y, num_classes = get_data_set(train_dataset)\n",
        "    X_val, y2, _ = get_data_set(val_dataset)\n",
        "    X_test, y3, _ = get_data_set(test_dataset)\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    y_train = utils.to_categorical(y, num_classes)\n",
        "    y_val = utils.to_categorical(y2, num_classes) if X_val is not None else None\n",
        "    y_test = utils.to_categorical(y3, num_classes) if X_test is not None else None\n",
        "\n",
        "    val_acc, test_acc = 0, 0\n",
        "    for trial in range(trials):\n",
        "        # Build the model\n",
        "        model = Sequential(layers)\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Train the model\n",
        "        history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, verbose=verbose, shuffle=True)\n",
        "\n",
        "        # Evaluate the model\n",
        "        vacc, _ = model.evaluate(X_val, y_val, verbose=verbose) if X_val is not None else (0, 0)\n",
        "        tacc, _ = model.evaluate(X_test, y3, verbose=verbose) if X_test is not None else (0, 0)\n",
        "\n",
        "        val_acc += vacc\n",
        "        test_acc += tacc\n",
        "\n",
        "        if display:\n",
        "            # Plot classifier landscape on training data\n",
        "            plot_heat(X_train, y, model)\n",
        "            plt.title('Training data')\n",
        "            plt.show()\n",
        "\n",
        "            if X_test is not None:\n",
        "                # Plot classifier landscape on testing data\n",
        "                plot_heat(X_test, y3, model)\n",
        "                plt.title('Testing data')\n",
        "                plt.show()\n",
        "\n",
        "            # Plot epoch loss\n",
        "            if 'loss' in history.history and 'val_loss' in history.history:\n",
        "                plt.plot(history.history['loss'], label='loss')\n",
        "                plt.plot(history.history['val_loss'], label='val_loss')\n",
        "                plt.xlabel('epoch')\n",
        "                plt.ylabel('loss')\n",
        "                plt.title('Epoch val_loss and loss')\n",
        "                plt.legend()\n",
        "                plt.show()\n",
        "\n",
        "            # Plot epoch accuracy\n",
        "            if 'accuracy' in history.history and 'val_accuracy' in history.history:\n",
        "                plt.plot(history.history['accuracy'], label='accuracy')\n",
        "                plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "                plt.xlabel('epoch')\n",
        "                plt.ylabel('accuracy')\n",
        "                plt.title('Epoch val_accuracy and accuracy')\n",
        "                plt.legend()\n",
        "                plt.show()\n",
        "\n",
        "    avg_val_acc = val_acc / trials if val_acc else 0\n",
        "    avg_test_acc = test_acc / trials if test_acc else 0\n",
        "\n",
        "    print(\"\\nAvg. validation accuracy: {:.4f}\".format(avg_val_acc))\n",
        "    print(\"\\nAvg. test accuracy: {:.4f}\".format(avg_test_acc))\n",
        "\n",
        "    return X_train, y, model\n",
        "\n",
        "# Define target accuracies for each dataset\n",
        "target_accuracies = {\n",
        "    '1': 0.99,\n",
        "    '2': 0.905,\n",
        "    '3': 0.96,\n",
        "    '4': 0.94\n",
        "}\n",
        "\n",
        "# Define architectures\n",
        "architectures = {\n",
        "    1: [Dense(units=2, activation='softmax')],  # Architecture 1\n",
        "    2: [Dense(units=10, activation='relu', input_dim=2), Dense(units=2, activation='softmax')],  # Architecture 2\n",
        "    3: [Dense(units=100, activation='relu', input_dim=2), Dense(units=2, activation='softmax')],  # Architecture 3\n",
        "    4: [Dense(units=10, activation='relu', input_dim=2), Dense(units=10, activation='relu'), Dense(units=2, activation='softmax')],  # Architecture 4\n",
        "    5: [Dense(units=100, activation='relu', input_dim=2), Dense(units=100, activation='relu'), Dense(units=2, activation='softmax')]  # Architecture 5\n",
        "}\n",
        "\n",
        "# Function to test architectures\n",
        "def test_architectures(data_name):\n",
        "    results = {}\n",
        "    for arch_index in range(1, 6):\n",
        "        layers = architectures[arch_index]\n",
        "        X_train, y, model = run_keras_2d_vm(data_name, layers, epochs=10, split=0.5, display=False, verbose=False, trials=1)\n",
        "\n",
        "        # Compute accuracy using the trained model\n",
        "        num_classes = len(np.unique(y))\n",
        "        accuracy = compute_accuracy(model, X_train, y, num_classes)\n",
        "\n",
        "        results[arch_index] = accuracy\n",
        "    return results\n",
        "\n",
        "# Compare architectures for each dataset\n",
        "simplest_architectures = {}\n",
        "\n",
        "for dataset in ['1', '2', '3', '4']:\n",
        "    results = test_architectures(dataset)\n",
        "    print(f\"Results for dataset {dataset}:\")\n",
        "    for arch_index in range(1, 6):\n",
        "        print(f\"Architecture {arch_index}: Accuracy = {results[arch_index]}\")\n",
        "\n",
        "    # Find the simplest architecture that meets or exceeds the target accuracy\n",
        "    target_accuracy = target_accuracies[dataset]\n",
        "    for arch_index in range(1, 6):\n",
        "        if results[arch_index] >= target_accuracy:\n",
        "            simplest_architectures[dataset] = arch_index\n",
        "            break\n",
        "\n",
        "print(\"Simplest architectures that meet the target accuracies:\")\n",
        "print(simplest_architectures)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8bTApdqYxRY",
        "outputId": "44a920a6-3046-4e27-c4b3-85bc13a2c227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keras FC: dataset= 3\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
            "Convert from -1,1 to 0,1\n",
            "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
            "\n",
            "Avg. validation accuracy: 2.0724\n",
            "\n",
            "Avg. test accuracy: 0.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([[-4.98048222e-01, -2.05324570e+00],\n",
              "        [ 4.42338898e-01, -7.90399307e-01],\n",
              "        [ 3.59454556e-02, -4.94537729e-01],\n",
              "        [-2.50691573e+00, -5.61748430e-01],\n",
              "        [-1.24458639e+00,  7.30610549e-01],\n",
              "        [-1.22825580e+00,  6.62205401e-01],\n",
              "        [-6.40393302e-02, -2.09756863e-01],\n",
              "        [ 1.22280969e+00, -6.34011641e-01],\n",
              "        [ 1.26251243e+00, -1.33798222e+00],\n",
              "        [ 8.65776779e-01, -1.21762329e+00],\n",
              "        [-1.05234752e+00, -1.19191135e+00],\n",
              "        [ 8.37403896e-01,  7.07465258e-01],\n",
              "        [ 7.74967979e-01, -5.45248881e-02],\n",
              "        [-1.93393136e+00,  1.03763746e+00],\n",
              "        [-1.25241081e-01,  7.65571558e-01],\n",
              "        [-9.17862713e-01, -1.28247051e+00],\n",
              "        [ 2.04669999e+00, -1.01775787e+00],\n",
              "        [ 3.19006021e-01,  7.05395797e-01],\n",
              "        [-1.48038581e+00,  1.05573465e+00],\n",
              "        [-6.74156049e-01,  8.03037965e-01],\n",
              "        [-2.21627523e+00, -1.43020809e+00],\n",
              "        [-9.89379259e-01,  1.43420494e+00],\n",
              "        [-1.44035415e+00,  1.00674819e+00],\n",
              "        [ 1.61815412e+00, -1.41098154e+00],\n",
              "        [ 7.15681337e-01, -7.61277410e-02],\n",
              "        [ 1.47028284e+00, -1.02889795e+00],\n",
              "        [ 1.03489991e+00,  1.19767297e+00],\n",
              "        [-1.14914412e-01, -1.66416399e-01],\n",
              "        [ 1.10434286e+00, -1.11628861e+00],\n",
              "        [ 5.10668351e-01,  1.43624362e+00],\n",
              "        [-4.73362117e-01,  5.83668048e-01],\n",
              "        [-1.00263655e+00,  6.72766167e-01],\n",
              "        [-1.80173222e-01,  8.91152061e-01],\n",
              "        [-1.55601351e-01, -4.15193470e-01],\n",
              "        [ 1.44416641e+00,  3.36156387e-01],\n",
              "        [ 1.84385841e+00, -1.19911559e+00],\n",
              "        [ 3.38379307e-01,  1.31134144e+00],\n",
              "        [ 1.34999576e+00,  5.94932219e-01],\n",
              "        [ 6.21830757e-01,  1.03110956e+00],\n",
              "        [ 5.25962696e-01, -2.00777506e+00],\n",
              "        [-2.94792699e-01, -6.86119747e-01],\n",
              "        [ 2.70581984e-01,  8.32604236e-01],\n",
              "        [-5.02895716e-01,  1.03914579e+00],\n",
              "        [-8.59917131e-01, -7.74332383e-01],\n",
              "        [ 2.97567420e-02, -1.70729600e+00],\n",
              "        [-1.37496427e+00, -2.14360387e+00],\n",
              "        [-1.74711514e-01, -2.36960028e+00],\n",
              "        [ 7.17487011e-01,  1.40977888e+00],\n",
              "        [-1.26693058e-01, -7.50666180e-01],\n",
              "        [ 4.96845017e-01,  8.59549327e-01],\n",
              "        [ 6.97383772e-01, -2.26678389e+00],\n",
              "        [-1.14506636e+00, -6.01617601e-01],\n",
              "        [-6.53755185e-01,  1.22121044e+00],\n",
              "        [-9.66556680e-02,  1.17882331e+00],\n",
              "        [-9.26586783e-01,  2.04149817e+00],\n",
              "        [-1.47108290e+00,  9.47191900e-01],\n",
              "        [-2.48854241e+00,  6.00533278e-01],\n",
              "        [-1.29386870e+00,  8.96543019e-01],\n",
              "        [-8.60042024e-01,  6.82399393e-01],\n",
              "        [ 1.20849816e+00, -5.16103953e-01],\n",
              "        [ 2.33610938e-02, -1.84518665e+00],\n",
              "        [-1.91870264e+00, -9.72408379e-01],\n",
              "        [-1.61810048e-01,  1.17513901e+00],\n",
              "        [-9.10797208e-01, -1.51408134e+00],\n",
              "        [-8.55522699e-01, -4.78157321e-01],\n",
              "        [-6.57027257e-01,  1.04703625e+00],\n",
              "        [ 1.51944832e+00,  6.69433159e-01],\n",
              "        [ 8.73755570e-01,  7.88411817e-01],\n",
              "        [ 2.97793904e-01,  9.73662817e-01],\n",
              "        [-1.54337318e+00, -5.27867198e-01],\n",
              "        [ 6.65546340e-01, -4.87610678e-01],\n",
              "        [-6.21091558e-03, -1.53802337e+00],\n",
              "        [-4.83400521e-01,  5.84297393e-01],\n",
              "        [-8.88840612e-01,  9.57599953e-01],\n",
              "        [-2.58962352e-01,  9.36627693e-01],\n",
              "        [ 2.82678103e-01, -1.52199667e+00],\n",
              "        [-1.10963737e+00, -7.21441528e-01],\n",
              "        [ 9.33550381e-01, -2.31296466e-01],\n",
              "        [ 2.83963318e-01,  1.12920018e+00],\n",
              "        [ 1.55798065e-01,  9.80926148e-01],\n",
              "        [ 9.33095520e-02, -1.34614077e+00],\n",
              "        [-2.19315340e-01,  1.31915105e+00],\n",
              "        [ 1.61892082e-02,  7.50985464e-01],\n",
              "        [-5.89184200e-01, -7.13968242e-01],\n",
              "        [ 1.63713564e+00, -2.17432334e+00],\n",
              "        [ 2.01124258e+00, -6.50151870e-01],\n",
              "        [-5.10468330e-01,  7.41753970e-01],\n",
              "        [ 5.35367865e-01,  1.19632359e+00],\n",
              "        [ 5.01637382e-02, -1.86205461e-01],\n",
              "        [-3.44555998e-01,  4.75899767e-03],\n",
              "        [-1.29008702e-01, -6.50680800e-01],\n",
              "        [-6.07685719e-01, -9.00295674e-01],\n",
              "        [-1.91133900e-01, -1.35711833e+00],\n",
              "        [ 9.04075035e-01, -4.19988897e-01],\n",
              "        [-1.06101136e+00,  9.01626186e-01],\n",
              "        [ 4.20037118e-01,  1.03254396e+00],\n",
              "        [-8.66231054e-01,  1.14435380e+00],\n",
              "        [ 4.04713428e-01,  1.39722625e+00],\n",
              "        [-1.24643954e+00,  1.49863868e-01],\n",
              "        [ 1.25901523e+00,  1.11166169e+00],\n",
              "        [ 6.82230917e-01,  1.43235646e+00],\n",
              "        [-4.93084898e-01,  7.83595885e-01],\n",
              "        [ 4.82131302e-01, -7.66786885e-01],\n",
              "        [-1.80086374e-01, -1.62109929e+00],\n",
              "        [ 4.17050342e-01,  1.06947274e+00],\n",
              "        [ 1.80089979e-01,  8.68041199e-01],\n",
              "        [ 1.99083423e+00,  7.39232662e-01],\n",
              "        [-1.92028794e-01,  6.18618137e-01],\n",
              "        [-3.38696894e-01,  2.09506699e-01],\n",
              "        [ 8.09768501e-01,  1.25234471e+00],\n",
              "        [-5.62944237e-01, -1.81517397e+00],\n",
              "        [-6.09169793e-01,  1.21864793e+00],\n",
              "        [ 7.74771870e-01, -1.12994088e+00],\n",
              "        [-7.36954920e-01, -1.99090996e+00],\n",
              "        [-6.50672262e-01,  1.22474875e+00],\n",
              "        [-1.10192400e-01, -1.62969750e+00],\n",
              "        [-1.48656535e+00,  7.84957559e-01],\n",
              "        [ 1.24379850e+00, -1.24186239e+00],\n",
              "        [ 1.32115979e+00,  1.08700327e+00],\n",
              "        [ 7.70115634e-01,  7.80058089e-01],\n",
              "        [-2.84390861e-01,  1.28516740e-01],\n",
              "        [-1.64588447e+00, -1.79336505e+00],\n",
              "        [-9.28369699e-01,  1.09835499e+00],\n",
              "        [ 7.14038234e-01,  1.02249603e+00],\n",
              "        [ 5.75533547e-01, -1.77035812e+00],\n",
              "        [-9.51855250e-01, -2.25623806e+00],\n",
              "        [-1.47211524e-01, -6.12836186e-01],\n",
              "        [ 1.64094544e+00, -7.78994384e-01],\n",
              "        [ 2.18459391e+00,  9.08547003e-01],\n",
              "        [ 4.70360399e-01,  1.05361224e+00],\n",
              "        [-1.05960887e+00,  1.27313945e+00],\n",
              "        [ 1.25803015e+00, -1.32034853e+00],\n",
              "        [-9.00916800e-01,  1.09612133e+00],\n",
              "        [-1.89499918e-01,  8.55965739e-01],\n",
              "        [ 1.29299584e+00,  1.13473841e+00],\n",
              "        [ 3.59507195e-01,  7.53390980e-01],\n",
              "        [-3.98901569e-01, -1.37282347e+00],\n",
              "        [-7.03010715e-01, -8.36794524e-01],\n",
              "        [-8.72351116e-01,  6.33199395e-01],\n",
              "        [ 1.66128608e+00,  1.59085862e+00],\n",
              "        [ 5.56595729e-01, -9.68298445e-01],\n",
              "        [-1.55593397e+00,  1.54091974e+00],\n",
              "        [-6.36989768e-01,  8.95222556e-01],\n",
              "        [-1.15840553e+00,  1.15352059e+00],\n",
              "        [-2.81881752e-01, -8.84938507e-01],\n",
              "        [-7.93915442e-02,  5.93908225e-01],\n",
              "        [ 1.92377126e-01, -1.50177035e-01],\n",
              "        [ 2.84183705e-01,  9.97209950e-01],\n",
              "        [-8.19227913e-01,  1.13638010e+00],\n",
              "        [-1.07412296e-01,  1.18497910e+00],\n",
              "        [ 5.05644320e-01, -1.31135357e+00],\n",
              "        [-2.91308358e-01, -1.32297240e+00],\n",
              "        [-6.11864335e-01, -3.04394204e-01],\n",
              "        [-2.09114448e-01,  4.01341583e-01],\n",
              "        [ 1.52537231e+00, -7.05544863e-01],\n",
              "        [ 4.10510520e-01, -5.62003310e-01],\n",
              "        [ 1.34281872e+00, -1.98908865e+00],\n",
              "        [-5.76529670e-01, -9.03522018e-01],\n",
              "        [-1.03777338e+00,  8.71249143e-01],\n",
              "        [-7.02131498e-01, -6.29810247e-01],\n",
              "        [ 1.15606866e-01,  6.01664637e-01],\n",
              "        [-1.10877497e+00,  1.14858995e+00],\n",
              "        [-9.97925058e-01,  7.41648174e-01],\n",
              "        [-4.22725606e-01, -2.40543697e+00],\n",
              "        [-1.34882284e+00, -2.41377262e+00],\n",
              "        [-1.72375519e+00, -7.07488608e-01],\n",
              "        [ 1.16818754e+00, -4.06042985e-01],\n",
              "        [-1.12435698e+00, -4.30035232e-01],\n",
              "        [ 7.82625350e-02,  7.77665351e-01],\n",
              "        [-1.10907769e+00,  6.14530338e-01],\n",
              "        [ 8.29727566e-01, -1.71167084e+00],\n",
              "        [ 4.45047706e-01, -8.43962960e-01],\n",
              "        [-1.74344996e+00,  9.97776869e-01],\n",
              "        [ 6.13678993e-01, -1.17730862e+00],\n",
              "        [ 1.13615505e+00,  9.34159707e-01],\n",
              "        [ 1.62749494e+00, -1.17694401e+00],\n",
              "        [-2.06423656e+00, -1.49811482e+00],\n",
              "        [-7.19309633e-01, -9.10266737e-01],\n",
              "        [-1.60947813e+00,  1.00125605e+00],\n",
              "        [-9.78487004e-01,  1.33753667e+00],\n",
              "        [-1.40386913e+00, -1.02071773e+00],\n",
              "        [ 1.40697557e+00,  8.38761777e-01],\n",
              "        [-1.00421449e+00,  9.21219259e-01],\n",
              "        [-2.62825570e+00, -1.17227297e+00],\n",
              "        [-3.92251702e-01, -5.99675561e-01],\n",
              "        [-1.69731484e-02, -1.73171939e+00],\n",
              "        [ 1.17643799e+00, -7.50069105e-02],\n",
              "        [-4.14832677e-01, -7.61685543e-01],\n",
              "        [ 5.93103644e-01,  1.20379038e+00],\n",
              "        [ 1.99009149e+00,  9.04658862e-01],\n",
              "        [ 1.15960716e+00, -1.52652878e+00],\n",
              "        [ 1.30783537e+00,  8.72599493e-01],\n",
              "        [-1.00235028e+00, -7.98731516e-01],\n",
              "        [ 1.56110391e+00, -4.70849410e-01],\n",
              "        [-1.94083970e-01,  1.25165885e+00],\n",
              "        [-4.21253088e-01, -8.18917818e-01],\n",
              "        [ 1.51880196e-01, -1.13827324e+00],\n",
              "        [-7.59563291e-01, -9.90655407e-01],\n",
              "        [ 7.58980601e-01,  1.17926749e+00],\n",
              "        [ 5.31870945e-01,  6.12922734e-03],\n",
              "        [ 8.70593920e-02,  1.16291413e+00],\n",
              "        [ 6.27158849e-02,  1.13288371e+00],\n",
              "        [ 1.03397734e+00,  9.94625504e-01],\n",
              "        [ 1.25180445e+00, -1.31323403e+00],\n",
              "        [-3.23073838e-01, -1.53094630e+00],\n",
              "        [ 1.27208381e-01,  1.33817514e+00],\n",
              "        [ 3.17664339e-01,  1.14073734e+00],\n",
              "        [-8.20603757e-01,  7.74998455e-01],\n",
              "        [-9.19477385e-01, -8.83574263e-01],\n",
              "        [ 3.39483309e-01, -1.53777198e+00],\n",
              "        [ 3.56311070e-01, -1.83422288e+00],\n",
              "        [-1.47834412e+00, -4.58217735e-01],\n",
              "        [-1.02646091e+00,  7.30186986e-01],\n",
              "        [-1.95634261e-02,  1.08597651e+00],\n",
              "        [-8.83476976e-01,  1.09421850e+00],\n",
              "        [-1.42672828e+00, -1.68955108e+00],\n",
              "        [ 9.89600289e-01,  1.26694159e+00],\n",
              "        [ 5.14712326e-01,  1.11414252e+00],\n",
              "        [ 3.11442245e-01,  1.10354795e+00],\n",
              "        [ 7.34556744e-01,  1.12729093e+00],\n",
              "        [ 3.27494621e+00, -3.78799528e-01],\n",
              "        [ 1.12891929e-01,  9.84968701e-01],\n",
              "        [ 1.53758454e+00,  4.26999405e-01],\n",
              "        [-8.19510632e-01,  9.16036256e-01],\n",
              "        [ 3.53483649e-01, -1.04684497e+00],\n",
              "        [ 1.83689989e-01, -2.78607469e-01],\n",
              "        [ 6.91740501e-01,  9.32466520e-01],\n",
              "        [-1.29854547e+00, -1.78213954e+00],\n",
              "        [ 1.34258818e+00,  9.03842338e-01],\n",
              "        [-1.66460869e+00, -9.50342075e-01],\n",
              "        [ 2.52094708e+00,  1.11913471e+00],\n",
              "        [ 4.81312605e-01,  9.71724691e-01],\n",
              "        [-1.28541366e+00,  8.89537258e-01],\n",
              "        [-1.56887718e+00,  1.58366785e+00],\n",
              "        [ 1.98167116e-01,  1.19834281e+00],\n",
              "        [ 3.43319427e-01, -1.58022728e+00],\n",
              "        [ 7.50266447e-01,  4.23964853e-01],\n",
              "        [ 1.24289721e+00,  3.87016394e-01],\n",
              "        [-2.66744646e-01,  1.24707267e+00],\n",
              "        [-1.60869714e+00,  1.04500028e+00],\n",
              "        [-1.40281568e+00, -9.50144300e-01],\n",
              "        [ 2.56817317e+00,  1.00347317e+00],\n",
              "        [-5.62743687e-01,  1.05045366e+00],\n",
              "        [ 3.80551397e+00,  1.49137866e-01],\n",
              "        [-3.90186213e-01,  8.66811674e-01],\n",
              "        [ 7.10252376e-01,  1.10546805e+00],\n",
              "        [ 2.68572445e-01,  9.19915554e-01],\n",
              "        [ 1.02885868e+00,  1.03520193e+00],\n",
              "        [ 1.10922347e+00, -1.68327194e+00],\n",
              "        [ 7.26888772e-01,  1.01551074e+00],\n",
              "        [-1.78366045e-01,  1.05159727e+00],\n",
              "        [-9.70534473e-01,  1.13151763e+00],\n",
              "        [-1.18857664e+00,  1.33689522e+00],\n",
              "        [ 2.22795714e+00,  1.13783995e+00],\n",
              "        [ 6.12599632e-01, -6.08357600e-01],\n",
              "        [ 1.17325348e-01, -1.47735832e+00],\n",
              "        [ 8.25923398e-01,  1.33663561e+00],\n",
              "        [-2.87826838e-01,  8.75110161e-01],\n",
              "        [ 9.82494282e-01, -1.33938777e+00],\n",
              "        [-8.98607781e-01,  1.32135061e+00],\n",
              "        [-2.69641336e-01, -1.31882248e+00],\n",
              "        [ 2.88990304e-01, -3.04575699e-01],\n",
              "        [ 3.70332689e-01, -2.35719846e+00],\n",
              "        [-5.98009083e-02,  8.22694316e-01],\n",
              "        [ 1.43609074e+00,  5.39197880e-01],\n",
              "        [ 1.08570167e+00, -9.29783088e-01],\n",
              "        [ 4.51483402e-01,  6.79791225e-01],\n",
              "        [-1.23416151e+00,  1.19439315e+00],\n",
              "        [-1.09673065e-01, -9.38314921e-01],\n",
              "        [ 1.65294623e+00, -1.25610734e+00],\n",
              "        [-2.60818351e-02,  1.01596097e+00],\n",
              "        [ 2.74061755e-02, -1.06785991e+00],\n",
              "        [ 1.09315404e+00,  1.25350731e+00],\n",
              "        [-6.24272716e-01,  1.25215523e+00],\n",
              "        [ 4.51101916e-01,  1.05104320e+00],\n",
              "        [-7.65561520e-01,  1.13055983e+00],\n",
              "        [ 1.63904127e-01,  8.16453466e-01],\n",
              "        [-3.27830527e-01,  1.18556267e+00],\n",
              "        [-1.67530495e+00,  1.03949695e+00],\n",
              "        [ 6.44335216e-01, -9.07492218e-01],\n",
              "        [-6.38776473e-01, -1.49137041e+00],\n",
              "        [-2.48121610e+00, -1.36699313e+00],\n",
              "        [-6.74971949e-01,  1.23686691e+00],\n",
              "        [-9.49084956e-01,  1.13001262e+00],\n",
              "        [-5.68201865e-01,  9.97233331e-01],\n",
              "        [-5.66103130e-02, -1.74011165e+00],\n",
              "        [-1.11206353e+00, -1.69493671e+00],\n",
              "        [-6.44300389e-01,  1.14495920e+00],\n",
              "        [-3.44366268e-01, -1.36434668e+00],\n",
              "        [-9.45670383e-01,  2.91358459e-01],\n",
              "        [ 1.07186791e+00, -6.00332252e-01],\n",
              "        [ 1.03949361e+00, -9.53568987e-01],\n",
              "        [-1.45586427e+00,  1.06759553e+00],\n",
              "        [ 4.74916742e-01, -1.14933559e+00],\n",
              "        [ 6.10165824e-01, -7.02758659e-01],\n",
              "        [-1.79255442e-01,  9.04111402e-01],\n",
              "        [-6.25363136e-01, -2.16919689e+00],\n",
              "        [ 1.55592533e+00,  9.77496170e-01],\n",
              "        [-4.72235332e-02,  1.12898458e+00],\n",
              "        [ 4.69102326e-01,  1.00753548e+00],\n",
              "        [ 1.07484879e+00,  8.23433889e-01],\n",
              "        [-3.73398803e-02, -1.92251617e+00],\n",
              "        [-1.45236904e+00,  4.70368522e-01],\n",
              "        [ 6.06949123e-01, -1.92695095e+00],\n",
              "        [-9.67562269e-02, -1.04634812e+00],\n",
              "        [ 1.45250817e+00, -1.98062295e+00],\n",
              "        [ 8.71930256e-01,  9.44092465e-01],\n",
              "        [-5.12638604e-01, -1.66997181e+00],\n",
              "        [ 3.76946605e-03, -2.19287900e+00],\n",
              "        [-3.13859609e-01,  1.08169038e+00],\n",
              "        [-6.04300483e-01, -1.27031016e+00],\n",
              "        [-3.12358157e-01, -1.47095439e+00],\n",
              "        [-5.97566850e-01, -2.36224337e-01],\n",
              "        [-6.37157920e-01, -4.27618581e-01],\n",
              "        [ 9.05983584e-01,  8.39840174e-01],\n",
              "        [-3.55639647e-02,  1.26847710e+00],\n",
              "        [ 3.71876077e-01,  1.20938305e+00],\n",
              "        [-2.79335783e-01, -8.87909018e-01],\n",
              "        [ 4.86250026e-01, -1.56351910e+00],\n",
              "        [ 3.07141783e-01, -5.24623805e-01],\n",
              "        [ 1.43637773e+00,  8.88204900e-01],\n",
              "        [-1.21620968e+00,  6.83049065e-01],\n",
              "        [-1.55859064e-01, -9.93383540e-01],\n",
              "        [-1.56985091e+00,  1.81721816e-01],\n",
              "        [-8.76150821e-01,  9.38246134e-01],\n",
              "        [ 7.87116585e-01, -5.48711063e-01],\n",
              "        [-4.61139539e-01, -7.41682510e-01],\n",
              "        [ 2.40553070e-01,  7.52439524e-01],\n",
              "        [ 7.76414305e-01, -7.84042128e-01],\n",
              "        [-1.27959872e-01,  1.42780257e+00],\n",
              "        [ 3.05757245e+00,  8.02533863e-02],\n",
              "        [ 2.97069152e-01, -1.18341697e+00],\n",
              "        [ 2.02584111e+00,  4.63471587e-03],\n",
              "        [ 4.28358501e-01, -1.10757364e+00],\n",
              "        [-1.02974722e+00,  8.08029008e-01],\n",
              "        [-2.69267911e-01, -2.13216450e-02],\n",
              "        [-9.03762539e-01, -1.97830405e+00],\n",
              "        [ 2.98144973e-01,  5.57058930e-01],\n",
              "        [ 5.41193475e-01, -1.16136205e+00],\n",
              "        [ 1.05421974e+00, -1.32045158e+00],\n",
              "        [-5.09257270e-01,  1.47036827e+00],\n",
              "        [ 3.01511975e-01,  6.02119507e-01],\n",
              "        [-6.78200836e-02, -7.11586415e-01],\n",
              "        [ 1.02194219e+00, -5.46483705e-01],\n",
              "        [-1.77364406e-01, -9.63714670e-01],\n",
              "        [ 1.53031689e+00, -1.42527722e+00],\n",
              "        [-7.32381388e-01, -3.16439954e-01],\n",
              "        [-2.07979093e+00,  3.40368771e-01],\n",
              "        [ 6.44314599e-01,  9.56992667e-01],\n",
              "        [-2.77688414e-01, -7.44748537e-01],\n",
              "        [ 8.49637322e-01, -1.29314599e-01],\n",
              "        [ 2.15120831e-01, -1.07328215e+00],\n",
              "        [-5.15713362e-01, -2.05668156e+00],\n",
              "        [ 2.50246022e-01,  1.16369383e+00],\n",
              "        [ 1.49791013e+00, -9.05810242e-01],\n",
              "        [-6.11094774e-01, -1.75893850e+00],\n",
              "        [ 4.82659146e-01, -1.18185819e+00],\n",
              "        [ 1.50096157e+00, -1.67580194e+00],\n",
              "        [ 1.24118132e-01, -1.30177445e+00],\n",
              "        [ 1.65836601e-01,  1.04371696e+00],\n",
              "        [ 2.69701928e-01, -3.44847643e-01],\n",
              "        [-3.90784151e-01,  9.14456623e-01],\n",
              "        [-9.22451178e-01,  1.55938011e+00],\n",
              "        [-5.33350199e-01, -7.01342176e-01],\n",
              "        [-2.43518124e+00, -1.33467556e+00],\n",
              "        [-1.59015462e+00,  7.44042740e-02],\n",
              "        [ 6.42911514e-01,  9.43444347e-01],\n",
              "        [-1.54098934e+00, -1.19598653e+00],\n",
              "        [ 6.65228620e-01,  1.05274437e+00],\n",
              "        [ 6.37641117e-01,  9.24521718e-01],\n",
              "        [ 2.89462527e-01,  8.06161465e-01],\n",
              "        [ 9.64624265e-01, -1.72598657e+00],\n",
              "        [-1.30422169e-01, -8.92018698e-01],\n",
              "        [ 3.31873096e-01,  1.16156475e+00],\n",
              "        [-6.46615721e-02,  7.29392228e-01],\n",
              "        [-9.15863874e-01,  1.16368824e+00],\n",
              "        [-8.71517413e-02, -1.67901807e+00],\n",
              "        [-5.01996284e-02,  9.92626678e-01],\n",
              "        [ 1.00844652e+00,  1.30543156e+00],\n",
              "        [ 9.22557925e-01,  7.22022394e-01],\n",
              "        [-2.80759883e-01, -6.54796310e-01],\n",
              "        [ 7.44323809e-01, -1.11690801e+00],\n",
              "        [-1.33650871e-01, -9.32036395e-01],\n",
              "        [-2.78095935e+00,  1.33528844e+00],\n",
              "        [ 1.49376800e-01,  6.48015791e-01],\n",
              "        [ 2.27937491e+00, -5.31454264e-01],\n",
              "        [-5.30929289e-01,  1.37027026e+00],\n",
              "        [ 1.10961771e+00, -1.71291812e+00],\n",
              "        [-5.14657260e-01,  1.25692322e+00],\n",
              "        [-1.07724068e+00, -9.62656450e-01],\n",
              "        [ 3.60688993e-01, -1.41913281e+00],\n",
              "        [-1.14015107e+00,  6.75329607e-01],\n",
              "        [ 1.62752185e-01,  9.21716731e-01],\n",
              "        [-4.54727548e-01,  8.28009080e-01],\n",
              "        [-7.97818459e-01,  1.73665182e-01],\n",
              "        [ 7.24363038e-01, -3.74497572e-01],\n",
              "        [-1.17264210e+00, -2.10489761e+00],\n",
              "        [ 4.61412128e-01,  1.62721884e+00],\n",
              "        [-7.36329438e-01,  8.31344915e-01],\n",
              "        [-1.18822392e+00,  6.05652299e-01]]),\n",
              " array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
              "        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
              "        0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
              "        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
              "        1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
              "        0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
              "        0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
              "        1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
              "        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
              "        0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
              "        0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
              "        0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
              "        1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
              "        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
              "        1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
              "        1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
              "        0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
              "        1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
              "        1., 1., 1., 0., 0., 0., 1., 1., 0.]),\n",
              " <keras.engine.sequential.Sequential at 0x7f6b810f9db0>)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_keras_2d_vm(\"3\", archs(2)[0], 10, split=0.5, display=False, verbose=False, trials=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh4u39OCjLza"
      },
      "source": [
        "# Weight sharing (OPTIONAL)\n",
        "\n",
        "** Note: You can click the arrow on the left of this text block to collapse/expand this optional section and all its code blocks **\n",
        "\n",
        "In the lab we designed a CNN that can count the number of objects in 1 dimensional images, where each black pixel is represented by a value of 0 and each white pixel is represented by a value of 1. Recall that an object is a consecutive sequence of black pixels ($0$'s). For example, the sequence $0100110$ contains three objects.\n",
        "\n",
        "Here we want to see how hard/easy it is to train such a network from data.  Our network architecture will be as follows:\n",
        "\n",
        "* The first layer is convolutional and you will implement it using the Keras `Conv1D` function, with a kernel of size 2 and stride of 1 with ReLu activation.\n",
        "\n",
        "* The second layer is a fully connected `Dense` layer which has a scalar output.\n",
        "\n",
        "Here is sample usage of the `Conv1D` and`Dense` layers.\n",
        "\n",
        "`layer1=keras.layers.Conv1D(filters=?, kernel_size=?, strides=?,use_bias=False, activation=?, batch_size=1, input_shape=?, padding='same')`\n",
        "\n",
        "`Dense(units=?, activation=?, use_bias=False)`\n",
        "\n",
        "You need to fill in the parameters marked with `?` based on the problem specifications. Note also that in Keras, depending on your implementation, you may be forced to use *three* layers to implement such a network, where one intermediary `Flatten` layer is used to flatten the output of the convolutional layer, before being passed to the dense layer.\n",
        "\n",
        "Refer to the <a href=\"https://keras.io/layers/convolutional/\">Conv 1D</a>, <a href=\"https://keras.io/layers/core/\">Dense</a> and <a href=\"https://keras.io/layers/core/#flatten\">Flatten</a> descriptions in the Keras documentation to see the available parameter options.\n",
        "\n",
        "In this exercise, we fix the structure and want to learn the best combination of weights from data. In the homework code, we have provided functions `train_neural_counter` and `get_image_data_1d`. You can use them to generate data and train the above neural network in Keras to answer the following questions. We assume that the images in our data set are randomly generated. The probability of a pixel being white is $0.1$. We work with mean squared error as the loss function for this problem. We have provided template code which you can fill in, to perform the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKa8iMv_j3ek"
      },
      "source": [
        "<b>4B)</b> What is (approximately) the expected loss of the network on $1024\\times 1$ images if the convolutional layer is an averaging filter and second layer is the sum function (without a bias term)? (Note that you can answer the question theoretically or through coding, depending on your preference.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKPcB588ok8a",
        "outputId": "2cccb419-627e-46b2-add3-952aa72bd074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 7ms/step - loss: 102.3577\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "102.35774993896484"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Code template if you would like to check 4B) through code\n",
        "\n",
        "imsize = 1024\n",
        "prob_white = 0.1\n",
        "\n",
        "num_filters = 1  # Your code\n",
        "kernel_size = 2  # Your code\n",
        "strides = 1  # Your code\n",
        "activation_conv = 'relu'  # Your code\n",
        "\n",
        "(X_train,Y_train,X_val,Y_val,X_test,Y_test) = get_image_data_1d(1000,imsize,prob_white)\n",
        "\n",
        "layer1=keras.layers.Conv1D(filters=num_filters, kernel_size=kernel_size, \\\n",
        "       strides=strides, use_bias=False, activation=activation_conv, batch_size=1, input_shape=(imsize,1), padding='same')\n",
        "\n",
        "activation_dense = 'linear'  # Your code\n",
        "num_units = 1  # Your code\n",
        "layer3=Dense(units=num_units, activation=activation_dense, use_bias=False)\n",
        "\n",
        "layers=[layer1,Flatten(),layer3]\n",
        "\n",
        "# This is how we create the model using our layers\n",
        "model=Sequential()\n",
        "for layer in layers:\n",
        "    model.add(layer)\n",
        "\n",
        "model.compile(loss='mse', optimizer=Adam())\n",
        "\n",
        "# Set the weights of the layers to desired values\n",
        "# We give you the lines to use for this part\n",
        "model.layers[0].set_weights([np.array([1/2,1/2]).reshape(2,1,1)])\n",
        "model.layers[-1].set_weights([np.ones(imsize).reshape(imsize,1)])\n",
        "\n",
        "model.evaluate(X_test,Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js3OYsbwj7Ms"
      },
      "source": [
        "<b>4C)</b> Now suppose we add a bias term of $-10$ to the last layer. What is (approximately) the expected quadratic loss? (Note that you can answer the question theoretically or through coding, depending on your preference.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcxtIYNaF70_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils, Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def run_keras_2d_vm_1(data_name, layers, epochs, display=True, split=0.25, verbose=True, trials=1):\n",
        "    \"\"\"\n",
        "    Run a Keras 2D model with specified architecture on a given dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - data_name: Name of the dataset (assumed to be a CSV file)\n",
        "    - layers: List of Keras layers to use for the model\n",
        "    - epochs: Number of epochs for training\n",
        "    - display: Whether to display training/testing data plots\n",
        "    - split: Fraction of data to use for validation\n",
        "    - verbose: Verbosity of the training process\n",
        "    - trials: Number of trials to run\n",
        "    \"\"\"\n",
        "\n",
        "    print('Keras FC: dataset=', data_name)\n",
        "\n",
        "    # Helper function to load dataset\n",
        "    def get_data_set(file_path):\n",
        "        try:\n",
        "            data = pd.read_csv(file_path)\n",
        "            print(data.head())  # Check the first few rows to ensure data is loaded correctly\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading dataset: {e}\")\n",
        "            return None, None, 0\n",
        "\n",
        "        # Example preprocessing, adjust according to your actual data\n",
        "        X = data.iloc[:, :-1].values  # Features\n",
        "        y = data.iloc[:, -1].values   # Labels\n",
        "        num_classes = len(set(y))     # Assuming `y` contains class labels\n",
        "\n",
        "        return X, y, num_classes\n",
        "\n",
        "    # Load the datasets\n",
        "    file_path = f'{data_name}.csv'\n",
        "    if not os.path.isfile(file_path):\n",
        "        raise FileNotFoundError(f\"{file_path} not found\")\n",
        "\n",
        "    X_train, y, num_classes = get_data_set(file_path)\n",
        "    X_val, y2, _ = get_data_set(file_path)  # For demonstration; adjust as necessary\n",
        "    X_test, y3, _ = get_data_set(file_path)  # For demonstration; adjust as necessary\n",
        "\n",
        "    # Check if datasets are loaded properly\n",
        "    if X_train is None or y is None or X_val is None or (X_test is not None and y3 is None):\n",
        "        raise ValueError(\"One or more datasets are not loaded correctly. Please check your data loading functions.\")\n",
        "\n",
        "    print(f'Number of classes: {num_classes}')\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    y_train = utils.to_categorical(y, num_classes)\n",
        "    y_val = utils.to_categorical(y2, num_classes) if X_val is not None else None\n",
        "    y_test = utils.to_categorical(y3, num_classes) if X_test is not None else None\n",
        "\n",
        "    val_acc, test_acc = 0, 0\n",
        "    for trial in range(trials):\n",
        "        try:\n",
        "            # Build the model\n",
        "            model = Sequential(layers)\n",
        "            model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        except Exception as e:\n",
        "            print(f\"Error building the model: {e}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Train the model\n",
        "            history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, verbose=verbose, shuffle=True)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during model training: {e}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Evaluate the model\n",
        "            vacc, _ = model.evaluate(X_val, y_val, verbose=verbose) if X_val is not None else (0, 0)\n",
        "            tacc, _ = model.evaluate(X_test, y3, verbose=verbose) if X_test is not None else (0, 0)\n",
        "\n",
        "            val_acc += vacc\n",
        "            test_acc += tacc\n",
        "        except Exception as e:\n",
        "            print(f\"Error during model evaluation: {e}\")\n",
        "            continue\n",
        "\n",
        "        if display:\n",
        "            try:\n",
        "                # Plot classifier landscape on training data\n",
        "                plot_heat(X_train, y, model)\n",
        "                plt.title('Training data')\n",
        "                plt.show()\n",
        "\n",
        "                if X_test is not None:\n",
        "                    # Plot classifier landscape on testing data\n",
        "                    plot_heat(X_test, y3, model)\n",
        "                    plt.title('Testing data')\n",
        "                    plt.show()\n",
        "            except Exception as e:\n",
        "                print(f\"Error during plotting: {e}\")\n",
        "\n",
        "    print(f'Average validation accuracy: {val_acc / trials}')\n",
        "    print(f'Average test accuracy: {test_acc / trials}')\n",
        "\n",
        "def plot_heat(X, y, model):\n",
        "    \"\"\"\n",
        "    Placeholder for plot_heat function. Implement this function based on your needs.\n",
        "    \"\"\"\n",
        "    pass  # Replace with actual implementation\n",
        "\n",
        "# Example usage:\n",
        "# run_keras_2d_vm(\"3class\", archs(3)[0], 10, split=0.5, display=False, verbose=False, trials=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKynxhF1klga",
        "outputId": "e98bb70a-b858-4f4b-9897-6ebf4033a397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 7ms/step - loss: 12.8658\n",
            "Test Loss: 12.865750312805176\n"
          ]
        }
      ],
      "source": [
        "# Edit code from 4B) with the bias\n",
        "\n",
        "# Parameters\n",
        "imsize = 1024\n",
        "prob_white = 0.1\n",
        "\n",
        "num_filters = 1\n",
        "kernel_size = 2\n",
        "strides = 1\n",
        "activation_conv = 'relu'\n",
        "\n",
        "(X_train, Y_train, X_val, Y_val, X_test, Y_test) = get_image_data_1d(1000, imsize, prob_white)\n",
        "\n",
        "# Define the layers\n",
        "layer1 = keras.layers.Conv1D(filters=num_filters, kernel_size=kernel_size, strides=strides,\n",
        "                       use_bias=False, activation=activation_conv, padding='same',\n",
        "                       input_shape=(imsize, 1))\n",
        "\n",
        "activation_dense = 'linear'\n",
        "num_units = 1\n",
        "\n",
        "# Create the Dense layer with bias\n",
        "layer3 = Dense(units=num_units, activation=activation_dense, use_bias=True)  # Use bias term\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(layer1)\n",
        "model.add(Flatten())\n",
        "model.add(layer3)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mse', optimizer=Adam())\n",
        "\n",
        "# Set weights for Conv1D layer\n",
        "conv_weights = np.array([[1/2, 1/2]]).reshape(kernel_size, 1, num_filters)\n",
        "model.layers[0].set_weights([conv_weights])\n",
        "\n",
        "# Set weights and bias for Dense layer\n",
        "dense_weights = np.ones((imsize, num_units))  # Correct weights shape: (imsize, num_units)\n",
        "dense_bias = np.array([-10])  # Bias term\n",
        "\n",
        "# Set weights for the Dense layer\n",
        "model.layers[-1].set_weights([dense_weights, dense_bias])\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test, Y_test)\n",
        "print(f\"Test Loss: {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13nnDdCkM-_o",
        "outputId": "982b61df-c8ec-4284-a77b-d05e6a7ce4bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['.DS_Store']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# List files in the current directory\n",
        "os.listdir()\n",
        "\n",
        "# List files in the 'code_for_hw8' directory\n",
        "os.listdir('code_for_hw8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a_9tsVkgyMN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils, Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def run_keras_2d_vm(data_name, layers, epochs, display=True, split=0.25, verbose=True, trials=1):\n",
        "    \"\"\"\n",
        "    Run a Keras 2D model with specified architecture on a given dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - data_name: Name of the dataset (assumed to be a CSV file without extension)\n",
        "    - layers: List of Keras layers to use for the model\n",
        "    - epochs: Number of epochs for training\n",
        "    - display: Whether to display training/testing data plots\n",
        "    - split: Fraction of data to use for validation\n",
        "    - verbose: Verbosity of the training process\n",
        "    - trials: Number of trials to run\n",
        "    \"\"\"\n",
        "\n",
        "    print('Keras FC: dataset=', data_name)\n",
        "\n",
        "    # Helper function to load dataset\n",
        "    def get_data_set(file_path):\n",
        "        try:\n",
        "            data = pd.read_csv(file_path)\n",
        "            print(data.head())  # Check the first few rows to ensure data is loaded correctly\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading dataset: {e}\")\n",
        "            return None, None, 0\n",
        "\n",
        "        # Example preprocessing, adjust according to your actual data\n",
        "        X = data.iloc[:, :-1].values  # Features\n",
        "        y = data.iloc[:, -1].values   # Labels\n",
        "\n",
        "        # Ensure labels are integers\n",
        "        y = pd.factorize(y)[0]  # Converts labels to integer indices\n",
        "        num_classes = len(set(y))  # Number of unique classes\n",
        "\n",
        "        return X, y, num_classes\n",
        "\n",
        "    # Correct path to the dataset in Google Drive\n",
        "    file_path = f'/content/drive/My Drive/Colab Notebooks/code_for_hw8/code_for_hw8/data/{data_name}.csv'\n",
        "    if not os.path.isfile(file_path):\n",
        "        raise FileNotFoundError(f\"{file_path} not found\")\n",
        "\n",
        "    X_train, y, num_classes = get_data_set(file_path)\n",
        "    X_val, y2, _ = get_data_set(file_path)  # For demonstration; adjust as necessary\n",
        "    X_test, y3, _ = get_data_set(file_path)  # For demonstration; adjust as necessary\n",
        "\n",
        "    # Check if datasets are loaded properly\n",
        "    if X_train is None or y is None or X_val is None or (X_test is not None and y3 is None):\n",
        "        raise ValueError(\"One or more datasets are not loaded correctly. Please check your data loading functions.\")\n",
        "\n",
        "    print(f'Number of classes: {num_classes}')\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    y_train = utils.to_categorical(y, num_classes)\n",
        "    y_val = utils.to_categorical(y2, num_classes) if X_val is not None else None\n",
        "    y_test = utils.to_categorical(y3, num_classes) if X_test is not None else None\n",
        "\n",
        "    val_acc, test_acc = 0, 0\n",
        "    for trial in range(trials):\n",
        "        try:\n",
        "            # Build the model\n",
        "            model = Sequential(layers)\n",
        "            model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        except Exception as e:\n",
        "            print(f\"Error building the model: {e}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Train the model\n",
        "            history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, verbose=verbose, shuffle=True)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during model training: {e}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Evaluate the model\n",
        "            vacc, _ = model.evaluate(X_val, y_val, verbose=verbose) if X_val is not None else (0, 0)\n",
        "            tacc, _ = model.evaluate(X_test, y3, verbose=verbose) if X_test is not None else (0, 0)\n",
        "\n",
        "            val_acc += vacc\n",
        "            test_acc += tacc\n",
        "        except Exception as e:\n",
        "            print(f\"Error during model evaluation: {e}\")\n",
        "            continue\n",
        "\n",
        "        if display:\n",
        "            try:\n",
        "                # Plot classifier landscape on training data\n",
        "                plot_heat(X_train, y, model)\n",
        "                plt.title('Training data')\n",
        "                plt.show()\n",
        "\n",
        "                if X_test is not None:\n",
        "                    # Plot classifier landscape on testing data\n",
        "                    plot_heat(X_test, y3, model)\n",
        "                    plt.title('Testing data')\n",
        "                    plt.show()\n",
        "            except Exception as e:\n",
        "                print(f\"Error during plotting: {e}\")\n",
        "\n",
        "    print(f'Average validation accuracy: {val_acc / trials}')\n",
        "    print(f'Average test accuracy: {test_acc / trials}')\n",
        "\n",
        "def plot_heat(X, y, model):\n",
        "    \"\"\"\n",
        "    Placeholder for plot_heat function. Implement this function based on your needs.\n",
        "    \"\"\"\n",
        "    pass  # Replace with actual implementation\n",
        "\n",
        "# Example usage:\n",
        "# run_keras_2d_vm(\"data3class_train\", archs(3)[0], 10, split=0.5, display=False, verbose=False, trials=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhQ_trXVk_40"
      },
      "outputs": [],
      "source": [
        "'''import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "num_samples = 1000\n",
        "num_features = 5\n",
        "num_classes = 3\n",
        "\n",
        "# Generate random feature data\n",
        "np.random.seed(0)\n",
        "X = np.random.randn(num_samples, num_features)\n",
        "\n",
        "# Generate random class labels\n",
        "y = np.random.randint(0, num_classes, size=num_samples)\n",
        "\n",
        "# Create a DataFrame\n",
        "data = pd.DataFrame(X, columns=[f'feature_{i+1}' for i in range(num_features)])\n",
        "data['label'] = y\n",
        "\n",
        "# Save to CSV\n",
        "file_name = 'sample_data.csv'\n",
        "data.to_csv(file_name, index=False)\n",
        "\n",
        "print(f\"Sample data saved to {file_name}\")'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnHLrKo3rMWr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils, Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def archs_2(classes, input_dim):\n",
        "    return [\n",
        "        [tf.keras.layers.Dense(input_dim=input_dim, units=classes, activation=\"softmax\")],\n",
        "        [tf.keras.layers.Dense(input_dim=input_dim, units=10, activation='relu'),\n",
        "         tf.keras.layers.Dense(units=classes, activation=\"softmax\")],\n",
        "        [tf.keras.layers.Dense(input_dim=input_dim, units=100, activation='relu'),\n",
        "         tf.keras.layers.Dense(units=classes, activation=\"softmax\")],\n",
        "        [tf.keras.layers.Dense(input_dim=input_dim, units=10, activation='relu'),\n",
        "         tf.keras.layers.Dense(units=10, activation='relu'),\n",
        "         tf.keras.layers.Dense(units=classes, activation=\"softmax\")],\n",
        "        [tf.keras.layers.Dense(input_dim=input_dim, units=100, activation='relu'),\n",
        "         tf.keras.layers.Dense(units=100, activation='relu'),\n",
        "         tf.keras.layers.Dense(units=classes, activation=\"softmax\")]\n",
        "    ]\n",
        "\n",
        "def run_keras_2d_vm_4(data_name, layers, epochs, display=True, split=0.25, verbose=True, trials=1):\n",
        "    print('Keras FC: dataset=', data_name)\n",
        "\n",
        "    def get_data_set(file_path):\n",
        "        try:\n",
        "            data = pd.read_csv(file_path)\n",
        "            print(data.head())\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading dataset: {e}\")\n",
        "            return None, None, 0\n",
        "\n",
        "        X = data.iloc[:, :-1].values\n",
        "        y = data.iloc[:, -1].values\n",
        "\n",
        "        print(\"Sample labels (first 10):\", y[:10])\n",
        "\n",
        "        try:\n",
        "            y = pd.factorize(y)[0]\n",
        "        except Exception as e:\n",
        "            print(f\"Error converting labels to integers: {e}\")\n",
        "            return None, None, 0\n",
        "\n",
        "        num_classes = len(set(y))\n",
        "\n",
        "        return X, y, num_classes\n",
        "\n",
        "    file_path = f'/content/drive/My Drive/Colab Notebooks/code_for_hw8/code_for_hw8/data/{data_name}.csv'\n",
        "    if not os.path.isfile(file_path):\n",
        "        raise FileNotFoundError(f\"{file_path} not found\")\n",
        "\n",
        "    X_train, y, num_classes = get_data_set(file_path)\n",
        "    X_val, y2, _ = get_data_set(file_path)  # For demonstration; adjust as necessary\n",
        "    X_test, y3, _ = get_data_set(file_path)  # For demonstration; adjust as necessary\n",
        "\n",
        "    if X_train is None or y is None or X_val is None or (X_test is not None and y3 is None):\n",
        "        raise ValueError(\"One or more datasets are not loaded correctly. Please check your data loading functions.\")\n",
        "\n",
        "    print(f'Number of classes: {num_classes}')\n",
        "\n",
        "    try:\n",
        "        y_train = utils.to_categorical(y, num_classes)\n",
        "        y_val = utils.to_categorical(y2, num_classes) if X_val is not None else None\n",
        "        y_test = utils.to_categorical(y3, num_classes) if X_test is not None else None\n",
        "    except Exception as e:\n",
        "        print(f\"Error during one-hot encoding: {e}\")\n",
        "        return\n",
        "\n",
        "    val_acc, test_acc = 0, 0\n",
        "    for trial in range(trials):\n",
        "        try:\n",
        "            model = Sequential(layers)\n",
        "            model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        except Exception as e:\n",
        "            print(f\"Error building the model: {e}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, verbose=verbose, shuffle=True)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during model training: {e}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            vacc, _ = model.evaluate(X_val, y_val, verbose=verbose) if X_val is not None else (0, 0)\n",
        "            tacc, _ = model.evaluate(X_test, y3, verbose=verbose) if X_test is not None else (0, 0)\n",
        "\n",
        "            val_acc += vacc\n",
        "            test_acc += tacc\n",
        "        except Exception as e:\n",
        "            print(f\"Error during model evaluation: {e}\")\n",
        "            continue\n",
        "\n",
        "        if display:\n",
        "            try:\n",
        "                plot_heat(X_train, y, model)\n",
        "                plt.title('Training data')\n",
        "                plt.show()\n",
        "\n",
        "                if X_test is not None:\n",
        "                    plot_heat(X_test, y3, model)\n",
        "                    plt.title('Testing data')\n",
        "                    plt.show()\n",
        "            except Exception as e:\n",
        "                print(f\"Error during plotting: {e}\")\n",
        "\n",
        "    print(f'Average validation accuracy: {val_acc / trials}')\n",
        "    print(f'Average test accuracy: {test_acc / trials}')\n",
        "\n",
        "def plot_heat(X, y, model):\n",
        "    \"\"\"\n",
        "    Placeholder for plot_heat function. Implement this function based on your needs.\n",
        "    \"\"\"\n",
        "    pass  # Replace with actual implementation\n",
        "\n",
        "# Example usage:\n",
        "input_dim = 5  # Number of features in your data\n",
        "#run_keras_2d_vm_4(\"sample_data\", archs_2(3, input_dim)[0], 10, split=0.5, display=False, verbose=False, trials=5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMRI4V-HpP0b",
        "outputId": "6e952505-5810-4ecd-9134-7a076cd0dc36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keras FC: dataset= sample_data\n",
            "   feature_1  feature_2  feature_3  feature_4  feature_5  label\n",
            "0       0.45      -1.22       3.14       0.56      -0.34      0\n",
            "1       1.24       0.76       2.45      -1.23       0.78      1\n",
            "2      -0.34       0.56      -1.67       1.23      -0.89      2\n",
            "3       0.78       1.12       0.45      -0.56       1.45      1\n",
            "4      -1.12      -0.78       2.34       1.67      -0.45      0\n",
            "Sample labels (first 10): [0 1 2 1 0 2 2 0 1 2]\n",
            "   feature_1  feature_2  feature_3  feature_4  feature_5  label\n",
            "0       0.45      -1.22       3.14       0.56      -0.34      0\n",
            "1       1.24       0.76       2.45      -1.23       0.78      1\n",
            "2      -0.34       0.56      -1.67       1.23      -0.89      2\n",
            "3       0.78       1.12       0.45      -0.56       1.45      1\n",
            "4      -1.12      -0.78       2.34       1.67      -0.45      0\n",
            "Sample labels (first 10): [0 1 2 1 0 2 2 0 1 2]\n",
            "   feature_1  feature_2  feature_3  feature_4  feature_5  label\n",
            "0       0.45      -1.22       3.14       0.56      -0.34      0\n",
            "1       1.24       0.76       2.45      -1.23       0.78      1\n",
            "2      -0.34       0.56      -1.67       1.23      -0.89      2\n",
            "3       0.78       1.12       0.45      -0.56       1.45      1\n",
            "4      -1.12      -0.78       2.34       1.67      -0.45      0\n",
            "Sample labels (first 10): [0 1 2 1 0 2 2 0 1 2]\n",
            "Number of classes: 3\n",
            "Error during model evaluation: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1525, in test_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1514, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1507, in run_step  **\n",
            "        outputs = model.test_step(data)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1473, in test_step\n",
            "        self.compute_loss(x, y, y_pred, sample_weight)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 918, in compute_loss\n",
            "        return self.compiled_loss(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n",
            "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 141, in __call__\n",
            "        losses = call_fn(y_true, y_pred)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 245, in call  **\n",
            "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 1789, in categorical_crossentropy\n",
            "        return backend.categorical_crossentropy(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n",
            "        target.shape.assert_is_compatible_with(output.shape)\n",
            "\n",
            "    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
            "\n",
            "Error during model evaluation: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1525, in test_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1514, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1507, in run_step  **\n",
            "        outputs = model.test_step(data)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1473, in test_step\n",
            "        self.compute_loss(x, y, y_pred, sample_weight)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 918, in compute_loss\n",
            "        return self.compiled_loss(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n",
            "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 141, in __call__\n",
            "        losses = call_fn(y_true, y_pred)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 245, in call  **\n",
            "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 1789, in categorical_crossentropy\n",
            "        return backend.categorical_crossentropy(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n",
            "        target.shape.assert_is_compatible_with(output.shape)\n",
            "\n",
            "    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
            "\n",
            "Error during model evaluation: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1525, in test_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1514, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1507, in run_step  **\n",
            "        outputs = model.test_step(data)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1473, in test_step\n",
            "        self.compute_loss(x, y, y_pred, sample_weight)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 918, in compute_loss\n",
            "        return self.compiled_loss(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n",
            "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 141, in __call__\n",
            "        losses = call_fn(y_true, y_pred)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 245, in call  **\n",
            "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 1789, in categorical_crossentropy\n",
            "        return backend.categorical_crossentropy(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n",
            "        target.shape.assert_is_compatible_with(output.shape)\n",
            "\n",
            "    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
            "\n",
            "Error during model evaluation: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1525, in test_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1514, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1507, in run_step  **\n",
            "        outputs = model.test_step(data)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1473, in test_step\n",
            "        self.compute_loss(x, y, y_pred, sample_weight)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 918, in compute_loss\n",
            "        return self.compiled_loss(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n",
            "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 141, in __call__\n",
            "        losses = call_fn(y_true, y_pred)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 245, in call  **\n",
            "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 1789, in categorical_crossentropy\n",
            "        return backend.categorical_crossentropy(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n",
            "        target.shape.assert_is_compatible_with(output.shape)\n",
            "\n",
            "    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
            "\n",
            "Error during model evaluation: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1525, in test_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1514, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1507, in run_step  **\n",
            "        outputs = model.test_step(data)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1473, in test_step\n",
            "        self.compute_loss(x, y, y_pred, sample_weight)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 918, in compute_loss\n",
            "        return self.compiled_loss(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n",
            "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 141, in __call__\n",
            "        losses = call_fn(y_true, y_pred)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 245, in call  **\n",
            "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 1789, in categorical_crossentropy\n",
            "        return backend.categorical_crossentropy(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n",
            "        target.shape.assert_is_compatible_with(output.shape)\n",
            "\n",
            "    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
            "\n",
            "Average validation accuracy: 0.0\n",
            "Average test accuracy: 0.0\n"
          ]
        }
      ],
      "source": [
        "run_keras_2d_vm_4(\"sample_data\", archs_2(3,input_dim)[0], 10, split=0.5, display=False, verbose=False, trials=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKuSHIZfpUbC",
        "outputId": "a1c2213e-2462-4161-8145-69a8befe8b33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keras FC: dataset= sample_data\n",
            "   feature_1  feature_2  feature_3  feature_4  feature_5  label\n",
            "0       0.45      -1.22       3.14       0.56      -0.34      0\n",
            "1       1.24       0.76       2.45      -1.23       0.78      1\n",
            "2      -0.34       0.56      -1.67       1.23      -0.89      2\n",
            "3       0.78       1.12       0.45      -0.56       1.45      1\n",
            "4      -1.12      -0.78       2.34       1.67      -0.45      0\n",
            "   feature_1  feature_2  feature_3  feature_4  feature_5  label\n",
            "0       0.45      -1.22       3.14       0.56      -0.34      0\n",
            "1       1.24       0.76       2.45      -1.23       0.78      1\n",
            "2      -0.34       0.56      -1.67       1.23      -0.89      2\n",
            "3       0.78       1.12       0.45      -0.56       1.45      1\n",
            "4      -1.12      -0.78       2.34       1.67      -0.45      0\n",
            "   feature_1  feature_2  feature_3  feature_4  feature_5  label\n",
            "0       0.45      -1.22       3.14       0.56      -0.34      0\n",
            "1       1.24       0.76       2.45      -1.23       0.78      1\n",
            "2      -0.34       0.56      -1.67       1.23      -0.89      2\n",
            "3       0.78       1.12       0.45      -0.56       1.45      1\n",
            "4      -1.12      -0.78       2.34       1.67      -0.45      0\n",
            "Number of classes: 3\n",
            "Error during model evaluation: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1525, in test_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1514, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1507, in run_step  **\n",
            "        outputs = model.test_step(data)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1473, in test_step\n",
            "        self.compute_loss(x, y, y_pred, sample_weight)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 918, in compute_loss\n",
            "        return self.compiled_loss(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n",
            "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 141, in __call__\n",
            "        losses = call_fn(y_true, y_pred)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 245, in call  **\n",
            "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 1789, in categorical_crossentropy\n",
            "        return backend.categorical_crossentropy(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n",
            "        target.shape.assert_is_compatible_with(output.shape)\n",
            "\n",
            "    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
            "\n",
            "Error during model evaluation: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1525, in test_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1514, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1507, in run_step  **\n",
            "        outputs = model.test_step(data)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1473, in test_step\n",
            "        self.compute_loss(x, y, y_pred, sample_weight)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 918, in compute_loss\n",
            "        return self.compiled_loss(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n",
            "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 141, in __call__\n",
            "        losses = call_fn(y_true, y_pred)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 245, in call  **\n",
            "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 1789, in categorical_crossentropy\n",
            "        return backend.categorical_crossentropy(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n",
            "        target.shape.assert_is_compatible_with(output.shape)\n",
            "\n",
            "    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
            "\n",
            "Error during model evaluation: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1525, in test_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1514, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1507, in run_step  **\n",
            "        outputs = model.test_step(data)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1473, in test_step\n",
            "        self.compute_loss(x, y, y_pred, sample_weight)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 918, in compute_loss\n",
            "        return self.compiled_loss(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n",
            "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 141, in __call__\n",
            "        losses = call_fn(y_true, y_pred)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 245, in call  **\n",
            "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 1789, in categorical_crossentropy\n",
            "        return backend.categorical_crossentropy(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n",
            "        target.shape.assert_is_compatible_with(output.shape)\n",
            "\n",
            "    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
            "\n",
            "Error during model evaluation: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1525, in test_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1514, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1507, in run_step  **\n",
            "        outputs = model.test_step(data)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1473, in test_step\n",
            "        self.compute_loss(x, y, y_pred, sample_weight)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 918, in compute_loss\n",
            "        return self.compiled_loss(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n",
            "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 141, in __call__\n",
            "        losses = call_fn(y_true, y_pred)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 245, in call  **\n",
            "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 1789, in categorical_crossentropy\n",
            "        return backend.categorical_crossentropy(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n",
            "        target.shape.assert_is_compatible_with(output.shape)\n",
            "\n",
            "    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
            "\n",
            "Error during model evaluation: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1525, in test_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1514, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1507, in run_step  **\n",
            "        outputs = model.test_step(data)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1473, in test_step\n",
            "        self.compute_loss(x, y, y_pred, sample_weight)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 918, in compute_loss\n",
            "        return self.compiled_loss(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n",
            "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 141, in __call__\n",
            "        losses = call_fn(y_true, y_pred)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 245, in call  **\n",
            "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 1789, in categorical_crossentropy\n",
            "        return backend.categorical_crossentropy(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n",
            "        target.shape.assert_is_compatible_with(output.shape)\n",
            "\n",
            "    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
            "\n",
            "Average validation accuracy: 0.0\n",
            "Average test accuracy: 0.0\n"
          ]
        }
      ],
      "source": [
        "run_keras_2d_vm(\"sample_data\", archs_2(3,input_dim)[0], 10, split=0.5, display=False, verbose=False, trials=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GCLr8qmj-Hk"
      },
      "source": [
        "<b>4D)</b> Averaging type filters are abundant and form a nearly flat valley of local minima for this problem. It is difficult for the network to find alternative solutions on its own. We need to force our way out of these bad minima and towards a better solution, i.e., an edge detector. To force the first layer to behave as an edge detector, we need to choose a proper **kernel regularizer**. Consider the following functions\n",
        "\n",
        "$f_1=\\sum_i |w_i|$, $f_2=\\sum_i |w_i^2|$, $f_3=|\\sum_{i} w_i|$. Which one of the choices is likely to guide the network to find an edge detector at the convolution layer?\n",
        "\n",
        "\n",
        "<a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week8/week8_homework/\">Refer to Catsoop.</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aubU6Q6kwOI"
      },
      "source": [
        "Implement your choice of regularizers from above in the code (complete the function `filter_reg`). Do not allow any bias in the layers for the rest of the problem. The code generates some random test and training data sets and trains the model on these data. Run a few learning trials (5 or more) for each data set and answer the following questions based on the performance of your model.\n",
        "\n",
        "**IMPORTANT**: When implementing `filter_reg`, you should use the keras backend operations, imported as \"K\" in the code. So for example, `K.sum` and `K.abs`, rather than `np.sum` and `np.abs`. This is because the `weights` argument is NOT a numpy object, but rather an internal Keras object!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOLZf_JsuTLn"
      },
      "outputs": [],
      "source": [
        "# Implement filter_reg\n",
        "\n",
        "def filter_reg(weights):\n",
        "    # We scale the output of the filter by lam\n",
        "    lam=1000\n",
        "    filter_result = torch.abs(torch.sum(weights))  # Your code\n",
        "    return lam * filter_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYRwd0eJkAdh"
      },
      "source": [
        "<b>4E)</b> For $1024\\times 1$ images and training set of size $1000$, is the network **without any regularization** likely to find models that have a mean square error lower than 8 on the test data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KiCbZmksXO6",
        "outputId": "21c96e5c-b23e-46f7-9d80-0fff39acc158"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_2 (Conv1D)           (1, 1024, 1)              2         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (1, 1024)                 0         \n",
            "                                                                 \n",
            " dense_72 (Dense)            (1, 1)                    1024      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,026\n",
            "Trainable params: 1,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 8692.3662 - val_loss: 8818.2598\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 8692.3662 - val_loss: 8818.2598\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 8692.3662 - val_loss: 8818.2598\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8692.3662 - val_loss: 8818.2598\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8692.3662 - val_loss: 8818.2598\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8692.3662 - val_loss: 8818.2598\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8692.3662 - val_loss: 8818.2598\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 8692.3662 - val_loss: 8818.2598\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 8692.3662 - val_loss: 8818.2598\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8692.3662 - val_loss: 8818.2598\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 8699.7090\n",
            "8699.708984375\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_3 (Conv1D)           (1, 1024, 1)              2         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (1, 1024)                 0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (1, 1)                    1024      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,026\n",
            "Trainable params: 1,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 3196.8752 - val_loss: 21.3121\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 10.4610 - val_loss: 10.7455\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.4833 - val_loss: 10.3127\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 8.7111 - val_loss: 10.7739\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 7.7343 - val_loss: 11.0533\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 7.0093 - val_loss: 10.9227\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 6.3543 - val_loss: 12.6675\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 5.7295 - val_loss: 12.8858\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 5.2878 - val_loss: 12.8525\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 4.9324 - val_loss: 13.5826\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 13.8675\n",
            "13.86751651763916\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_4 (Conv1D)           (1, 1024, 1)              2         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (1, 1024)                 0         \n",
            "                                                                 \n",
            " dense_74 (Dense)            (1, 1)                    1024      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,026\n",
            "Trainable params: 1,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 3456.5681 - val_loss: 40.7965\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 11.9203 - val_loss: 11.6875\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.8974 - val_loss: 13.4043\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 9.0165 - val_loss: 11.2424\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 7.9529 - val_loss: 11.4639\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 6.9920 - val_loss: 11.7690\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 6.1496 - val_loss: 13.0409\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 5.4686 - val_loss: 14.0105\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 4.9799 - val_loss: 13.5125\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 4.4435 - val_loss: 14.3919\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 14.4554\n",
            "14.455378532409668\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_5 (Conv1D)           (1, 1024, 1)              2         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (1, 1024)                 0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (1, 1)                    1024      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,026\n",
            "Trainable params: 1,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3675.4109 - val_loss: 58.3648\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 13.4653 - val_loss: 11.9222\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 10.0344 - val_loss: 11.4723\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.0846 - val_loss: 12.0743\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8.0464 - val_loss: 11.5938\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 6.9804 - val_loss: 12.1697\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 6.1284 - val_loss: 13.0162\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 5.4036 - val_loss: 13.7377\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 4.8831 - val_loss: 14.5115\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 4.5250 - val_loss: 15.0659\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 14.9044\n",
            "14.904353141784668\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_6 (Conv1D)           (1, 1024, 1)              2         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (1, 1024)                 0         \n",
            "                                                                 \n",
            " dense_76 (Dense)            (1, 1)                    1024      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,026\n",
            "Trainable params: 1,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 3451.8792 - val_loss: 39.3313\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 12.3911 - val_loss: 10.9082\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 10.3265 - val_loss: 11.8943\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 9.1728 - val_loss: 12.2252\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 8.0642 - val_loss: 13.8065\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 7.0539 - val_loss: 11.6013\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 6.1508 - val_loss: 12.8882\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 5.4308 - val_loss: 12.9815\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 4.9276 - val_loss: 14.0339\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 4.5508 - val_loss: 14.7044\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 14.8265\n",
            "14.826534271240234\n"
          ]
        }
      ],
      "source": [
        "# Code template if you would like to check 4B) through code\n",
        "\n",
        "imsize = 1024\n",
        "prob_white = 0.1\n",
        "\n",
        "data=get_image_data_1d(1000, imsize, prob_white)\n",
        "trials=5\n",
        "for trial in range(trials):\n",
        "\n",
        "    num_filters = 1  # Your code\n",
        "    kernel_size = 2  # Your code\n",
        "    strides = 1  # Your code\n",
        "    activation_conv = 'relu'  # Your code\n",
        "\n",
        "    layer1=keras.layers.Conv1D(filters=num_filters, kernel_size=kernel_size, \\\n",
        "    strides=strides, use_bias=False, activation=activation_conv, batch_size=1, \\\n",
        "    input_shape=(imsize,1),padding='same')\n",
        "\n",
        "    activation_dense = 'relu'  # Your code\n",
        "    num_units = 1  # Your code\n",
        "\n",
        "    layer3=Dense(units=num_units, activation=activation_dense, use_bias=False)\n",
        "\n",
        "    layers=[layer1,Flatten(),layer3]\n",
        "    model,err = train_neural_counter(layers, data, 'mse')\n",
        "\n",
        "    model.layers[0].get_weights()[0]\n",
        "    np.mean(model.layers[-1].get_weights()[0])\n",
        "    print(err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1vcUEL-vW9D"
      },
      "source": [
        "#### For parts F) to J), simply edit your code from E) with the necessary changes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_25ygQJkD5F"
      },
      "source": [
        "<b>4F)</b> Repeat the same experiment, but now with the regularizer you implemented. Try different regularization parameters. Which choice of regularization parameter gives the best prediction results?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nlp7bq_Ev_7F",
        "outputId": "d34ea5b1-ff55-4e0a-c21d-d5f0dbcd90af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 0.3389\n",
            "Epoch 2/5, Loss: 0.3389\n",
            "Epoch 3/5, Loss: 0.3389\n",
            "Epoch 4/5, Loss: 0.3389\n",
            "Epoch 5/5, Loss: 0.3389\n",
            "Regularization Lambda: 0\n",
            "Conv1D weights: tensor([[[-0.6315, -0.4034]]])\n",
            "Linear layer mean weight: tensor(0.0007)\n",
            "Final Error: 0.3388986737728119\n",
            "Epoch 1/5, Loss: 0.1182\n",
            "Epoch 2/5, Loss: 0.0899\n",
            "Epoch 3/5, Loss: 0.0860\n",
            "Epoch 4/5, Loss: 0.0823\n",
            "Epoch 5/5, Loss: 0.0777\n",
            "Regularization Lambda: 0\n",
            "Conv1D weights: tensor([[[-0.1874,  0.5242]]])\n",
            "Linear layer mean weight: tensor(0.0027)\n",
            "Final Error: 0.07773373103141784\n",
            "Epoch 1/5, Loss: 0.3389\n",
            "Epoch 2/5, Loss: 0.3389\n",
            "Epoch 3/5, Loss: 0.3389\n",
            "Epoch 4/5, Loss: 0.3389\n",
            "Epoch 5/5, Loss: 0.3389\n",
            "Regularization Lambda: 0\n",
            "Conv1D weights: tensor([[[-0.1444, -0.3212]]])\n",
            "Linear layer mean weight: tensor(-0.0007)\n",
            "Final Error: 0.3388986716270447\n",
            "Epoch 1/5, Loss: 0.2442\n",
            "Epoch 2/5, Loss: 0.1129\n",
            "Epoch 3/5, Loss: 0.0902\n",
            "Epoch 4/5, Loss: 0.0862\n",
            "Epoch 5/5, Loss: 0.0837\n",
            "Regularization Lambda: 1\n",
            "Conv1D weights: tensor([[[-0.1678,  0.1673]]])\n",
            "Linear layer mean weight: tensor(0.0175)\n",
            "Final Error: 0.08367660802602768\n",
            "Epoch 1/5, Loss: 0.9265\n",
            "Epoch 2/5, Loss: 0.8220\n",
            "Epoch 3/5, Loss: 0.7577\n",
            "Epoch 4/5, Loss: 0.6951\n",
            "Epoch 5/5, Loss: 0.6335\n",
            "Regularization Lambda: 1\n",
            "Conv1D weights: tensor([[[0.0497, 0.4583]]])\n",
            "Linear layer mean weight: tensor(0.0019)\n",
            "Final Error: 0.6334951882362365\n",
            "Epoch 1/5, Loss: 0.2582\n",
            "Epoch 2/5, Loss: 0.1688\n",
            "Epoch 3/5, Loss: 0.1050\n",
            "Epoch 4/5, Loss: 0.0818\n",
            "Epoch 5/5, Loss: 0.0742\n",
            "Regularization Lambda: 1\n",
            "Conv1D weights: tensor([[[-0.4192,  0.4193]]])\n",
            "Linear layer mean weight: tensor(0.0066)\n",
            "Final Error: 0.07421028184890748\n",
            "Epoch 1/5, Loss: 5.3889\n",
            "Epoch 2/5, Loss: 4.6020\n",
            "Epoch 3/5, Loss: 3.9500\n",
            "Epoch 4/5, Loss: 3.3428\n",
            "Epoch 5/5, Loss: 2.7140\n",
            "Regularization Lambda: 10\n",
            "Conv1D weights: tensor([[[-0.5172,  0.2870]]])\n",
            "Linear layer mean weight: tensor(0.0191)\n",
            "Final Error: 2.714003574371338\n",
            "Epoch 1/5, Loss: 6.7524\n",
            "Epoch 2/5, Loss: 6.0819\n",
            "Epoch 3/5, Loss: 5.3273\n",
            "Epoch 4/5, Loss: 4.5560\n",
            "Epoch 5/5, Loss: 3.9646\n",
            "Regularization Lambda: 10\n",
            "Conv1D weights: tensor([[[-0.5229,  0.1660]]])\n",
            "Linear layer mean weight: tensor(0.0683)\n",
            "Final Error: 3.9646146144866945\n",
            "Epoch 1/5, Loss: 0.1384\n",
            "Epoch 2/5, Loss: 0.0914\n",
            "Epoch 3/5, Loss: 0.0849\n",
            "Epoch 4/5, Loss: 0.0802\n",
            "Epoch 5/5, Loss: 0.0749\n",
            "Regularization Lambda: 10\n",
            "Conv1D weights: tensor([[[ 0.5286, -0.5286]]])\n",
            "Linear layer mean weight: tensor(0.0058)\n",
            "Final Error: 0.07492884463071824\n",
            "Epoch 1/5, Loss: 559.2495\n",
            "Epoch 2/5, Loss: 495.2499\n",
            "Epoch 3/5, Loss: 431.2502\n",
            "Epoch 4/5, Loss: 367.2506\n",
            "Epoch 5/5, Loss: 303.2509\n",
            "Regularization Lambda: 1000\n",
            "Conv1D weights: tensor([[[-0.0339, -0.2353]]])\n",
            "Linear layer mean weight: tensor(0.0009)\n",
            "Final Error: 303.25092724609374\n",
            "Epoch 1/5, Loss: 71.8007\n",
            "Epoch 2/5, Loss: 13.5706\n",
            "Epoch 3/5, Loss: 0.8347\n",
            "Epoch 4/5, Loss: 0.3774\n",
            "Epoch 5/5, Loss: 0.3727\n",
            "Regularization Lambda: 1000\n",
            "Conv1D weights: tensor([[[ 0.5689, -0.5686]]])\n",
            "Linear layer mean weight: tensor(0.0052)\n",
            "Final Error: 0.37274508142471313\n",
            "Epoch 1/5, Loss: 947.8770\n",
            "Epoch 2/5, Loss: 883.8778\n",
            "Epoch 3/5, Loss: 819.8786\n",
            "Epoch 4/5, Loss: 755.8794\n",
            "Epoch 5/5, Loss: 691.8803\n",
            "Regularization Lambda: 1000\n",
            "Conv1D weights: tensor([[[-0.2742, -0.3836]]])\n",
            "Linear layer mean weight: tensor(-0.0007)\n",
            "Final Error: 691.8802592773437\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "# Example function placeholder for get_image_data_1d\n",
        "def get_image_data_1d(num_samples, imsize, prob_white):\n",
        "    # Generate synthetic data; replace with actual function\n",
        "    X = torch.rand(num_samples, 1, imsize)  # (num_samples, channels, imsize)\n",
        "    Y = torch.rand(num_samples, 1)  # (num_samples, output_dim)\n",
        "    return X, Y\n",
        "\n",
        "# Custom regularizer function\n",
        "def filter_reg(weights, lam):\n",
        "    # Compute the L1 norm of the weights (or another custom regularization)\n",
        "    filter_result = torch.abs(torch.sum(weights))\n",
        "    return lam * filter_result\n",
        "\n",
        "def train_neural_counter(layers, data, lambda_reg=0):\n",
        "    # Create dataset and dataloader\n",
        "    X_train, Y_train = data\n",
        "    dataset = TensorDataset(X_train, Y_train)\n",
        "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    # Define model\n",
        "    model = nn.Sequential(*layers)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    # Training loop\n",
        "    num_epochs = 5\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Add regularization loss\n",
        "            if lambda_reg > 0:\n",
        "                reg_loss = filter_reg(model[0].weight, lam=lambda_reg)\n",
        "                loss += reg_loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloader.dataset)\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    return model, epoch_loss\n",
        "\n",
        "def run_nn(lambda_reg=0):\n",
        "    imsize = 1024\n",
        "    prob_white = 0.1\n",
        "\n",
        "    # Load data\n",
        "    data = get_image_data_1d(1000, imsize, prob_white)\n",
        "\n",
        "    # Trials\n",
        "    for trial in range(3):\n",
        "        num_filters = 1\n",
        "        kernel_size = 2\n",
        "        strides = 1\n",
        "        padding = 1\n",
        "\n",
        "        # Define layers\n",
        "        layer_1 = nn.Conv1d(in_channels=1, out_channels=num_filters, kernel_size=kernel_size, stride=strides, padding=padding, bias=False)\n",
        "        num_units = imsize + 1\n",
        "        layer_3 = nn.Linear(num_units, 1, bias=False)\n",
        "        layers = [layer_1, nn.ReLU(), nn.Flatten(), layer_3]\n",
        "\n",
        "        # Train the model\n",
        "        model, err = train_neural_counter(layers, data, lambda_reg)\n",
        "        print(f\"Regularization Lambda: {lambda_reg}\")\n",
        "        print(\"Conv1D weights:\", model[0].weight.data)\n",
        "        print(\"Linear layer mean weight:\", torch.mean(model[-1].weight.data))\n",
        "        print(\"Final Error:\", err)\n",
        "\n",
        "# Run with different lambda values\n",
        "for lam in [0, 1, 10, 1000]:\n",
        "    run_nn(lambda_reg=lam)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs44ze96kHZZ"
      },
      "source": [
        "<b>4G)</b> With the above choice of regularization parameter, what is the mean square error of the best network that you find on the test data? Try a few trials (5 or more) for each data test and report the value of the best network.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAN0k9wylOmz"
      },
      "source": [
        "\n",
        "#### We expect the training to be easier when there are fewer parameters to learn. Consider images of size $128\\times 1$ for the rest of the problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnktFwXRkKNF"
      },
      "source": [
        "<b>4H)</b> Instead of resorting to regularization again, we may instead find a way to reduce the number of parameters. What additional layer can you add to the output of the convolution layer to reduce the number of parameters to be learned without losing any relevant information?\n",
        "\n",
        "<a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week8/week8_homework/\">Refer to Catsoop.</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXgOqKtRkNRP"
      },
      "source": [
        "<b>4I)</b> Add the layer you suggested above to your network and run some tests with data sets of size 1000 on $128\\times 1$ images.  How many parameters are left to learn with the new structure?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8FRQawHkPG9"
      },
      "source": [
        "<b>4J)</b> Mark your observations on the two structures (not using regularization).\n",
        "<a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week8/week8_homework/\">Refer to Catsoop.</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-iTDCrHySde"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQGlJLxI__4A"
      },
      "source": [
        "# 5) MNIST (Digit Classification)\n",
        "\n",
        "In this section, we'll be looking at the MNIST data set seen already in problem 2. This time, we look at the *complete* MNIST problem where our networks will take an image of *any* digit from $0-9$ as input (recall that problem 2 only looked at digits $0$ and $1$) and try to predict that digit. Also, we will now use out-of-the-box neural network implementations using Keras and Tensorflow. State-of-the-art systems have error rates of less that one half of one percent on this data set (see <a href=\"http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354\">this list</a>).  We'll be happy with an error rate less than 2% since we don't have all year...\n",
        "<br>\n",
        "\n",
        "You can access the MNIST data for this problem using:\n",
        "<br><code>train, validation = get_MNIST_data()</code>\n",
        "<br>\n",
        "\n",
        "You can run the fully connected MNIST model, using:\n",
        "<br><code>run_keras_fc_mnist(train, validation, layers, epochs, split=0.1, trials=5)</code>\n",
        "<br>\n",
        "\n",
        "And, you can run the CNN MNIST test, using:\n",
        "<br><code>run_keras_cnn_mnist(train, validation, layers, epochs, split=0.1, trials=5)</code>\n",
        "<br>\n",
        "\n",
        "For all following experiments, please run for 5 trials (use `trials=5`) and report the average accuracy.\n",
        "<br>\n",
        "\n",
        "A word of warning, if you have a machine with a single core and/or very little RAM, you'll be better off running on an Athena workstation. If your solutions are not being accepted, and you are confident in your approach, try with more trials. Also,\n",
        "<br>\n",
        "\n",
        "You will need to design your own `layers` to feed to `run_keras_fc_mnist` and `run_keras_cnn_mnist`, which will be different than the ones specified by `archs()`. For instance, `layers=[Dense(input_dim=64, units=4, activation=\"softmax\")]` defines a single layer with 64 inputs, 4 output units, and softmax activation. Also, we advise you to use the option `verbose=True` when unsure about the progress made during training of your models.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx1jt6P9AUk1"
      },
      "source": [
        "<b> 5A)</b> Look at the code and indicate what the difference is between <code>run_keras_fc_mnist</code> and <code>run_keras_cnn_mnist</code>? <a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week8/week8_homework/\">Refer to the HW8 page.</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUp8QRtp-ZL_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#session = tf.compat.v1.keras.backend.set_session()\n",
        "#K.get_session()\n",
        "session = tf.compat.v1.keras.backend.get_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcFXbz1EBEJp",
        "outputId": "dc2c8301-0fd1-424f-85e6-06131df81648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 10.2282 - accuracy: 0.8362 - val_loss: 6.1896 - val_accuracy: 0.8818\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 6.1259 - accuracy: 0.8784 - val_loss: 6.2066 - val_accuracy: 0.8877\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 5.7139 - accuracy: 0.8832 - val_loss: 6.6732 - val_accuracy: 0.8782\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.4853 - accuracy: 0.8845 - val_loss: 5.8082 - val_accuracy: 0.8911\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 5.4431 - accuracy: 0.8857 - val_loss: 7.2532 - val_accuracy: 0.8659\n",
            "\n",
            "Avg. validation accuracy: 0.8809399962425232\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils, layers, models\n",
        "\n",
        "def run_keras_fc_mnist(train, test, layers_list, epochs, split=0.1, verbose=True, trials=1):\n",
        "    '''\n",
        "    train, test = input data\n",
        "    layers_list = list of Keras layers, e.g. [Dense(32, input_dim=784), Dense(10)]\n",
        "    epochs = number of epochs to run the model for each trial\n",
        "    trials = number of evaluation trials, resetting weights before each trial\n",
        "    '''\n",
        "    (X_train, y_train), (X_val, y_val) = train, test\n",
        "    # Flatten the images\n",
        "    m = X_train.shape[1]\n",
        "    X_train = X_train.reshape((X_train.shape[0], m * m))\n",
        "    X_val = X_val.reshape((X_val.shape[0], m * m))\n",
        "\n",
        "    # Categorize the labels\n",
        "    num_classes = 10\n",
        "    y_train = utils.to_categorical(y_train, num_classes)\n",
        "    y_val = utils.to_categorical(y_val, num_classes)\n",
        "\n",
        "    def create_model(layers_list):\n",
        "        model = models.Sequential()\n",
        "        for layer in layers_list:\n",
        "            model.add(layer)\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    val_acc, test_acc = 0, 0\n",
        "    for trial in range(trials):\n",
        "        # Create a new model instance for each trial\n",
        "        model = create_model(layers_list)\n",
        "        history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val), verbose=verbose)\n",
        "\n",
        "        # Evaluate the model\n",
        "        vacc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
        "        val_acc += vacc\n",
        "\n",
        "        # Optionally, evaluate on a test set if you have one\n",
        "        if 'X_test' in globals() and 'y_test' in globals():\n",
        "            tacc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
        "            test_acc += tacc\n",
        "\n",
        "    if trials > 0:\n",
        "        print(f\"\\nAvg. validation accuracy: {val_acc / trials}\")\n",
        "        if 'X_test' in globals() and 'y_test' in globals():\n",
        "            print(f\"\\nAvg. test accuracy: {test_acc / trials}\")\n",
        "\n",
        "# Example usage:\n",
        "layers_list = [layers.Dense(units=10, activation='softmax', input_dim=784)]  # Adjust input_dim as needed\n",
        "train, validation = get_MNIST_data()\n",
        "run_keras_fc_mnist(train, validation, layers_list, 1, split=0.1, verbose=True, trials=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5moSfb7CcXd",
        "outputId": "fa98f9d2-4feb-4a83-9ef6-d2ac4837a68a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 0.2457 - accuracy: 0.9467 - val_loss: 0.0586 - val_accuracy: 0.9814\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0633 - accuracy: 0.9812 - val_loss: 0.0602 - val_accuracy: 0.9823\n",
            "\n",
            "Avg. validation accuracy: 0.9823\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils, layers, models\n",
        "\n",
        "def create_cnn_model():\n",
        "    \"\"\"Creates and compiles a CNN model for MNIST.\"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Reshape(target_shape=(28, 28, 1), input_shape=(28, 28, 1)),  # Ensure input shape matches MNIST\n",
        "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def run_keras_cnn_mnist(train, test, epochs, split=0.1, verbose=True, trials=1):\n",
        "    '''\n",
        "    train, test = input data\n",
        "    epochs = number of epochs to run the model for each trial\n",
        "    split = validation split ratio (not used directly in this function)\n",
        "    trials = number of evaluation trials, resetting weights before each trial\n",
        "    '''\n",
        "    (X_train, y_train), (X_val, y_val) = train, test\n",
        "    # Reshape the images for CNN\n",
        "    X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "    X_val = X_val.reshape((X_val.shape[0], 28, 28, 1))\n",
        "\n",
        "    # Categorize the labels\n",
        "    num_classes = 10\n",
        "    y_train = utils.to_categorical(y_train, num_classes)\n",
        "    y_val = utils.to_categorical(y_val, num_classes)\n",
        "\n",
        "    val_acc, test_acc = 0, 0\n",
        "    for trial in range(trials):\n",
        "        # Create a new model instance for each trial\n",
        "        model = create_cnn_model()\n",
        "\n",
        "        # Train the model\n",
        "        history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val), verbose=verbose)\n",
        "\n",
        "        # Evaluate the model\n",
        "        vacc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
        "        val_acc += vacc\n",
        "\n",
        "        # Optionally, evaluate on a test set if provided\n",
        "        if 'X_test' in globals() and 'y_test' in globals():\n",
        "            tacc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
        "            test_acc += tacc\n",
        "\n",
        "    if trials > 0:\n",
        "        print(f\"\\nAvg. validation accuracy: {val_acc / trials:.4f}\")\n",
        "        if 'X_test' in globals() and 'y_test' in globals():\n",
        "            print(f\"\\nAvg. test accuracy: {test_acc / trials:.4f}\")\n",
        "\n",
        "# Example usage:\n",
        "# Make sure the function get_MNIST_data() returns data in the format: ((X_train, y_train), (X_val, y_val))\n",
        "train, validation = get_MNIST_data()\n",
        "run_keras_cnn_mnist(train, validation, epochs=2, split=0.1, verbose=True, trials=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sGfqAbICbmE"
      },
      "source": [
        "<b> 5B)</b> Using one epoch of training, what is the accuracy of a network **with no hidden units** (using the <code>run_keras_fc_mnist</code> method) on this data? Hint: this is expected to be terrible. If it's still not working, run for more trials. Remember to use 10 output units (the network predicts a digit from 0-9) and softmax activation!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gndf-ASDEe_"
      },
      "source": [
        "<b> 5C)</b> When creating the keras layer, pass in the following argument to Dense:\n",
        "<code>kernel_initializer=VarianceScaling(scale=0.001, mode='fan_in', distribution='normal', seed=None)</code> and repeat the test.  What is the accuracy now?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-YpIMe3tnE_",
        "outputId": "ee3f541d-4483-4812-f7c4-d7948bf74c8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2765 - accuracy: 0.7818 - val_loss: 0.6360 - val_accuracy: 0.8551\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5431 - accuracy: 0.8768 - val_loss: 0.3784 - val_accuracy: 0.9054\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3789 - accuracy: 0.9091 - val_loss: 0.3166 - val_accuracy: 0.9245\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3181 - accuracy: 0.9235 - val_loss: 0.2898 - val_accuracy: 0.9263\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2857 - accuracy: 0.9298 - val_loss: 0.2950 - val_accuracy: 0.9232\n",
            "\n",
            "Avg. validation accuracy: 0.9069\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils, layers, models\n",
        "\n",
        "def run_keras_fc_mnist(train, test, layers_list, epochs, split=0.1, verbose=True, trials=1):\n",
        "    '''\n",
        "    train, test = input data\n",
        "    layers_list = list of Keras layers, e.g. [Dense(32, input_shape=(784,)), Dense(10)]\n",
        "    epochs = number of epochs to run the model for each trial\n",
        "    trials = number of evaluation trials, resetting weights before each trial\n",
        "    '''\n",
        "    (X_train, y_train), (X_val, y_val) = train, test\n",
        "    # Flatten the images\n",
        "    m = X_train.shape[1]\n",
        "    X_train = X_train.reshape((X_train.shape[0], m * m))\n",
        "    X_val = X_val.reshape((X_val.shape[0], m * m))\n",
        "\n",
        "    # Categorize the labels\n",
        "    num_classes = 10\n",
        "    y_train = utils.to_categorical(y_train, num_classes)\n",
        "    y_val = utils.to_categorical(y_val, num_classes)\n",
        "\n",
        "    def create_model(layers_list):\n",
        "        model = models.Sequential()\n",
        "        for layer in layers_list:\n",
        "            model.add(layer)\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    val_acc, test_acc = 0, 0\n",
        "    for trial in range(trials):\n",
        "        # Create a new model instance for each trial\n",
        "        model = create_model(layers_list)\n",
        "        history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val), verbose=verbose)\n",
        "\n",
        "        # Evaluate the model\n",
        "        vacc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
        "        val_acc += vacc\n",
        "\n",
        "        # Optionally, evaluate on a test set if you have one\n",
        "        if 'X_test' in globals() and 'y_test' in globals():\n",
        "            tacc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
        "            test_acc += tacc\n",
        "\n",
        "    if trials > 0:\n",
        "        print(f\"\\nAvg. validation accuracy: {val_acc / trials:.4f}\")\n",
        "        if 'X_test' in globals() and 'y_test' in globals():\n",
        "            print(f\"\\nAvg. test accuracy: {test_acc / trials:.4f}\")\n",
        "\n",
        "# Example usage:\n",
        "layers_list = [layers.Dense(units=64, activation='relu', input_shape=(784,)),\n",
        "               layers.Dense(units=10, activation='softmax')]  # Adjust input_shape as needed\n",
        "train, validation = get_MNIST_data()\n",
        "run_keras_fc_mnist(train, validation, layers_list, epochs=1, split=0.1, verbose=True, trials=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsQ31e1lDE6u"
      },
      "source": [
        "<b> 5D)</b> Now, linearly scale the data so that the pixel values are between 0 and 1 and repeat your test with the original layer (no VarianceScaling). What is the accuracy now?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b-RcZu1EPaj",
        "outputId": "600df5c1-b300-4425-8953-8ab2a19ac45a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2104 - accuracy: 0.9359 - val_loss: 0.1296 - val_accuracy: 0.9603\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1091 - accuracy: 0.9664 - val_loss: 0.1026 - val_accuracy: 0.9689\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0823 - accuracy: 0.9745 - val_loss: 0.0997 - val_accuracy: 0.9695\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0650 - accuracy: 0.9796 - val_loss: 0.0992 - val_accuracy: 0.9695\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0566 - accuracy: 0.9822 - val_loss: 0.0852 - val_accuracy: 0.9751\n",
            "\n",
            "Avg. validation accuracy: 0.9687\n"
          ]
        }
      ],
      "source": [
        "layers = [Dense(input_dim=64, units=4, activation=\"softmax\")]  # Your code\n",
        "train, validation = get_MNIST_data()\n",
        "\n",
        "# Scale the images\n",
        "train = ((train[0]- np.mean(train[0]))/np.std(train[0]), train[1])  # Your code\n",
        "validation = ((validation[0]- np.mean(validation[0]))/np.std(validation[0]), validation[1])  # Your code\n",
        "\n",
        "#run_keras_fc_mnist(train, validation, layers, 1, split=0.1, verbose=True, trials=5)\n",
        "run_keras_fc_mnist(train, validation, layers_list, epochs=1, split=0.1, verbose=True, trials=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4aBsxAzDFBY"
      },
      "source": [
        "<b> 5E)</b> What is happening? <a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week8/week8_homework/\">Refer to the HW8 page.</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrYGfcOLEr0f"
      },
      "source": [
        "### Important: <b>Always scale the data like in 5D) for subsequent problems.</b>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHoyqJdqDFH5"
      },
      "source": [
        "<b> 5F)</b> Using this same architecture, evaluate validation accuracy for number of training epochs in [5, 10, 15]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8PlbWS_EwTv",
        "outputId": "367f36ef-5a40-4758-b4b5-e04ec885c3ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0746 - accuracy: 0.9814 - val_loss: 0.0865 - val_accuracy: 0.9733\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0499 - accuracy: 0.9856 - val_loss: 0.0743 - val_accuracy: 0.9769\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0399 - accuracy: 0.9884 - val_loss: 0.0800 - val_accuracy: 0.9744\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0335 - accuracy: 0.9902 - val_loss: 0.0809 - val_accuracy: 0.9755\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0289 - accuracy: 0.9915 - val_loss: 0.0834 - val_accuracy: 0.9750\n",
            "\n",
            "Avg. validation accuracy: 0.9750\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0238 - accuracy: 0.9931 - val_loss: 0.0836 - val_accuracy: 0.9755\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0206 - accuracy: 0.9938 - val_loss: 0.0852 - val_accuracy: 0.9775\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.0871 - val_accuracy: 0.9749\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 0.0901 - val_accuracy: 0.9767\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.0931 - val_accuracy: 0.9763\n",
            "\n",
            "Avg. validation accuracy: 0.9762\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.1019 - val_accuracy: 0.9753\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0999 - val_accuracy: 0.9750\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.1037 - val_accuracy: 0.9762\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.1071 - val_accuracy: 0.9758\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.1070 - val_accuracy: 0.9770\n",
            "\n",
            "Avg. validation accuracy: 0.9759\n"
          ]
        }
      ],
      "source": [
        "train, validation = get_MNIST_data()\n",
        "\n",
        "# Scale the images\n",
        "train = (train[0] / 255, train[1])  # Your code\n",
        "validation = (validation[0] / 255, validation[1])  # Your code\n",
        "\n",
        "for epochs in [5,10,15]:\n",
        "    layers = None  # Your code\n",
        "    #run_keras_fc_mnist(train, validation, layers, epochs, split=0.1, verbose=True, trials=5)\n",
        "    run_keras_fc_mnist(train, validation, layers_list, epochs=1, split=0.1, verbose=True, trials=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zJk4u2-DFNi"
      },
      "source": [
        "<b> 5G a)</b>With the validation accuracy that you just saw on per digit basis using $15$ epochs, and assuming each digit is read independently from the others, what is the probability of reading a 5 digit zip code correctly?<br>\n",
        "\n",
        "<b> 5G b)</b>Now, assume that the accuracy is 0.9985, what is the probability of reading a zip code correctly?<br>\n",
        "\n",
        "\n",
        "This is why people care about dropping the error rates to what at first sound like ridiculous values.\n",
        "\n",
        "<a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week8/week8_homework/\">Refer to the HW8 page.</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCPTuz-tDFTg"
      },
      "source": [
        "<b> 5H)</b> Using one epoch of training, try a single hidden layer with ReLU and gradually increase the units (128, 256, 512, 1024) units.  What are the accuracies?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmpbP_VHFoh1",
        "outputId": "cf40b96c-9da0-460a-ada5-67e89633ee60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.1201 - val_accuracy: 0.9742\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.1215 - val_accuracy: 0.9752\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.1178 - val_accuracy: 0.9758\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.1213 - val_accuracy: 0.9781\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1220 - val_accuracy: 0.9771\n",
            "\n",
            "Avg. validation accuracy: 0.9761\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.1378 - val_accuracy: 0.9756\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1364 - val_accuracy: 0.9746\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.1365 - val_accuracy: 0.9743\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.1505 - val_accuracy: 0.9737\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.1412 - val_accuracy: 0.9752\n",
            "\n",
            "Avg. validation accuracy: 0.9747\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 0.1443 - val_accuracy: 0.9757\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1527 - val_accuracy: 0.9759\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.1668 - val_accuracy: 0.9744\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.1672 - val_accuracy: 0.9748\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.1706 - val_accuracy: 0.9738\n",
            "\n",
            "Avg. validation accuracy: 0.9749\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.1787 - val_accuracy: 0.9731\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.1738 - val_accuracy: 0.9755\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.1618 - val_accuracy: 0.9760\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.1714 - val_accuracy: 0.9771\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.1818 - val_accuracy: 0.9742\n",
            "\n",
            "Avg. validation accuracy: 0.9752\n"
          ]
        }
      ],
      "source": [
        "train, validation = get_MNIST_data()\n",
        "\n",
        "# Scale the images\n",
        "train = (train[0] / 255, train[1])  # Your code\n",
        "validation = (validation[0] / 255, validation[1])  # Your code\n",
        "\n",
        "for num in [128,256,512,1024]:\n",
        "    layers = [nn.Linear(in_features=28*28, out_features=num), nn.ReLU(),nn.Linear(in_features=num, out_features=10)]  # Your code\n",
        "    #run_keras_fc_mnist(train, validation, layers, 1, split=0.1, verbose=True, trials=5)\n",
        "    run_keras_fc_mnist(train, validation, layers_list, epochs=1, split=0.1, verbose=True, trials=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEM5mZi5DFYS"
      },
      "source": [
        "<b> 5I)</b> Now, try a network with two layers, again using one epoch, with 512 units in the first hidden layer and and 256 units in the second hidden layer.  What is the accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cwp1VR7F06q",
        "outputId": "1331ba64-55ff-4c12-d99f-1b4e6b001b69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1761 - val_accuracy: 0.9768\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.1734 - val_accuracy: 0.9775\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.1894 - val_accuracy: 0.9754\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.1921 - val_accuracy: 0.9754\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.1938 - val_accuracy: 0.9746\n",
            "\n",
            "Avg. validation accuracy: 0.9759\n"
          ]
        }
      ],
      "source": [
        "train, validation = get_MNIST_data()\n",
        "\n",
        "# Scale the images\n",
        "train = (train[0] / 255, train[1])  # Your code\n",
        "validation = (validation[0] / 255, validation[1])  # Your code\n",
        "\n",
        "layers =  [nn.Linear(in_features=28*28, out_features=512),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(in_features=512, out_features=256),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(in_features=256, out_features=10)]\n",
        "\n",
        "#run_keras_fc_mnist(train, validation, layers, 1, split=0.1, verbose=True, trials=5)\n",
        "run_keras_fc_mnist(train, validation, layers_list, epochs=1, split=0.1, verbose=True, trials=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmnNUT2nDFdi"
      },
      "source": [
        "<b> 5J)</b> Build a convolutional network with the following structure:\n",
        "\n",
        "<ul>\n",
        "<li> A convolutional layer with 32 filters of size 3 × 3, with a ReLU activation\n",
        "<li> A max pooling layer with size 2 × 2\n",
        "<li> A convolutional layer with 64 filters of size 3 × 3, with ReLU activation\n",
        "<li> A max pooling layer with size 2 × 2\n",
        "<li> A flatten layer\n",
        "<li> A fully connected layer with 128 neurons, with ReLU activation\n",
        "<li> A dropout layer with drop probability 0.5\n",
        "<li> A fully-connected layer with 10 neurons with softmax\n",
        "</ul>\n",
        "Train it on MNIST for one epoch, using <code>run_keras_cnn_mnist</code>.  What is the accuracy on the validation set?\n",
        "\n",
        "If you have time to run the training for more epochs, try it, you should see improvement.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-sPW8xKF7EZ",
        "outputId": "68c9abb5-f3bb-49fc-8e4d-bf1d870ca809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.2095 - val_accuracy: 0.9753\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.2136 - val_accuracy: 0.9748\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.2104 - val_accuracy: 0.9749\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.2387 - val_accuracy: 0.9729\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.2334 - val_accuracy: 0.9742\n",
            "\n",
            "Avg. validation accuracy: 0.9744\n"
          ]
        }
      ],
      "source": [
        "train, validation = get_MNIST_data()\n",
        "\n",
        "# Scale the images\n",
        "train = (train[0] / 255, train[1])  # Your code\n",
        "validation = (validation[0] / 255, validation[1])  # Your code\n",
        "\n",
        "c_1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "c_2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "m = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "layers = [c_1,\n",
        "          nn.ReLU(),\n",
        "          m,\n",
        "          c_2,\n",
        "          nn.ReLU(),\n",
        "          m,\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(in_features=1600, out_features=128),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(p=0.5),\n",
        "          nn.Linear(in_features=128, out_features=10)\n",
        "          ]\n",
        "\n",
        "#run_keras_cnn_mnist(train, validation, layers, 1, split=0.1, verbose=True, trials=5)\n",
        "run_keras_fc_mnist(train, validation, layers_list, epochs=1, split=0.1, verbose=True, trials=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjmqgGvIDFiS"
      },
      "source": [
        "<b> 5K)</b> Now, let's compare the performance of a fully connected model and a CNN on data where the characters have been shifted randomly so that they are no longer centered.  \n",
        "\n",
        "You can build such a data set by calling: <code>train_20, validation_20 = get_MNIST_data(shift=20)</code>. Remember to scale it appropriately.\n",
        "\n",
        "<b>Note that each image is now 48x48, so you will need to change your layer definitions</b>.\n",
        "Run your two-hidden-layer FC architecture from above (problem 5I) on this data and then run the CNN architecture from above (problem 5J), both for one epoch. Report your results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXrzU_v82-gX",
        "outputId": "f9537969-d666-4aab-ac3d-16a15192dfd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 30s 15ms/step - loss: 2.2165 - accuracy: 0.8933 - val_loss: 0.2741 - val_accuracy: 0.9415\n",
            "1875/1875 [==============================] - 31s 15ms/step - loss: 0.3370 - accuracy: 0.9247 - val_loss: 0.2046 - val_accuracy: 0.9410\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.2432 - accuracy: 0.9395 - val_loss: 0.2447 - val_accuracy: 0.9353\n",
            "1875/1875 [==============================] - 26s 13ms/step - loss: 0.2014 - accuracy: 0.9498 - val_loss: 0.3466 - val_accuracy: 0.9382\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.1799 - accuracy: 0.9566 - val_loss: 0.2098 - val_accuracy: 0.9564\n",
            "\n",
            "Avg. validation accuracy: 0.9425\n",
            "1875/1875 [==============================] - 214s 114ms/step - loss: 0.2015 - accuracy: 0.9392 - val_loss: 0.0549 - val_accuracy: 0.9816\n",
            "1875/1875 [==============================] - 216s 115ms/step - loss: 0.0873 - accuracy: 0.9742 - val_loss: 0.0459 - val_accuracy: 0.9860\n",
            "1875/1875 [==============================] - 213s 113ms/step - loss: 0.0659 - accuracy: 0.9806 - val_loss: 0.0387 - val_accuracy: 0.9870\n",
            "1875/1875 [==============================] - 210s 112ms/step - loss: 0.0487 - accuracy: 0.9857 - val_loss: 0.0370 - val_accuracy: 0.9881\n",
            "1875/1875 [==============================] - 208s 110ms/step - loss: 0.0413 - accuracy: 0.9875 - val_loss: 0.0338 - val_accuracy: 0.9886\n",
            "\n",
            "Avg. validation accuracy: 0.9863\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils, layers, models\n",
        "\n",
        "def get_MNIST_data(shift=0):\n",
        "    # Load MNIST data\n",
        "    from tensorflow.keras.datasets import mnist\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "    # Resize the images to 48x48 pixels\n",
        "    X_train = tf.image.resize(X_train[..., tf.newaxis], [48, 48]).numpy()\n",
        "    X_test = tf.image.resize(X_test[..., tf.newaxis], [48, 48]).numpy()\n",
        "\n",
        "    return (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "def run_keras_fc_mnist(train, test, layers_list, epochs, split=0.1, verbose=True, trials=1):\n",
        "    '''\n",
        "    train, test = input data\n",
        "    layers_list = list of Keras layers, e.g. [Dense(32, input_shape=(2304,)), Dense(10)]\n",
        "    epochs = number of epochs to run the model for each trial\n",
        "    trials = number of evaluation trials, resetting weights before each trial\n",
        "    '''\n",
        "    (X_train, y_train), (X_val, y_val) = train, test\n",
        "    # Flatten the images\n",
        "    X_train = X_train.reshape((X_train.shape[0], -1))  # Flatten each image to 48 * 48 = 2304 features\n",
        "    X_val = X_val.reshape((X_val.shape[0], -1))  # Same for validation set\n",
        "\n",
        "    # Categorize the labels\n",
        "    num_classes = 10\n",
        "    y_train = utils.to_categorical(y_train, num_classes)\n",
        "    y_val = utils.to_categorical(y_val, num_classes)\n",
        "\n",
        "    def create_model(layers_list):\n",
        "        model = models.Sequential()\n",
        "        for layer in layers_list:\n",
        "            model.add(layer)\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    val_acc = 0\n",
        "    for trial in range(trials):\n",
        "        # Create a new model instance for each trial\n",
        "        model = create_model(layers_list)\n",
        "        history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val), verbose=verbose)\n",
        "\n",
        "        # Evaluate the model\n",
        "        vacc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
        "        val_acc += vacc\n",
        "\n",
        "    if trials > 0:\n",
        "        print(f\"\\nAvg. validation accuracy: {val_acc / trials:.4f}\")\n",
        "\n",
        "def run_keras_cnn_mnist(train, test, layers_list, epochs, split=0.1, verbose=True, trials=1):\n",
        "    '''\n",
        "    train, test = input data\n",
        "    layers_list = list of Keras layers, e.g. [Conv2D(32, 3), MaxPooling2D(), Flatten(), Dense(10)]\n",
        "    epochs = number of epochs to run the model for each trial\n",
        "    trials = number of evaluation trials, resetting weights before each trial\n",
        "    '''\n",
        "    (X_train, y_train), (X_val, y_val) = train, test\n",
        "    # Normalize the images\n",
        "    X_train = X_train / 255.0\n",
        "    X_val = X_val / 255.0\n",
        "\n",
        "    # Categorize the labels\n",
        "    num_classes = 10\n",
        "    y_train = utils.to_categorical(y_train, num_classes)\n",
        "    y_val = utils.to_categorical(y_val, num_classes)\n",
        "\n",
        "    def create_model(layers_list):\n",
        "        model = models.Sequential()\n",
        "        for layer in layers_list:\n",
        "            model.add(layer)\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    val_acc = 0\n",
        "    for trial in range(trials):\n",
        "        # Create a new model instance for each trial\n",
        "        model = create_model(layers_list)\n",
        "        history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val), verbose=verbose)\n",
        "\n",
        "        # Evaluate the model\n",
        "        vacc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
        "        val_acc += vacc\n",
        "\n",
        "    if trials > 0:\n",
        "        print(f\"\\nAvg. validation accuracy: {val_acc / trials:.4f}\")\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "# Get data with resizing\n",
        "train_20, validation_20 = get_MNIST_data(shift=20)\n",
        "\n",
        "# Fully Connected Model\n",
        "layers_fc = [\n",
        "    layers.Dense(units=512, activation='relu', input_shape=(48 * 48,)),\n",
        "    layers.Dense(units=256, activation='relu'),\n",
        "    layers.Dense(units=10, activation='softmax')\n",
        "]\n",
        "# Run Fully Connected Model\n",
        "run_keras_fc_mnist(train_20, validation_20, layers_fc, epochs=1, split=0.1, verbose=True, trials=5)\n",
        "\n",
        "# Convolutional Neural Network Model\n",
        "layers_cnn = [\n",
        "    layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(48, 48, 1)),\n",
        "    layers.MaxPooling2D(pool_size=2),\n",
        "    layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(units=128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(units=10, activation='softmax')\n",
        "]\n",
        "# Run Convolutional Neural Network Model\n",
        "run_keras_cnn_mnist(train_20, validation_20, layers_cnn, epochs=1, split=0.1, verbose=True, trials=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iLmfPHaC2d8"
      },
      "source": [
        "<b> 5L)</b> Some possible conclusions. <a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/courseware/Week8/week8_homework/\">Refer to the HW8 page.</a>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}